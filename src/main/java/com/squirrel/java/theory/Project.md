#### Evaluate

- **评价系统介绍**

    - 评价系统的业务背景呢就是,自如之前的评价数据不统一,自如有好多业务线,长租,资管(自如寓/自如驿等),服务线(自如的搬家/保洁/维修等)
      ,之前每个业务线都有评价的业务,但是呢评价的功能都是每个业务线自己维护的,就类似于每个系统呢有一套自己的评价系统。
    - 后来公司要统一管理评价数据,就做了现在的这个评价中台,这个评价中台是基于之前长租的评价系统改进重构,技术背景之前的是Oracle数据库,然后重构直接进行了去O。
    - 当前的评价系统主要有几个模块:
        - 项目结构就是 评价API服务 + 评价DUBBO服务提供者 + 评价定时任务服务 + 评价后台服务
        - 第一个就是数据模型进行了改造::
          现在评价系统的数据模型是基于评价问题模板来进行设计的。首先呢是评价场景,场景下会有多个评价模板,我们可以根据该评价单的城市以及被评对象的分类或者评价人的用户画像以及被评人的用户画像等等去路由到不同的模板,说白了其实就是一个用户在去进行一个评价的时候会通过各种规则路由到一个评价模板上。(
          而之前的评价系统一个评价场景对应一套问题,不利于评价问卷的快速迭代与扩展,也不利于数据的统计,)
        -
      第二个就是评价系统抛弃之前APP原生页面,而是改用为H5页面,这样的话其实就是不依赖app发版时间,从而达到更快的迭代,更方便的让业务线进行对接,如果业务线要接入评价场景,可以直接使用评价系统提供的H5,而业务线只需要进行一个创建评价单的操作,就能够让用户进行一套完整的评价流程。(
      如果想要新增一个类型的问题,如果是APP的话肯定要等下一个版本进行发版（因为我们APP有固定的发版时间,一般双周发一次),如果是H5的话就不需要等待APP的发版时间。直接生效
        - 第三个就是评价系统的数据存储: 使用Mysql,并用Sharding-JDBC进行分表,以及使用Es存储评价数据,来达到可以存储大量的评价数据以及快速的进行评价数据的检索功能。
        - 第四个就是评价后台管理系统,对评价场景以及评价模板的灵活化配置,无需研发的操作,即可以完全达到产品和业务的自主配置就能对接一个评价场景,以及评价数据的各种方式的检索以及低分评价的一个处理回访等,以及一些统计报表。
    - 一套完整的评价流程？
        - 业务线调用评价的创建评价单接口-生成评价相关信息
        - 评价系统会返回给业务线一个去评价的链接。
        - 业务线拿到链接后返回给用户,提示用户去评价
          - 然后用户点击去评价的链接，就是从评价系统查看问题。（查看问题的部分有些逻辑- 根据城市、产品类型、被评人类型、以及当前被评人之前是否收过差评,如果收过差评继续推送之前的低分问题。）
    - 标准化接口相关逻辑：
        - 业务线创建评价单：
            - 评价单相关信息： 评价单归属地,评价单城市,评价单的开始和结束时间（可以由业务线自己制定）,幂等key,评价单来源,是否可进行回访等
            - 评价人相关信息：评价人uid 等。 异步补全评价人照片等信息。
            - 被评对象相关信息
                - 管家：管家Code,管家类型 -- 评价存储快照信息 -- 异步补全当时管家的信息- 姓名啊 所属组织等等
                - 房子:   房源Code,房源类型 -- 评价存储快照信息 -- 异步补全当时房源的信息 -- 房源地址 房源的产品类型等等
        - 查看评价问题 ：通过评价单号去查询评价问题。 创建评价单的时候根据 城市+场景+房源类型+管家类型+评价人类型 （有一个路由规则,确定一个评价模板）
            - 评价模板是什么？
            - 评价模板就是类似异于一张问卷。 该模板上绑定了一些评价问题。 有星星 标签、mot 、多选、矩阵、文本 图片等问题。
            - 核心是,一个评价场景下有很多模板, 例如客户新签了要给客户推送个评价。 之前老系统是不管是哪个城市的新签,评价的问题都是一样的。然后有了模板的概念之后,就比如
              不同城市或者几个城市对应一个模板。这样的话就能够针对性的给用户推送不同的问题。
            - 城市、产品、被评人类型、评价人类型 去做匹配。 （傻瓜式对接）
        - 提交评价：用户在页面选择答案进行提交
        - 查看详情：通过评价单号查询评价的详情.
        - 发送已评价消息：通过Mq 发送给业务线该评价的状态。 tipic 模式： routingkey 是 场景编号。 各自对接的业务线去消费这些数据。
    - 如何保证幂等key - 既然做了分表？
        - 我们的分表- 主要流程数据就是用评价单号进行分表。
        - 然后呢，还做了一个mapping表用来做 幂等key,uid 与评价单号的映射, 然后这个mapping的分区key 就是通过 幂等key和uid进行分区,然后通过有个字段代表这个key是属于 幂等key还是
          uid，从而能够查询出评价单号，业务线创建评价单的时候,我们会首先根据幂等key 去该映射表查询是否生成过评价，如果生成过了 就把生成过的评价单号返给业务线。
        - 做了一个幂等key与评价单号的映射表, 然后呢,创建评价单的时候首先去查询是否已经创建过了,如果创建过了那么直接返回评价单号。

- **评价系统相关指标**

    - 接入业务线： 长租、自如寓、自如驿、保洁、搬家、维修、职能。 9个业务线
    - 接入场景:  调研问卷、
    - 分表数量: 32张表
    - 单表数量:  1000万
    - 评价数据总量:  32 * 1000万 = 3.2亿
    - 目前每天评价单数据量: 15万, 月单量500万,年单量 7500万,可以支撑5年左右
    - 系统QPS:  总体来说不是很大,毕竟是房子、以及服务之类的评价。 80左右, 比较均匀

- **系统的难点**:

    - 数据模型的设计以及场景的配置？

        - 如何能够尽最大程度的满足业务的目标以及更多地业务需求？
            - 做到不同评价问卷按照一定的规则进行不同的适配（根据城市、房屋类型、以及简单的智慧推评）
            - 智慧推评：其实就是我们会收集用户低评的相关信息,记录某个低评相关的人以及问题，下次继续将该问题推送给他，
            - 以及某个评价问卷中问题按照一定的规则进行展示。 比如配置了多个MOT问题,随机展示两个或者1个。
            - 这样的话可以做到更精准的评价数据运营,针对更细粒度的被评对象,拿到用户的评价,然后再去对这些评价进行分析,这种更精细的问题可以更有效的找到业务上的痛点。

    - 数据迁移？ 分表

        - 平滑的进行数据迁移（不停机）
        - 第一阶段:主分表数据源同时写数据,以及将主表的历史数据写入分表数据源,并校验两个数据源的数据是否一致（但是事务模型以主表为准）
        - 第二阶段:主分表数据一致,仍然同时写入数据,并校验两个数据源的数据是否一致,(此时事务模型以分表为准)
        - 第三阶段: 第三阶段就是下掉主表，主表不在写入数据了。 完成分表

    - 系统QPS？

        - 一天平均访问次数400W PV

        - 平均响应时间 100ms

        - 最快速解决方案，就是增加机器。我们根据以上情况来实际计算一下。

            - 访问量：一天 400w pv
            - QPS： 60 多 两台机器作为流量的入口。

          根据日常经验，80% 的访问量集中在 20%的时间，算一下这 200w pv实际需要机器达到多少qps才能满足。

          ```apache
          qps = (200w * 0.8) / (24 * 3600 * 0.2)
          
          qps = 61.7
          ```

- **主要表结构**

    - 评价单表:
    - 评价人表
    - 被评对象表
    - 被评人表
    - 被评房屋表

### 数据迁移

- 数据库双写, 事务模型以老的为准,查询也走老模型
- 定时任务把历史数据迁移到新表中
- 实时数据：通过定时任务进行新老数据比对,并将数据不同差异补全

- 历史数据同步完毕切实时数据对比没有问题
- 数据源切为新表的数据源
- 依然是双写,事务模型以新模型为准,查询走新模型
- 定时任务接着比对新表老表数据

- 老模型不在同步写入、
- 数据平台迁移为新表数据源 把老表废除

### 非分区key映射

- NoSql
    - 首先我们是通过基础平台提供的Canal,将评价单分表聚合起来形成一个Es,这个Es上包括了uid、phone、bizCode等,当业务线或者评价 自己使用非sharding
      key查询的时候,先查询这个Es,可以查到评价单的状态以及单号,之后在查询评价的信息就可以通过评价单号查询出所有相关的信息.

- DB映射表
    - 基础平台提供的Es存在不稳定的情况,有时候可能消费延迟了,就会存在 根据uid 或者 bizCode在Es上查不到该条评价记录,此时就会影响业务,比如业务端的评价
      列表,就存在有时候管家邀约业主去评价时,业主打开列表却看不到评价单内容,不能评价。找过基础平台谈过这件事,现在好了很多,但是偶尔还会存在这种情况。
    - 为了解决这种情况,以及预防就及时Es服务不可用的情况下,只要DB可用,就不会影响评价系统对外提供服务,就设计了非 sharding key-Mapping的这个表。
    - 当非sharding key 的字段去查询评价信息, 首先通过Es去查,如果查不到,就去Mapping表查询到对应的评价单号,再去查对应的信息。

- 映射表上线流程：先进行实时写

### 业务线历史数据迁移

- 首先我们在评价系统创建好一系列的评价问题和答案 内容对应到业务线的历史评价数据,并告诉业务线这些评价问题和答案编码，约定迁移数据的接口,创建评价单的数据
  以及评价答案的数据一起打包传递过来,通过MQ的方式,评价这面声明一个队列,业务线往里发消息,主要是为了削峰,业务线肯定批量调么,为了不影响评价系统的性能,
  所以用mq的方式慢慢消费,这个过程中,执行失败或者成功都用mongo标记,并且处理完给业务线发送状态消息,告诉这条消息有没有正确 的消费掉。没有正确消费掉的
  消息，最后双方一起排查一下问题,接着消费。（当然在实际迁移过程中,失败的情况很少）

### 评价分布式事务解决方案

https://xiaomi-info.github.io/2020/01/02/distributed-transaction/

- 本地消息表： 最大努力通知：
    - 评价系统涉及到的分布式事务主要就在于评价状态的流转,某些业务线会记录评价单的单号以及状态,评价系统提供的方案就是用户提交完评价后发送消息
      通知各业务线,这个过程评价系统会记录一个本地消息表,存取评价单号以及评价状态,业务线收到消息后回调确认评价状态的一个接口,评价系统这面将该消息 表的评价状态变更为已评价。否则就会去轮询尝试发送消息直到重试最大次数。
    - 同时评价系统也暴露查询评价状态的接口,如果业务线需要特别实时的评价状态,可以选择直接调用评价状态的接口。

### 评价系统表结构设计:

- 评价单表:
  - 评价单表.包含了评价单状态,场景编号,城市,开始时间,结束时间,幂等key、评价时间等
  - 评价人表:存储评价人相关的一些信息
  - 被评人表:存储被评人相关的一些信息, 自如管家,维修师傅,保洁阿姨等等。
  - 被评价房屋表: 对应的房屋ID等.
  - 评价场景-模板关联表: 场景下有哪些模板。
  - 评价问题表: 问题编码 问题类型, 问题描述,选项样式
  - 评价选项表:
      - 垂直分表
      - 水平分表
  - 场景配置表

###  project：

# 评价系统重构面点：
## 一期：背着 7年的历史包袱，将三套系统重构为一套
- A&Q：背景简单说；公司的目标，去除Oracle数据库，耗时5个月，3个人
- 难点：1. 如何保证线上业务正常运行，无感迁移数据到分表 2. 如何保证数据一致性
- 如何做：三个点，自下而上，
- 1. 重新设计数据模型，体现“单据”大概念，评价只是自如业务的一个点，通过评价单将业务上下游串起来
- 2. 基于平台化的思想，接口标准化，6大业务线35+场景几乎0开发接入业务线，不同业务线特殊业务逻辑“扩展点”实现（这个就瞎吹就行，虽然并没有做到，但当初思路差不多）
- 3. 全新 to C、to B 系统，评价页面实现模板动态渲染，类似于问卷形式
- 做的不好的：数据迁移方案设计的不好，但二期实现了线上无感“平滑迁移”（引到二期，突出平滑，这很关键）
## 二期：一年不到评价单量接近一千万，问题记录表 2千多万，故以评价单号分表32张
- A&Q：背景，业务线不断有各个流程节点的评价场景接入，如上
- 难点：1. 如何保证线上业务正常运行，无感迁移数据到分表 2. 如何保证数据一致性 3. 如何实现非sharding-key的高效查询 4. 怎么确定是评价单号分表
- 设计：通过梳理分析当前评价在业务中的使用场景，有8+场景使用评价单号，另外有2+ 使用 uid等场景
- 如何做：
- master - slave双写设计。基于 DataSource 做封装，业务代码无侵入，事务隔离，读写请求动态路由隔离，设计 master - slave 的角色概念，动态管理 DataSource 的角色，同一时间段 写请求以 master 为准，slave 做流量拷贝异步执行写请求，适当放量灰度部分读流量到 slave（分表）（灰度我们没有设计，但是如果问就说 读 请求灰度就行，灰度策略就是城市或评价单号白名单）
- 定时任务校验主表与分表，修复数据一致性。一个定时任务兜底，基于 master-slave 的思路，秒级别查询主表变更的数据（通过最后更新时间），与分表做对比
- 通过canal 实现增量消息订阅，将评价分表数据同步聚合到 ES 宽表，以支撑查询。
- 做的不好的：6大业务线在评价中心的隔离（不同业务线请求量和数据量都不一样），只做到了流量层面控制（Sentinel流控），并没做数据层面的隔离，之后可以参考多租户的概念
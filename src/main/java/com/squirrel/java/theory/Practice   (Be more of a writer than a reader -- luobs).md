**Practice**   (Be more of a writer than a reader -- luobs)

------

#### HashMap

1.  首先计算key的hashCode,然后进行右移16位，然后进行一个异或运算。避免hash值得低位冲突,造成hash碰撞的概率变高。
2.  然后判断数组是否为空以及数组的长度是否为0,如果为空或0,那么进行一次扩容操作。 如果指定了集合容量,就取与该容量最接近的2的n次幂的容量。保证集合的大小为偶数。
3. 用计算过后的hash值与数组长度减1进行位运算,当数组长度位2的n次幂的时候就相当于, hash值与数组长度进行取模运算,这样的话就能计算出当前key在数组中的下标。
4. 然后判断当前下标处时候有值,如果无,那么就直接将值插入到当前下标下。
5. 如果有值,判断第一个节点的key是否是要插入的key的值,如果是的话,那么将该key 的值进行替换。
6. 如果不相同,判断头结点是链表节点还是红黑树节点，如果是链表节点的话,就将遍历该链表,然后判断是否有该节点的key,如果有就替换值即可，如果没有就插入到链表尾部，
7. 然后判断链表的长度是否大于8,如果大于8那么就转换成红黑树。
8. 如果是红黑树就按照红黑树的方式插入到红黑树的节点上。
9. 然后判断容量是否达到了集合的阈值,如果超过了 那么进行扩容。

ConcurrentHashMap

1. 校验 key和value不能为空
2. 计算key 的hashCode,  然后 判断数组是否为空,如果为空,就去初始化数组,不过是保证了一个线程去初始化。使用cas通过sizeCtl变量来保证的。
3. 然后根据hashCode与数据组的长度确定到数组的下标,然后判断当前下标处是否有值, 无值得话,通过cas设置该节点。
4. 如果不为空判断是否处于迁移阶段, 如果是处于迁移阶段,那么去进行协助迁移
5. 否则使用synchronized锁定头结点,如果是链表就插入到链表尾部,如果是红黑树节点就按照红黑树的插入逻辑插入到红黑树中,链表长度到8就转为红黑树。

hashmap长度设置为2的原因？

1. hashmap计算hashCode的时候总是将 高16位和低16位进行异或运算的到最终的hash值,这样可以保留高位的特征,避免某些key 的低位相同,造成hash冲突。
2. 同时数组下标计算方式是, hashCode与n-1进行位运算，在2的n次幂情况下,类似于 hashCode%n，位运算更快一些

hashmap扩容后需要rehash吗？

1. 不需要,扩容情况下,数组扩大2倍,所以当hashCode与数组长度取模的时候,只需要多看1位,如果运算完是1,那么就将原位置的元素添加到原数组长度+当前下标的位置上,如果是0就保持原来元素的位置不变。

为什么在链表长度为8的时候进行转换？

1. 遵循泊松分布的概率,链表长度为8的概率很低很低
2. 当链表长度大于8的时候,红黑树的时间复杂度小于链表的时间复杂度。

hashmap与ConcurrentMap区别？

1. key 和 value  hashmap可以为空
2. hashmap是线程不安全的。  

LinkedHashMap？

1. 链表，结构就是hashmap 然后每个节点存有两个指针,指向前一个节点和后一个节点,形成一个双向链表。
2. accessOrder实现了按照顺序插入以及访问顺序。

ArrayList和LinkedList？

1. 底层是一个Object数组,默认数组长度为0,添加第一个元素的时候会初始化一个数组长度为10的数组,后面如果元素超过数组长度,那么进行扩容,新数组的容量为原来的1.5倍
2. LinkedList底层使用的是双向链表,每个节点保存了指向前驱节点和后继节点的指针,初始化时,不执行任何操作,添加第一个元素时候,再去构造链表中的节点。

##### Lock

1. CAS涉及三个操作数

   1. 读写内存的地址
   2. 读内存地址的原值
   3. 想替换的新值
   4. 当期望的值等于传入的值,那么进行交换。
2. CAS的缺点：

   1. ABA问题,如果一个线程在进行CAS操作的时候,如果另一个线程对其进行了修改然后又改回了原值,这个线程不能感知却还能继续对该地址的值进行操作。
   2. 自旋操作
   3. 只能对一个共享变量进行操作。  可以使用AtomicStamp 的类来避免这种问题，提供了一个版本号的概念。
3. Synchronized？

   1. Synchronized是一个同步锁,1.6之前是一个重量锁, 1.6之后进行了一系列优化,有几种锁的概念,偏向锁、轻量级所、重量级锁。每个对象的对象头中都包含了一个MarkWord,这个MarkWord中包含了  线程ID,hashCode ,GC年龄等
   2. 偏向锁：线程在获取锁对象的时候,将自身的线程ID通过CAS设置到锁对象上,如果设置成功,则证明获取偏向锁成功,然后该线程下次再获取锁的时候,只需要比较自身ID和锁对象中的线程ID是否相同,如果相同,则证明获取到了锁。
   3. 轻量级锁：线程将锁对象的MarkWord复制到自身的MarkWord上,然后在将markword通过CAS设置到锁对象上,如果设置成功,那么代表获取到轻量级锁。如果获取不到就通过一个自适应自旋的操作去获取锁,如果还获取不到那么久升级为重量级锁。
   4. 重量级锁：使用的是操作系统底层的互斥锁。每个对象都有一个monitor对象,并且存在几个队列。 
      1. 竞争队列:  存在多个竞争锁的线程   先进后出的一个队列。
      2. 等待队列：调用wait方法的会进入等待队列
      3. 候选队列：获取到锁的线程会从竞争对队列尾部选取一个线程加入候选队列,与末尾入队的线程进行竞争锁
4. 谈谈ReentrantLock？

   1. 基于AQS 抽象队列同步器, AQS提供了一个state 代表锁的状态, 0 代表无锁
   2. ReentrantLock 首先对state 尝试用cas 将其从0变为1,如果成功,并设置当前线程ID,则证明获取锁成功
   3. 如果cas失败,在进行一次获取锁，然后如果失败后再判断其是否是锁重入，如果是重入将 state+1,获取锁成功
   4. 如果再次获取锁失败  那么加入等待队列。
5. **Synchronzied 和 ReentrantLock区别？**

   1. Synchronized不支持响应中断, ReentrntLock支持响应中断
   2. reentrant支持超时放弃竞争锁,synchronized会一直阻塞到获取到锁
   3. 线程激烈的情况下 reentrantlock 性能会更好一些。
   4. synchronized是非公平锁,reen支持两种模式
6. **谈谈你对AQS的理解？**

   1. AQS是一个抽象队列同步器,帮助你实现了线程获取不到锁的时候入队和出队的功能,只需要我们实现一个锁的时候,重写获取锁的部分以及释放锁的部分即可。 tryAcquire 和 tryRelease等方法。
7. **读写锁以及底层实现**？
   1. 读写锁的一个原理其实就是。  读写互斥、写写互斥、读读不互斥。 
   2. 读写锁呢,根据一个整形变量的字段 高16位和低16位来区分是读锁还是写锁，低16位是写锁,高16位是读锁。
   3. 写锁的读取与释放：首先判断state,如果state为0,那么就去设置锁状态返回,如果不为0,判断写锁数量是否为0,如果为0 或者线程ID不是当前线程,那么就返回, 如果为是当前线程ID,再去判断 写锁数量是否超过了最大值,如果没超过,那么就设置状态并返回。
   4. 读锁的读取与释放：读锁首先是共享的,它能够被多个读线程获取,首先判断写锁是否为0,如果不是0则返回,如果是0的话,就设置读锁状态，然后判断读线程是否为0,如果为0,设置当前线程为第一个读线程,然后将读线程数+1,如果不是第一个读线程的话,就获取到当前线程的计数器, 然后进行读线程数++
8. **线程池设置**？
   1. 核心线程数
   2. 最大线程数
   3. 线程存活时间
   4. 阻塞队列
   5. 线程池拒绝策略：  
      1. 主线程提交策略
      2. 抛出异常策略 
      3. 丢弃策略
      4. 丢弃老的未执行的任务
   6. CPU密集型：  CPU+ 1个核心线程
   7. IO密集型：   2CPU+1 个线程。
9. **并发工具**？
   1. FutureTask
   2. CountDownLatch
   3. 

##### Redis

- Redis**有哪些结构**？
  - list:   压缩列表
  - string：字符串
  - set   ：set集合   底层是一个hash结构
  - zset ：zset 集合    跳跃表： 类似于 底层是一个链表,然后每个链表节点上方有一些索引节点。
  - hash ：哈希表  
- Redis过期key是如何清理的？
  - 惰性清理：当查询一个key的时候,然后去过期列表中判断该key有没有过期,如果过期了那么就删除。并返回null
  - 定时清理：定时任务去扫描每个DB中过期列表的key，如果过期了那么就进行删除。
  - 内存不够的时候进行清理：
    - 直接报错
    - 从所有结果集中进行淘汰：随机淘汰、从过期字典中随机淘汰,LRU算法淘汰。
- **Zset是怎么执行查询操作的？**
  - Zset是基于跳跃表和字典来实现的
    - 如果是单key查询的话  那么直接用字典即可查询
    - 如果是跳跃表查询, 从最上层的节点的score值进行比较, 根据要查找key 的score 的分值进行比较,不断的查找索引节点所在的区间,一层一层的进行寻找,直到找到与这个节点相同的节点。
- **Redis为什么是单线程的以及为什么这么快？**https://www.jianshu.com/p/bc6904abc330
  - Redis是纯基于内存的。
  - Redis使用的数据都是经过优化过得：比如string 内部结构保留了一定的预留空间,避免修改带来的开销。 list采用了压缩列表,使得空间占用变小。
  - Redis使用了IO多路复用技术： epoll 。  一个线程去处理所有的socket链接,如果某个socket连接发起请求,
- Linux IO模型有哪些？
  - 阻塞IO
  - 非阻塞IO
  - 异步IO
  - 信号驱动
- 聊聊IO多路复用模型？
  - select ： select的一个缺点在于单个进程能够监视的文件描述符为1024个。 使用遍历文件描述符的方式。
  - poll：poll 的话就是没有数量的限制,也是通过遍历文件描述符的方式去获取已经就绪的socket,
  - epoll: epoll 是事先通过 epoll_ctl 来注册一个文件描述符,一旦基于某个文件描述就绪的时候,内核会采用回调的机制,通知告知epoll 这个文件描述符可以执行了。  类似于一种注册监听的机制。
  - epoll的优点就是监听的描述符数量不受限制,IO的效率不会随着 描述符数量的增多而导致效率下降, epoll 是基于描述符的回调机制来实现的，只有就绪的描述符才会执行回调函数， 而select 和poll 是属于轮训遍历所有的 描述符，然后找到就绪的描述符。
- Redis缓存穿透？
  - 缓存穿透，是指客户端故意访问一些缓存中不存在的key ,然后导致大量的请求打入到DB 从而引起DB崩溃。 
  - 为NULL 也缓存很短的时间  避免大量请求涌入DB
- Redis缓存击穿？
  - 热点key 时效 导致大量请求失败.   1.双重缓存   不同的key  时间不同  2.请求的时候根绝缓存的剩余时间去更新缓存。
- **Redis缓存雪崩?**
  - 缓存中的key 大量时效，导致请求持续涌入DB 导致系统崩溃
- Redis缓存与数据库一致性问题如何解决？
  - 延时双删， 先更新数据库，删除缓存,在延时删除一次缓存（保证删除成功。）
  - 订阅数据库的binlog, 通过阿里的canal来订阅mysql中的更新操作,获取到指定的key然后进行缓存删除的操作,延时双删。异常重试。
- Redis持久化如何实现的？
  - 通过 AOF和RDB两种方式实现。
- AOF和RDB的区别？
  - AOF 记录Redis的操作命令，粒度更细，在进行数据恢复的时候，恢复的数据更加完整,但相比RDB效率会低一点。
  - RDB记录的是数据的快照信息，恢复效率比较高
- AOF如何防止文件越来越大？
  - AOF重写，生成此刻DB数据所需的写命令 并写入AOF文件,生成期间,父进程可以正常进行处理请求,将命令写入aof_buf 缓冲区,然后在将其写入到新的aof文件中,然后原子的替换老的aof文件
- AOF持久化方式？
  - 混合持久化，互相配合使用。前半段是RDB  后半段是aof。
- 跳跃表与平衡树,哈希表的比较？
  - 哈希表和  O（1）   平衡    跳跃表 单key 查询时间复杂度为
  - 空间复杂度： 平衡树每个节点包含了两个指针,  跳跃表的节点数量和其有几层的概率相关, redis默认的跳表指针是1.33  
- 为什么Mysql不是用跳跃表作为索引？
  - 磁盘IO的开销, B+树一般是2到4层,而跳表查找一个score对应的位置需要进行 log n次的操作，如果所有的索引节点都存在磁盘中，那么也就需要 log n次的磁盘IO
- **为什么平衡二叉树也不适合作为索引？**https://www.cnblogs.com/aspirant/p/9214485.html
  - 逻辑上相近的节点在物理结构上可能会相差很远,因此，每次读取的磁盘页的数据好多是用不上的。因此查找过程中需要进行多次的磁盘IO
- 红黑树
  - 

##### Mysql

1. 一条Sql语句执行发生了什么?
   1. 连接-分析器-优化器-执行器
   2. 首先写undolog,记录下执行语句的回滚日志,用来MVCC 回滚。如果查找的目标 在内存中 ： 判断是唯一索引还是普通索引   不在内存中 
   3. 在写redolog , 写binlog  提交事务 刷 redolog 盘  在刷binlog盘。
2. **为什么要用二阶段提交机制**？
   1. 数据库的二阶段提交机制就是   先写redolog,设置事务状态为prepare状态,然后在写 binlog，事务状态标记为完成。
   2. 如果redolog提交成功了, binlog没写,数据库崩溃了，服务启动后对比一下两个文件的数据，发现不一致就进行回滚
   3. 先写binlog的话  然后崩溃  redolog没写  事务不生效  但是binlog有了 ，可以发现数据库的数据和根据日志恢复出来的数据不一致。
3. 聊聊索引？
   1. 索引是什么呢？ 索引就是一种能够高效的获取数据的一种数据结构。
   2. 聚簇索引和非聚簇索引：聚簇又名主键索引，主键索引叶子节点存储了该行数据，非主键索引叶子节点存储的是 主键id
   3. 唯一索引： 内存中只有一个
   4. 联合索引： 最左前缀   多列字段组成的联合索引
   5. 索引有几种类型： B+树 索引    hash索引    普通索引、 唯一索引、联合索引
4. 聊聊Sql优化？
   1. 通过  查看执行计划
5. Mysql事务的实现以及原理？https://cloud.tencent.com/developer/article/1431307
6. Mvcc实现的原理是什么？https://github.com/NotFound9/interviewGuide/blob/master/docs/MySQLNote.md
7. Mysql锁有哪些？
8. 当前读和快照读？
9. Mysql不可重复读是怎么实现的？
10. Mysql底层采用什么树什么存储的？
11. Mysql死锁实践？
12. Mysql覆盖索引通过执行计划能看到哪几个？
13. 设计数据库表的思路？


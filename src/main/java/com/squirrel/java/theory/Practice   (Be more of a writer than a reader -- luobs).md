**Practice**   (Be more of a writer than a reader -- luobs)

------

#### HashMap

1.  首先计算key的hashCode,然后进行右移16位，然后进行一个异或运算。避免hash值得低位冲突,造成hash碰撞的概率变高。
2.  然后判断数组是否为空以及数组的长度是否为0,如果为空或0,那么进行一次扩容操作。 如果指定了集合容量,就取与该容量最接近的2的n次幂的容量。保证集合的大小为偶数。
3. 用计算过后的hash值与数组长度减1进行位运算,当数组长度位2的n次幂的时候就相当于, hash值与数组长度进行取模运算,这样的话就能计算出当前key在数组中的下标。
4. 然后判断当前下标处时候有值,如果无,那么就直接将值插入到当前下标下。
5. 如果有值,判断第一个节点的key是否是要插入的key的值,如果是的话,那么将该key 的值进行替换。
6. 如果不相同,判断头结点是链表节点还是红黑树节点，如果是链表节点的话,就将遍历该链表,然后判断是否有该节点的key,如果有就替换值即可，如果没有就插入到链表尾部，
7. 然后判断链表的长度是否大于8,如果大于8那么就转换成红黑树。
8. 如果是红黑树就按照红黑树的方式插入到红黑树的节点上。
9. 然后判断容量是否达到了集合的阈值,如果超过了 那么进行扩容。

ConcurrentHashMap

1. 校验 key和value不能为空
2. 计算key 的hashCode,  然后 判断数组是否为空,如果为空,就去初始化数组,不过是保证了一个线程去初始化。使用cas通过sizeCtl变量来保证的。
3. 然后根据hashCode与数据组的长度确定到数组的下标,然后判断当前下标处是否有值, 无值得话,通过cas设置该节点。
4. 如果不为空判断是否处于迁移阶段, 如果是处于迁移阶段,那么去进行协助迁移
5. 否则使用synchronized锁定头结点,如果是链表就插入到链表尾部,如果是红黑树节点就按照红黑树的插入逻辑插入到红黑树中,链表长度到8就转为红黑树。

hashmap长度设置为2的原因？

1. hashmap计算hashCode的时候总是将 高16位和低16位进行异或运算的到最终的hash值,这样可以保留高位的特征,避免某些key 的低位相同,造成hash冲突。
2. 同时数组下标计算方式是, hashCode与n-1进行位运算，在2的n次幂情况下,类似于 hashCode%n，位运算更快一些

hashmap扩容后需要rehash吗？

1. 不需要,扩容情况下,数组扩大2倍,所以当hashCode与数组长度取模的时候,只需要多看1位,如果运算完是1,那么就将原位置的元素添加到原数组长度+当前下标的位置上,如果是0就保持原来元素的位置不变。

为什么在链表长度为8的时候进行转换？

1. 遵循泊松分布的概率,链表长度为8的概率很低很低
2. 当链表长度大于8的时候,红黑树的时间复杂度小于链表的时间复杂度。

hashmap与ConcurrentMap区别？

1. key 和 value  hashmap可以为空
2. hashmap是线程不安全的。  

LinkedHashMap？

1. 链表，结构就是hashmap 然后每个节点存有两个指针,指向前一个节点和后一个节点,形成一个双向链表。
2. accessOrder实现了按照顺序插入以及访问顺序。

ArrayList和LinkedList？

1. 底层是一个Object数组,默认数组长度为0,添加第一个元素的时候会初始化一个数组长度为10的数组,后面如果元素超过数组长度,那么进行扩容,新数组的容量为原来的1.5倍
2. LinkedList底层使用的是双向链表,每个节点保存了指向前驱节点和后继节点的指针,初始化时,不执行任何操作,添加第一个元素时候,再去构造链表中的节点。

##### Lock

1. CAS涉及三个操作数

   1. 读写内存的地址
   2. 读内存地址的原值
   3. 想替换的新值
   4. 当期望的值等于传入的值,那么进行交换。
2. CAS的缺点：

   1. ABA问题,如果一个线程在进行CAS操作的时候,如果另一个线程对其进行了修改然后又改回了原值,这个线程不能感知却还能继续对该地址的值进行操作。
   2. 自旋操作
   3. 只能对一个共享变量进行操作。  可以使用AtomicStamp 的类来避免这种问题，提供了一个版本号的概念。
3. Synchronized？

   1. Synchronized是一个同步锁,1.6之前是一个重量锁, 1.6之后进行了一系列优化,有几种锁的概念,偏向锁、轻量级所、重量级锁。每个对象的对象头中都包含了一个MarkWord,这个MarkWord中包含了  线程ID,hashCode ,GC年龄等
   2. 偏向锁：线程在获取锁对象的时候,将自身的线程ID通过CAS设置到锁对象上,如果设置成功,则证明获取偏向锁成功,然后该线程下次再获取锁的时候,只需要比较自身ID和锁对象中的线程ID是否相同,如果相同,则证明获取到了锁。
   3. 轻量级锁：线程将锁对象的MarkWord复制到自身的MarkWord上,然后在将markword通过CAS设置到锁对象上,如果设置成功,那么代表获取到轻量级锁。如果获取不到就通过一个自适应自旋的操作去获取锁,如果还获取不到那么久升级为重量级锁。
   4. 重量级锁：使用的是操作系统底层的互斥锁。每个对象都有一个monitor对象,并且存在几个队列。 
      1. 竞争队列:  存在多个竞争锁的线程   先进后出的一个队列。
      2. 等待队列：调用wait方法的会进入等待队列
      3. 候选队列：获取到锁的线程会从竞争对队列尾部选取一个线程加入候选队列,与末尾入队的线程进行竞争锁
4. 谈谈ReentrantLock？

   1. 基于AQS 抽象队列同步器, AQS提供了一个state 代表锁的状态, 0 代表无锁
   2. ReentrantLock 首先对state 尝试用cas 将其从0变为1,如果成功,并设置当前线程ID,则证明获取锁成功
   3. 如果cas失败,在进行一次获取锁，然后如果失败后再判断其是否是锁重入，如果是重入将 state+1,获取锁成功
   4. 如果再次获取锁失败  那么加入等待队列。
5. **Synchronzied 和 ReentrantLock区别？**

   1. Synchronized不支持响应中断, ReentrntLock支持响应中断
   2. reentrant支持超时放弃竞争锁,synchronized会一直阻塞到获取到锁
   3. 线程激烈的情况下 reentrantlock 性能会更好一些。
   4. synchronized是非公平锁,reen支持两种模式
6. **谈谈你对AQS的理解？**

   1. AQS是一个抽象队列同步器,帮助你实现了线程获取不到锁的时候入队和出队的功能,只需要我们实现一个锁的时候,重写获取锁的部分以及释放锁的部分即可。 tryAcquire 和 tryRelease等方法。
7. **读写锁以及底层实现**？
   1. 读写锁的一个原理其实就是。  读写互斥、写写互斥、读读不互斥。 
   2. 读写锁呢,根据一个整形变量的字段 高16位和低16位来区分是读锁还是写锁，低16位是写锁,高16位是读锁。
   3. 写锁的读取与释放：首先判断state,如果state为0,那么就去设置锁状态返回,如果不为0,判断写锁数量是否为0,如果为0 或者线程ID不是当前线程,那么就返回, 如果为是当前线程ID,再去判断 写锁数量是否超过了最大值,如果没超过,那么就设置状态并返回。
   4. 读锁的读取与释放：读锁首先是共享的,它能够被多个读线程获取,首先判断写锁是否为0,如果不是0则返回,如果是0的话,就设置读锁状态，然后判断读线程是否为0,如果为0,设置当前线程为第一个读线程,然后将读线程数+1,如果不是第一个读线程的话,就获取到当前线程的计数器, 然后进行读线程数++
8. **线程池设置**？
   1. 核心线程数
   2. 最大线程数
   3. 线程存活时间
   4. 阻塞队列
   5. 线程池拒绝策略：  
      1. 主线程提交策略
      2. 抛出异常策略 
      3. 丢弃策略
      4. 丢弃老的未执行的任务
   6. CPU密集型：  CPU+ 1个核心线程
   7. IO密集型：   2CPU+1 个线程。
9. **并发工具**？
   1. FutureTask
   2. CountDownLatch
   3. 

##### Redis

- Redis**有哪些结构**？
  - list:   压缩列表
  - string：字符串
  - set   ：set集合   底层是一个hash结构
  - zset ：zset 集合    跳跃表： 类似于 底层是一个链表,然后每个链表节点上方有一些索引节点。
  - hash ：哈希表  
- Redis过期key是如何清理的？
  - 惰性清理：当查询一个key的时候,然后去过期列表中判断该key有没有过期,如果过期了那么就删除。并返回null
  - 定时清理：定时任务去扫描每个DB中过期列表的key，如果过期了那么就进行删除。
  - 内存不够的时候进行清理：
    - 直接报错
    - 从所有结果集中进行淘汰：随机淘汰、从过期字典中随机淘汰,LRU算法淘汰。
- **Zset是怎么执行查询操作的？**
  - Zset是基于跳跃表和字典来实现的
    - 如果是单key查询的话  那么直接用字典即可查询
    - 如果是跳跃表查询, 从最上层的节点的score值进行比较, 根据要查找key 的score 的分值进行比较,不断的查找索引节点所在的区间,一层一层的进行寻找,直到找到与这个节点相同的节点。
- **Redis为什么是单线程的以及为什么这么快？**https://www.jianshu.com/p/bc6904abc330
  - Redis是纯基于内存的。
  - Redis使用的数据都是经过优化过得：比如string 内部结构保留了一定的预留空间,避免修改带来的开销。 list采用了压缩列表,使得空间占用变小。
  - Redis使用了IO多路复用技术： epoll 。  一个线程去处理所有的socket链接,如果某个socket连接发起请求,
- Linux IO模型有哪些？
  - 阻塞IO
  - 非阻塞IO
  - 异步IO
  - 信号驱动
- 聊聊IO多路复用模型？
  - select ： select的一个缺点在于单个进程能够监视的文件描述符为1024个。 使用遍历文件描述符的方式。
  - poll：poll 的话就是没有数量的限制,也是通过遍历文件描述符的方式去获取已经就绪的socket,
  - epoll: epoll 是事先通过 epoll_ctl 来注册一个文件描述符,一旦基于某个文件描述就绪的时候,内核会采用回调的机制,通知告知epoll 这个文件描述符可以执行了。  类似于一种注册监听的机制。
  - epoll的优点就是监听的描述符数量不受限制,IO的效率不会随着 描述符数量的增多而导致效率下降, epoll 是基于描述符的回调机制来实现的，只有就绪的描述符才会执行回调函数， 而select 和poll 是属于轮训遍历所有的 描述符，然后找到就绪的描述符。
- Redis缓存穿透？
  - 缓存穿透，是指客户端故意访问一些缓存中不存在的key ,然后导致大量的请求打入到DB 从而引起DB崩溃。 
  - 为NULL 也缓存很短的时间  避免大量请求涌入DB
- Redis缓存击穿？
  - 热点key 时效 导致大量请求失败.   1.双重缓存   不同的key  时间不同  2.请求的时候根绝缓存的剩余时间去更新缓存。
- **Redis缓存雪崩?**
  - 缓存中的key 大量时效，导致请求持续涌入DB 导致系统崩溃
- Redis缓存与数据库一致性问题如何解决？
  - 延时双删， 先更新数据库，删除缓存,在延时删除一次缓存（保证删除成功。）
  - 订阅数据库的binlog, 通过阿里的canal来订阅mysql中的更新操作,获取到指定的key然后进行缓存删除的操作,延时双删。异常重试。
- Redis持久化如何实现的？
  - 通过 AOF和RDB两种方式实现。
- AOF和RDB的区别？
  - AOF 记录Redis的操作命令，粒度更细，在进行数据恢复的时候，恢复的数据更加完整,但相比RDB效率会低一点。
  - RDB记录的是数据的快照信息，恢复效率比较高
- AOF如何防止文件越来越大？
  - AOF重写，生成此刻DB数据所需的写命令 并写入AOF文件,生成期间,父进程可以正常进行处理请求,将命令写入aof_buf 缓冲区,然后在将其写入到新的aof文件中,然后原子的替换老的aof文件
- AOF持久化方式？
  - 混合持久化，互相配合使用。前半段是RDB  后半段是aof。
- 跳跃表与平衡树,哈希表的比较？
  - 哈希表和  O（1）   平衡    跳跃表 单key 查询时间复杂度为
  - 空间复杂度： 平衡树每个节点包含了两个指针,  跳跃表的节点数量和其有几层的概率相关, redis默认的跳表指针是1.33  
- 为什么Mysql不是用跳跃表作为索引？
  - 磁盘IO的开销, B+树一般是2到4层,而跳表查找一个score对应的位置需要进行 log n次的操作，如果所有的索引节点都存在磁盘中，那么也就需要 log n次的磁盘IO
- **为什么平衡二叉树也不适合作为索引？**https://www.cnblogs.com/aspirant/p/9214485.html
  - 逻辑上相近的节点在物理结构上可能会相差很远,因此，每次读取的磁盘页的数据好多是用不上的。因此查找过程中需要进行多次的磁盘IO
- 红黑树
  - 

##### Mysql

1. 一条Sql语句执行发生了什么?
   1. 连接-分析器-优化器-执行器
   2. 首先写undolog,记录下执行语句的回滚日志,用来MVCC 回滚。如果查找的目标 在内存中 ： 判断是唯一索引还是普通索引   不在内存中 
   3. 在写redolog , 写binlog  提交事务 刷 redolog 盘  在刷binlog盘。
2. **为什么要用二阶段提交机制**？
   1. 数据库的二阶段提交机制就是   先写redolog,设置事务状态为prepare状态,然后在写 binlog，事务状态标记为完成。
   2. 如果redolog提交成功了, binlog没写,数据库崩溃了，服务启动后对比一下两个文件的数据，发现不一致就进行回滚
   3. 先写binlog的话  然后崩溃  redolog没写  事务不生效  但是binlog有了 ，可以发现数据库的数据和根据日志恢复出来的数据不一致。
3. 聊聊索引？
   1. 索引是什么呢？ 索引就是一种能够高效的获取数据的一种数据结构。
   2. 聚簇索引和非聚簇索引：聚簇又名主键索引，主键索引叶子节点存储了该行数据，非主键索引叶子节点存储的是 主键id
   3. 唯一索引： 内存中只有一个
   4. 联合索引： 最左前缀   多列字段组成的联合索引
   5. 索引有几种类型： B+树 索引    hash索引    普通索引、 唯一索引、联合索引
4. 聊聊Sql优化？
   1. 通过explain 关键字查看sql的执行计划, 执行计划可以看到 sql扫描了多少行数据，同时有一个 extra 字段,里面有一些值 可以看到是否使用了索引， 如果是 use index 就是使用了索引，use where 就是没有使用到索引， use filesort 代表排序的字段没有增加索引，然后建立一些合适的索引,然后再通过执行计划检查是否走了索引，以及扫描行数是否降低了。
   2. 然后也可以拆分大查询
   3. 避免在查询的时候对索引字段进行计算或者使用函数。
5. Mysql事务的实现以及原理？https://cloud.tencent.com/developer/article/1431307
   1.  原子性： 是通过 undo log 来实现的。  undolog 记录了事务修改之前的信息,如果事务出现了异常回滚的情况,会根据undolog 将其恢复称修改之前的数据,保证了数据的原子性。
   2.  一致性性：一致性是通过 原子性、隔离性、持久性、同时作用保证了数据的一致性，从一个一致性的状态转移到另一个状态下。
   3.  隔离性：通过读写锁机制以及MVCC，  读写锁呢就是 读锁的话就是共享锁 可以同时读取读锁，写锁的话就是排它锁，会排斥其他获取锁的请求，MVCC的话就是每行记录都隐藏的两个列  一个是事务ID  一个是指向undolog的上个版本的数据。 然后可以根据事务ID的大小，来判断当前版本的数据可见性。从而保证隔离性。
   4.  持久性： redo log 记录了事务的提交信息,并将其持久化到磁盘中。其实现的了事务的持久性。
6. Mvcc实现的原理是什么？https://github.com/NotFound9/interviewGuide/blob/master/docs/MySQLNote.md
   1. 首先呢MVCC主要适用于可重复读，解决幻读的问题，innodb解决幻读的问题主要是通过MVCC解决的。
   2. 每行记录上有两个字段 一列是事务ID，一列是回滚指针。
   3. 当事务A在查询过程中,事务B修改了该行记录，在可重复读隔离级别下，会根据回滚指针读取 去undolog中寻找事务开始时的快照数据。
7. Mysql锁有哪些？
   1.  行锁：   包括共享锁S 锁和排它锁 X锁  ， S锁支持多个事务读取一行数据  但不能被修改    排它锁  只能当前事务修改这行数据  其他事务不行
   2. 记录锁：  对单挑索引记录的锁定 ， 防止插入  删除  修改
   3. 间隙锁    gap锁： 间隙锁会对记录之间的间隙进行加锁，防止数据插入    比如某个字段的值有4 有 6   间隙锁可以是对 4 到6之间的间隙进行加锁。
   4. next-key 锁：next-key锁就是会锁记录以及记录之间的间隙， 就是record lock 和 gap lock 的组合，会对索引记录加记录锁以及索引记录之前的间隙。
8. 当前读和快照读？
   1. 当前读其实就是读取的实时的数据，而不是快照数据，读的时候会加 next-key 锁  锁住当前的记录以及两个区间的间隙，这样读的时候就不能往我们的查询范围内插入数据了。
   2. 快照读的话，就是普通的select 查询，也就是读取的数据是事务刚开始那个状态的数据，普通读的幻读问题是通过MVCC来解决的。
9. Mysql不可重复读是怎么实现的？
   1. 通过MVCC 
10. Mysql底层采用什么树什么存储的？
    1. B+树 ，  B+树是什么样的结构，B+树是一个 M阶多路平衡树以及叶子节点是由双向链表构成的。   B+树的非叶子节点是索引节点,只存储索引节点的值不存储数据 ,叶子节点存储数据。 这样的话  数据页能够存储更多的索引节点，来使得相同的空间 B+就能够存储更多的值。
11. 红黑树是什么？
    1. 红黑树是一个平衡二叉树，有以下几个性质：
       1. 根节点和叶子节点都是黑色的，
       2. 红色节点的子节点必须是黑色，也就是不能有两个红色的节点连续。
       3. 
       4. 根节点到叶子节点的所有路径的包含的黑色节点个数是一致的。  所以根节点到叶子节点的最长路径《= 最短路径的两倍。
       5. 红黑树不是严格意义上的平衡二叉树，因为平衡二叉树要求任何节点的左右子树的高度差 《=1 ，红黑树根节点到叶子节点的最长路径会《=最短路径的两倍，他是大致意义上的平衡树。
       6. 红黑树的插入   搜素 删除效率比平衡二叉树 效率更高。
    2. B+ 与红黑树的比较？
       1. 更少的查找次数， 平衡树的查找时间复杂度与树高有关，B+树的多路，查找的次数更少。
       2. B+树中存储的叶子节点在内存中是连续的。 磁盘预读性,在内存中是相邻的。读取次数更少。
       3. B+树能够存储更多的索引节点。
12. Mysql死锁实践？
13. Mysql覆盖索引通过执行计划能看到哪几个？
14. 设计数据库表的思路？
    1. 根据产品原型设计出业务实体，并看是否一个业务实体能够满足业务  不能满足的话就用多个业务实体，然后看用哪个字段能够把有关联的业务实体关联起来。
    2. 然后考虑字段的长度，字段的类型
    3. 然后看业务上哪些字段是经常要进行查询和关联的，加好索引。

##### Mq

1. ​	Mq是什么？
   1. 是消息中间件。
2. RabbitMQ 大体结构
   1. 由 Broker --  代表消息队列服务器
   2. Exchange -  消息换机器：  指定消息按照什么规则，路由到哪个队列
   3. Queue：  消息队列   消息会被投入到一个或者多个队列。
   4. Binding:  绑定：  作用就是 将 交换器和队列按照路由规则绑定起来
   5. Routing key  ： 路由key   exchange  通过路由key进行消息投递。
   6. Vhost： 虚拟的broker，可以进行隔离。
   7. 由 交换器  队列  路由key  能决定一个从 Exchange 到 Queue的唯一路线。
3. RabbitMQ的工作模式？
   1. 发布订阅模式： 绑定到此交换机的每个队列，都能够收到消息。
   2. 路由模式：  topic ->  交换机根据key 的规则模糊匹配到对应的队列，由队列的监听消费者接收消息消费。
4. 如何保证MQ消息的顺序性？
   1. 可以在业务代码中去保证。有序的操作  用一个消息体去包装。  拆分多个队列，每个队列一个 consumer
5. 消息如何分发？
   1. 通过轮询的方式发送给消费者。  
6. 消息咋么路由？
   1. 生产者-》路由-》消息拥有一个路由key， 然后呢这个路由key 将交换器和队列绑定了起来， 消息到交换器后，交换器通过这个key去与他绑定的队列的路由key去进行匹配，匹配到了 就投送的对应的队列中。
   2. fanout： 交换器收到消息：会广播到所有绑定的队列上。
   3. direct：路由key 完全匹配，才回去投送
   4. topic: 使得来自不同源头的消息能够到达一个队列，使用topic交换器，可以使用通配符。
7. 消息基于什么传输？
   1. 通过信道：  Channel   是建立与TCP连接内的虚拟连接，且每条TCP连接上的信道数量没有限制。
8. 如何保证消息不被重复消费？
   1. 做幂等校验即可。  消息中可以传一个幂等key  DB做一个校验 -- 判断这个是否已经消费完成
9. 如何保证消息正确的发送至MQ，如果确保消息接收方消费了消息？
   1. 信道可以设置成 confirm 模式， 发送方确认模式。  所有在信道上发布的消息会被指派一个唯一ID
   2. 消息被投递到目的队列后，或者写入磁盘后， 信道会发送一个确认给生产者，包含了唯一ID。
   3. 发送方确认模式是异步的。生产者应用程序有个回调方法用来确认消息
10. 如何确保接口放收到了消息？
    1. 消费者接受每条消息后都必须进行确认。 只有消费者确认了消息，MQ才能安全的把消息从队列中删除
    2. RabbitMQ 是通过Consumer的连接是否中断来确认是否需要重新发送消息，只要连接不中断 - mq给consumer 足够长的时间处理消息。
11. 如何保证MQ可靠传输？
    1. 首先消息不可靠就几种情况： 
       1. 生产者丢失消息
       2. 消息列表丢失消息
       3. 消费者丢失消息
    2. 生产者丢失消息： 可以通过 生产者的 confirm 模式--  如果消息投递成功的话 会发送一个ACK给生产者，失败的话会发送一个Nack 消息
    3. 消息对垒丢失数据：可以进行消息持久化
    4. 消息丢失消息：一般是自动确认模式，然后消费失败了 才会导致消息丢之，开启手动确认模式， 然后处理成功后  手动确认消息。 或者,异常了存入DB。

Dubbo 分为几层？

- serve   服务层：   对应的接口以及服务的实现。
- config 配置层：  dubbo的相关配置、 比如注解以及xml配置
- proxy 代理层：  主要为生产者和消费者提供代理对象，提供过滤接口以及各种扩展点
- Registy  注册中心层：
- cluster   集群层： 主要负责  负载均衡以及路由等
- 监控层：
- 协议层：
- 数据交换层： exchange
- 数据传输层：
- 序列化层：


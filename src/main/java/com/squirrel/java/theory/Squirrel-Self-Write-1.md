## Squirrel  - Self - Write

#### Introduce Self

- 我是18年的毕业的,目前工作三年了,19年加入的自如到现在,主要负责了两个系统,评价系统和会议系统。
  - **评价系统**呢就是一个给公司所有业务线的评价场景提供评价能力的有一个平台,核心的评价流程就是:  
    - **业务线创建评价单**
    - **评价中台返回评价链接给业务线**
    - **业务线将评价链接或者评价列表展示给用户**
    - **用户进行评价-评价数据落入评价中台**
    - **评价中台发送评价完成的消息通知业务线该用户的某个评价已经完成。**
  - 然后呢这个项目是我接触的最深的项目,因为来自如的时候就进行该项目的重构啊以及中台化建设,并完成了将公司所有业务线的评价进行了接入。完成了评价数据的统一口径与来源。
  - **会议系统**呢主要就是给公司所有业务人员提供的一个晨会的线上平台,提供了一些业务的基础数据指标以及业务人员每日必做的事项（每日一题以及每日工单处理,收出房数据等等这些）,来聚焦管家每日该做的事情。为公司的核心目标进行提效。
- 平常用的技术栈就是项目里所用的这些:**SpringBoot + Mysql + Redis + Dubbo + Zk + RabbitMq + Es + Mongo**

#### Evaluate

- **评价系统介绍**
  - 评价系统的业务背景呢就是,自如之前的评价数据不统一,自如有好多业务线么,长租,资管(自如寓/自如驿等),服务线(自如的搬家/保洁/维修等),之前每个业务线都有评价的业务,但是呢评价的功能都是每个业务线自己维护的,就类似于每个系统呢有一套自己的评价系统。
  - 后来公司要统一管理评价数据,就做了现在的这个评价中台,这个评价中台是基于之前长租的评价系统改进重构,技术背景之前的是Oracle数据库,公司要进行去O,从而进行去O操作,并不断接入新的评价场景。
  - 当前的评价系统主要有几个模块:
    - 首先呢项目结构就是  评价API服务 + 评价DUBBO服务提供者 + 评价定时任务服务  + 评价后台服务 
    - 第一个就是数据模型,现在评价系统的数据模型是基于评价问题模板来进行设计的。首先呢是评价场景,场景下会有多个评价模板,我们可以根据该评价单的城市以及被评对象的分类或者评价人的用户画像以及被评人的用户画像等等去路由到不同的模板,说白了其实就是一个用户在去进行一个评价的时候可能会展示不同的问题。(而之前的评价系统一个评价场景对应一套问题,不利于评价问卷的快速迭代与扩展,也不利于数据的统计,)
    - 第二个就是评价系统抛弃之前APP原生页面,而是改用为H5页面,这样的话其实就是不依赖app发版时间,从而达到更快的迭代,更方便的让业务线进行对接,如果业务线要接入评价场景,可以直接使用评价系统提供的H5,而业务线只需要进行一个创建评价单的操作,就能够让用户进行一套完整的评价流程。
    - 第三个就是评价系统的数据存储: 使用Mysql,并用Sharding-JDBC进行分表,以及使用Es存储评价数据,来达到可以存储大量的评价数据以及快速的进行评价数据的检索功能。
    - 第四个就是评价后台管理系统,对评价场景以及评价模板的灵活化配置,无需研发的操作,即可以完全达到产品和业务的自主配置就能对接一个评价场景,以及评价数据的各种方式的检索以及低分评价的一个处理回访等,以及一些统计报表。
- **评价系统相关指标**
  - 接入业务线：  长租、自如寓、自如驿、保洁、搬家、维修、职能。   9个业务线
  - 接入场景:  调研问卷、
  - 分表数量:  16
  - 单表数量:  1000万
  - 评价数据总量:  16 * 1000万 =  1.6亿
  - 目前每天评价单数据量: 10万, 月单量300万,年单量 3600万,可以支撑5年左右
  - 系统QPS:  总体来说不是很大,毕竟是房子评价之类的。
- **系统的难点**:
  - 数据模型的设计以及场景的配置？
    - 如何能够尽最大程度的满足业务的目标以及更多地业务需求？
      - 做到不同评价问卷按照一定的规则进行不同的适配（根据城市、物品种类、被评人或者评价人的用户画像标签）
      - 以及某个评价问卷中问题按照一定的规则进行展示。 比如配置了多个MOT问题,随机展示两个或者1个。
      - 这样的话可以做到更精准的评价数据运营,针对更细粒度的被评对象,拿到用户的评价,然后再去对这些评价进行分析,这种更精细的问题可以更有效的找到业务上的痛点。
  - 数据迁移？ 分表
    - 平滑的进行数据迁移（不停机）
    - 第一阶段:主分表数据源同时写数据,以及将主表的历史数据写入分表数据源,并校验两个数据源的数据是否一致（但是事务模型以主表为准）
    - 第二阶段:主分表数据一致,仍然同时写入数据,并校验两个数据源的数据是否一致,(此时事务模型以分表为准)
    - 第三阶段:某些业务方依赖我们的主表数据源,等她们完全切换成我们的分表数据源,（数据平台跑我们的表出统计数据），我们最终下掉主表。
  - 系统QPS？
- **主要表结构**
  - 评价单表
  - 评价人表
  - 被评对象表
  - 被评人表
  - 被评非人表

#### Jvm

- **Java内存结构有哪些？**
  - 堆: 对象主要存在的位置。
  - 虚拟机栈: 每个方法的执行会在虚拟机栈创建一个栈桢,并对应着入栈以及出栈的过程。
  - 本地方法栈: 与虚拟机栈类似,不过是jdk提供的本地方法,由C++实现
  - 方法区: 存储类的元信息,静态变量,运行时常量池等
  - 程序计数器: 记录每个线程的下一个指令的地址。CPU在进行时间片切换的时候,线程会交替执行,当一个线程暂停后要继续执行的时候需要知道下一步指令的地址。
- **类的加载机制？**
  - 按需加载,第一次使用该类的时候进行加载。
  - 装载,链接,解析,初始化。
  - 采用的是双亲委托加载机制。JDK 提供的几个类加载器,顶级加载器  BootStrapClassLoader,ExtensionClassLoader,AppClassLoader, 当加载一个类的时候,通过当前的类加载器逐层向上找到父类加载器,首先由父类加载器进行加载,如果加载不成功,那么由父类加载器在逐层向下找到加载器进行加载,这样就可以保证一个类只能被加载一次。
- **什么打破了双亲委派机制？**
  - SPI机制.JDBC的类的实现是由不同的厂商来开发的,JDK默认的父类加载器加载不到,所以直接使用应用程序加载器直接进行加载。
  - Tomcat的类加载机制: Tomcat是一个web容器,可以包含不同的web项目,不同web项目依赖的相同限定类名的版本不同,如果用JDK默认的类加载器,相同限定类名类只能加载一个,web项目中的依赖的版本不同所以是不可行的。
- **new一个对象发生了什么？** https://www.cnblogs.com/JackPn/p/9386182.html
  - 判断类是否已经被加载,如果没有没加载首先进行加载
  - 在堆中分配内存空间
  - 对所有实例变量赋默认值
  - 执行实例初始化代码,然后执行构造方法
- **如何确定一个对象是否可以被回收**？
  - 引用计数法:如果该对象有一个引用进行+1计数,循环引用可以解决 ,但是多线程环境下要进行同步操作,性能比较低。
  - 可达性分析法:GCROOT(栈中的引用变量,方法区的静态变量等),查找引用这些变量的对象。
- **垃圾收集算法有哪些**？
  - 标记-清除:  标记完成后进行清理,而不整理内存空间,可能会存在不连续的空间
  - 标记-整理: 
  - 复制算法: 分代收集中的年轻代。
- **CMS垃圾回收机制**？
  - https://tech.meituan.com/2020/11/12/java-9-cms-gc.html
  - https://www.jianshu.com/p/2a1b2f17d3e4
  - 初始标记:Stop The World。 标记出GCRoot出关联的对象（这些对象是不可进行回收的）
  - 并发标记:GC线程和用户线程同时执行。针对初始标记的对象在根据这些对象引用的对象的一个标记
  - 重新标记:Remark,Stop the world。重新标记,避免并发标记的时候修改了对象之间的引用关系。
  - 并发清理: 针对不可达的对象进行一个垃圾回收。
- **JVM参数**  http://www.51gjie.com/java/551.html
- 调优:  个人中心项目(GC日志)

#### Java

- **HashMap**: 	 **hashMap底层是数组+链表+红黑树**

1. 计算key的hashCode,并将其无符号右移16位,对高低位进行一个异或运算,避免低位相同造成hash冲突。
2. 判断数组是否为空,如果为空进行第一次扩容也就是初始化,如果指定了集合容量,那么就取于该容量嘴接近的2的n次幂的整数,作为集合的容量
3. 根据hashCode与数组长度  n-1  相当于  hashCode % n 进行位运算,的到数组的下标。
4. 再判断当前数组的下标该位置是否有节点,如果没有那么就插入一个节点。如果有节点,判断当前插入的key是否与该节点的key是否相同,如果相同则返回,判断当前节点属于链表节点还是树节点,如果是链表节点那么遍历这个链表,并插入到链表尾部,如果是树节点,按照红黑树的节点插入逻辑进行插入。如果链表节点个数大于到8,那么转换成红黑树。
5. 判断当前集合元素是否到达了集合的阈值,如果超过了那么就进行扩容操作。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       

- **ConcurrentHashMap**:

1. 校验key和value的值不能为空
2. 计算key的hashCode, 判断数组为空,如果为空进行第一次扩容,扩容的时候通过cas保证只有一个线程进行扩容。通过一个集合大小的控制变量进行判断。
3. 通过hashCode与数组长度-1进行与运算计算出该节点在数组中的下标,并判断该下标处是否有节点,如果无节点,那么通过cas设置该新节点。
4. 如果不为空判断是否处于扩容阶段,并进行协同迁移。（协同迁移如何迁移？）
5. 否则使用synchronize锁定头结点。如果是链表就插入到链表尾部。如果是红黑树节点就按照红黑树的插入逻辑插入到红黑树中。如果链表长度到8的时候那么进行链表转红黑树的操作。
6. 对集合元素的大小进行+1操作.

- **hashmap的长度总是设置为2的整数次幂的原因？**
  1. 因为hashmap计算hashCode的时候,总是将hashCode的高16位与低16位进行异或运算得到hash值,这样可以保留高位的特征,避免某些key的低位相同,造成hash冲突。
  2. 同时数组下标的计算方式是: hashCode 与 n-1进行位运算,其实就是相当于 hashCode与n进行取余计算,这个公式只有在n为2的整数次幂时才正确。而位运算在计算机中运算更快。
- **hashmap 扩容后是否需要进行 rehash？**
  1. 1.8之后不需要进行rehash。下标的计算方式是通过hash值与数组长度取模进行计算,hashmap扩容都是变为之前的2倍,这样的话,当hash值与数组长度-1进行位运算的时候,只需要多看一位,看hash值与1的位运算结果。如果为1,那么该元素在新数组中的下标位置为  之前的index+之前的数组长度。如果为0,那么该元素在数组中的下标位置不变。
-   **为什么链表长度为8的时候进行红黑树的转换？**
  1. hashmap中节点分布遵循泊松分布,链表长度超过8的概率极低。
  2. 在链表长度较短的时候时间复杂度和红黑树没什么区别。
  3. 红黑树的空间占是链表的两倍。
- **Hashmap 与ConcurrentHashMap的区别**？
  - hashmap 线程不安全、key value 可以为null、
  - concurrent 线程安全、key value 不能为null、
- **LinkedHashMap？**
  - 底层也是HashMap 不过每个节点有两个指针,指向前一个节点和后一个节点,形成一个双向链表。
  - accessOrder 实现了按照插入顺序以及访问顺序。 实现了LRU。
- **ArrayList和LinkedList**
  - ArrayList 底层是一个Object数组。默认数组长度为0,添加第一个元素的时候会初始化一个数组长度为10的数组,后面如果元素超过数组长度,那么进行扩容,新数组的容量为原来的1.5倍。
  - LinkedList底层使用的是双向链表,每个节点保存了指向前驱节点和后继节点的指针,初始化时,不执行任何操作,添加第一个元素时,再去构造链表中的节点。

#### Lock

- **CAS**
  
  - CAS涉及三个操作数:
    - 读写内存的地址
    - 该内存的地址的原值
    - 想替换的新值
  - 当传入的期望值与该内存的地址的值相同时,原子的将该地址的值替换成新值。
  
- **CAS** **的缺点**
  - ABA问题,一个线程对该内存地址的进行修改,此时有另一个线程对其进行了修改,并改回来了原先的值,此时这个线程还是能对该内存地址成功的进行修改,而不知道有其他线程已经对该内存地址进行了操作。
  - 自旋操作,长时间不成的话会消耗CPU。
  - 只能对一个共享变量进行操作。

- **Synchronzied**
  - Synchronized是Java提供的一个关键字,既是一个同步锁。1.6之前其是一个重量级锁，使用时会直接使用操作系统底层的互斥锁,比较耗费性能。jdk1.6之后对其进行一系列的优化,synchronized具有了偏向锁,轻量级锁,重量级锁这几种形态。每个对象的对象头中包含了一个MarkWord,包含了对象的GC年龄,hashCode,线程ID,偏向锁标识,锁标记等。
  - 偏向锁:某个线程去获取锁时候,将自己的线程ID通过Cas设置到锁对象中,如果设置成功,代表获取到偏向锁,如果下次该线程再次获取这把锁的时候,比较锁对象中的线程ID是否和该线程的线程ID相同,如果相同那么直接拿到这把锁,否则进行锁的升级。
  - 轻量级锁: 某个线程获取锁的时候会将锁对象的markword 复制到自身的lockRecord上,然后在通过cas将锁对象的markword替换成自身的锁记录,如果替换成功.那么证明获取到轻量级锁,否则会进行一个适应性自旋来获取锁,如果一段时间后仍然获取不到,那么就升级为重量级锁。
  - 重量级锁:(调用操作系统底层的互斥锁进行同步操作)每个对象都有一个monitor监视器对象,并且存在几个队列。 
    - 竞争队列: 如果存在多个竞争锁线程,其是先进后出的一个队列。
    - 候选队列:  获取到锁的线程会从竞争队列尾部选取一个线程进入候选队列,并指定某一个线程去竞争锁,与未入队进行自旋获取锁的线程互相竞争。
    - 等待队列: 调用对象的wait方法会进入等待队里。
    - 竞争锁线程: OnDeck
  
- **ReentrantLock**
  
  - 是JDK提供的一个锁工具类,基于AQS实现的。
  - 加锁流程？
    - Aqs中有一个state变量,标识锁的状态,ReentrantLock在加锁时候,通过cas将state变量从0变为1,如果cas操作成功,并设置当前线程ID,证明获取锁成功。
    - 如果cas失败,在进行一次获取锁,并判断是否是锁重入,如果是当前锁冲入那么将state加1,获取锁成功
    - 如果再次获取锁失败,那么加入到等待队列,进行阻塞等待。Lock.Support.
  
- **Synchronzied 和 ReentrantLock区别？**
  
  - Synchronized 是非公平锁,ReentrantLock支持公平锁以及非公平锁。
  - Synchronized是jdk提供的一个关键字,RenntrantLock是java并发包下提供的类。
  - Synchronized在线程竞争激烈的情况下没有ReentrantLock高。
  
  - Synchronized 一直堵塞到获取到锁,ReentrantLock可以设置一个超时时间进行尝试获取锁。
  - ReentrantLock可以进行响应中断,synchronized不行。
  
- **谈谈你对AQS的理解？**
  
  - AQS其实就是JDK提供的一个抽象队列同步器,可用于实现基于先进先出的等待队列的锁和同步器的框架,比如ReentrantLock、FutureTask、CountDownLatch等都是基于其实现的,该抽象类实现了线程的入队,出队等操作,所以我们只需要实现获取锁的逻辑,以及释放锁的逻辑即可。
  
- **读写锁以及底层实现**？

  - https://pdai.tech/md/java/thread/java-thread-x-lock-ReentrantReadWriteLock.html
  - https://www.huaweicloud.com/articles/13733556.html

#### Redis

- Redis**有哪些结构**？
  - string: 动态字符串, 预分配空间,维护了一个字节数组,分配了一定的空间,减少内存的频繁分配.字符串长度小于1M时,扩容是翻倍的现有空间,大于1M,扩容是扩展1MB的空间。
  - hash: 类似于java中的hashmap,基于数组+链表的结构。
  - list: 列表类似于java中 LinkedList,注意其是链表而不是数组。意味着ist的插入和删除操作非常快。
  - set: set集合,类似于java中的hashset,内部实现也是一个字典,每一个value是一个null
  - zset: 有序列表,  跳表。 类似于SortSet和HashMap的结合体。一方面它是一个set,保证了内部value的唯一性,另一方面value设置一个分值,用来进行排序。  单链表的某些节点的上层增加一些索引节点。
  
- **Redis过期key是如何清理的？**
  - 惰性清理:在访问key的时候,发现其已经过期,那么将其删除
  - 定时清理: 每次遍历所有的DB,从DB的过期字典里随机筛选出20个key,如果超过25%的key已经过期,那么继续对这个db进行清理,否则对下一个DB进行清理。
  - 内存不够时候进行清理:
    - 直接报错
    - 从所有结果集中进行淘汰:
      - 随机淘汰算法
      - LFU算法,使用频率最低的key。
      - LRU算法,最近最久未使用的key进行清理。
    - 从淘汰列表中进行淘汰:
      - ~~
  
- **Zset是怎么执行查询操作的？**
  - Zset是基于跳跃表+字典实现的.
    - 如果只是单key查询,那么就直接从字典中进行查询.
    - 跳跃表查询,首先根据要查找节点的分数与顶层的节点的分数进行比较,不断索引查找索引节点的区间,一层一层的向下查找,直到找到与这个节点相同的节点
  
- **Redis为什么是单线程的以及为什么这么快？**https://www.jianshu.com/p/bc6904abc330
  - Redis是纯基于内存的,处理请求速度非常快,不需要使用多线程提高其的CPU利用率。CPU不会成为瓶颈。
  - 这里单线程指的是处理客户端发送的请求命令的处理器模块是单线程,而有些模块不一定是单线程的。
  - 只有IO才是影响Redis服务器性能的主要因素,而Redis采用了IO多路复用模型,尽量减少网络 I/O 的时间消耗。减少了线程的切换。
  - Redis的数据结构也是进行了一些优化的,例如动态字符串,是预分配的一些空间,避免修改时候进行扩容带来的开销,以及list使用压缩链表等减少内存占用。
  
- **Linux IO模型有哪些？**

  - BIO:阻塞IO,当用户态进程发出一个IO请求时,用户进程进行阻塞,内核态准备数据,进行阻塞等待,等内核态准备好数据后,将数据从内核拷贝到用户态,然后告知用户进程数据好了,然后返回。
  - NIO:非阻塞 IO,进程不断的询问内核,数据准备好了没有,知道内核准备好数据。
  - IO多路复用: 一个进程处理多个socket连接
  - 信息驱动IO: 内核准备好数据后,会给用户态发送一个信号,通知其准备好了,用户态在去请求,拿到数据
  - 异步IO模型: 数据在内核态拷贝到用户态之后,在通知用户态来处理数据,在复制数据到用户空间这个时间段内,用户态进程也是不阻塞的。

- **聊聊IO多路复用模型？**
  
  - 单个线程处理多个socket连接请求,减少系统开销,不必创建过多的线程。 
  
  - select：当 没有IO事件的时候,进程处于阻塞状态,当有IO事件时候,有一个代理（select和poll）去轮询的遍历所有Socket连接,来处理IO事件
  
    ​	select只能处理1024个链接,而poll无限,poll是基于链表来实现的。
  
  - poll：
  
  - epoll：epoll是基于事件驱动,通知进程那个socket连接有IO事件,不需要进行全部连接进行遍历,提高了查找效率。
  
- **Redis缓存穿透？**
  
  - 缓存穿透指的是攻击者故意大量的请求一些缓存中不存在的key,从而导致大量请求打入到DB,从而导致了DB崩溃。
    - 解决方案:
      - 参数校验（总会绕过这些参数进来） 
      - 对DB不存在的key也进行一个缓存,失效时间可以设置小一点,比如几秒钟,可以避免大量的请求打入DB。
  
- **Redis缓存击穿？**
  - 某个热点key失效造成了大量的请求打入DB。
    - 解决方案：
      - 每次请求的时候去判断缓存剩余时间,如果缓存剩余时间小于设置的缓存时间的一半去更新缓存。
      - 热点key,可以使用两个key例如A和B进行存储,两个key的缓存时间不同,如果A查不到去查B,同时在去更新两个key的缓存值。
  
- **Redis缓存雪崩?**
  - 缓存雪崩指的是大量的key失效,导致流量一次又一次的打进Redis服务器,导致Redis一直垮掉。
    - 解决方案:
      - 原有的失效时间上增加一个随机值,避免了采用相同的过期时间导致的缓存雪崩。
      - 熔断机制,当请求达到一个阈值的时候,直接返回。保证有一部分用户可用。
  
- **Redis缓存与数据库一致性问题如何解决？**
  - 延时双删: 先更新数据库,然后删除缓存,然后再启用一个异步线程进行延时删除缓存,保证缓存的值是最新的。
  
- **Redis持久化如何实现的？**
  - **AOF**:
    - 将Redis的操作命令追加写入到AOF文件中。
  - **RDB**:
    - RDB是在一定条件下.对这个数据库某个时间点所有的键值对信息生成一个压缩文件,然后将旧的删除,新的替换掉。
  
- **AOF和RDB的区别？**
  - AOF是保存了所有的执行修改命令,粒度更细,进行数据恢复的时候,恢复的数据更加完整,但是由于需要对所有的命令重新执行一遍,所以效率没有RDB的方式高。因为是所有的修改命令,所以同样的数据集,aof文件也会比RDB文件大一些。
  - RDB就是保存了某一个时刻DB所有的键值对的信息,恢复效率比较高。
  
- **AOF如何防止文件越来越大？**
  - 进行AOF重写,生成此刻的DB数据所需的写命令并写入AOF文件。生成期间,父进程可以正常进行处理请求,将命令写入aof_buf缓冲区,然后在将其写入到新的aof文件中,并原子的替换掉原先的AOF文件。
  
- AOF持久化方式？
  - 混合持久化,AOF文件前半段是RDB,后半段是AOF文件。

- Redis集群方案？https://github.com/NotFound9/interviewGuide/blob/master/docs/RedisUserful.md
  - 主从：全量同步,部分同步
  - 哨兵：运行在哨兵模式下的Redis服务器,核心功能是检测主节点和从节点的运行情况,如果主节点宕机,让某个从节点变更为主节点。
  - 集群：no know

- **跳跃表与平衡树,哈希表的比较？**
  - 时间复杂度：单key查找时,跳跃表和平衡树的查找时间复杂度 ologn,哈希表 o1.
  - 空间复杂度：平衡树的节点包含两个指针,跳跃表的节点指针与其节点有几层的概率相关。redis默认的跳表指针就是1.33。  1 / 3/4
  
- **为什么Mysql不是用跳跃表作为索引？**
  - 磁盘IO的开销,B+树的一般是2到4层,而跳表查找一个Score对应的位置需要进行log(n)次的操作,如果所有的索引节点都存在磁盘中,那么也就需要logn次的磁盘IO。
  
- **为什么平衡二叉树也不适合作为索引？**https://www.cnblogs.com/aspirant/p/9214485.html
  - 平衡二叉树指的是逻辑上的结构,而物理结构其实就是数组,逻辑结构上相近,但是物理结构上却不一定相近,当查找数据的时候,平衡二叉树可能会查出很多没有用的数据,会导致更多的磁盘IO,导致性能下降。
  
- **红黑树**？

  - 

#### Mysql

- ​	一条Sql语句执行发生了什么?
  - 连接器->分析器->优化器->执行器
  - 首先写undolog-记录下执行语句的回滚日志,用来MVCC,回滚。
  - 如果查找的目标数据存在于内存中。
    - Yes:
      - 判断是唯一索引还是普通索引
        - 唯一索引,判断唯一索引是否冲突并更新内存
        - 普通索引,直接更新内存
    - No: 磁盘
      - 唯一索引,从磁盘读到内存,判断冲突与否并更新
      - 普通索引,变更到changeBuffer
  - 写Redo log
  - 写bin log
  - 提交事务
  - 刷redo log盘
  - 刷bin log盘
- 聊聊索引？
  - 索引是一种对数据库表中一列或者多列数据进行排序的存储结构,能够通过索引快速的定位到数据中的某条数据。
  - Mysql中的索引分为聚簇索引和非聚簇索引。聚簇索引也就是主键索引,主键索引的叶子节点包含的时数据库某一行的数据,而非聚簇索引也就是二级索引,叶子节点存储的时主键的值。
  - Mysql有唯一索引、联合索引、普通索引。
    - 唯一索引:DB数据该字段的值时唯一的
    - 联合索引:多个字段组成一个索引,遵循最左前缀原则,遇到范围查询就停止
  - 覆盖索引: 查询的字段都在索引上,叫做覆盖索引,无需回表
  - 哪些字段需要建立索引？
    - 经常用作查询条件的
    - 与其他表相关联的字段
    - 需要排序,统计,分组的字段
  - 哪些字段不需要建立索引？
    - 区分度不高的字段
    - 数据量较少的表
- 聊聊Sql优化？
  - 首先我们在优化sql的时候要查询他的执行计划,通过explain语句,有一个extra字段
  - 如果是 use index证明使用索引,如果是use where 证明没有使用索引
  - use fileSort 代表排序的字段没有添加索引,结果集生成后在进行排序,可以在排序字段增加索引
  - 减少扫描行数,通过执行计划中扫描行数来添加合适的索引来减少扫描行数
  - join字段也要加索引,采用索引嵌套连接方式。
- Mysql事务的实现以及原理？https://cloud.tencent.com/developer/article/1431307
  - 事务的原子性是通过undolog来实现的
    - 回滚日志,如果有异常那么就执行回滚日志,返回之前的数据。
  - 事务的持久性是通过redolog来实现的
    - redo log是同步存储,而缓存同步是 随机操作也就是数据写入到文件中
    - 缓冲池,避免性能消耗
  - 事务的隔离性是通过读写锁+MVCC实现的
- Mvcc实现的原理是什么？https://github.com/NotFound9/interviewGuide/blob/master/docs/MySQLNote.md
  - Mysql每行数据有隐藏的两列,一列时事务ID,一列是回滚指针,指向undolog
  - 查询的时候,如果查询事务ID小于当前事务ID的时候,那么查询的时候就要通过unlog找到查询事务当时的数据,然后返回
- Mysql死锁实践？
  - b是唯一索引
  - 事务A
    - insert into  A (a,b) values (1,5);
    - insert into  A (a,b) values (2,6);
    - insert into  A (a,b) values (3,4);
  - 事务B
    - insert into  A (a,b) values (1,5);
    - insert into  A (a,b) values (2,6);
    - insert into  A (a,b) values (3,4);
  - 首先呢唯一索引冲突的时候唯一索引会升级为 Next-key锁,next-key锁是行锁+间隙锁
  - https://tech.meituan.com/2014/08/20/innodb-lock.html
- 设计数据库表的思路？
  - 首先根据我们的prd,原型图,找出某个业务对应的实体,来建立一张表,然后在考虑不同实体之间有什么联系,如果有联系的通过某一个字段进行关联。 例如用其中一个表的主键或者业务ID啊等
  
  - 然后考虑字段的类型呀,以及长度,根据业务场景确定字段的长度
  
  - 然后再就是考虑在经常查询的字段上建立合适的索引。
  
  - 然后再就是可以冗余的字段就冗余上,可以增加查询效率。（例如之前做过一个账单表中费用项,如果只存储费用项Code,还需要连表查询其名称,如果直接冗余,一次性就查出来了）
  
    

#### Mq

https://blog.csdn.net/ThinkWon/article/details/104588612

- **Mq有哪些优点**？
  - 异步:  异步通讯
  - 解耦:  系统之间解耦,无序关心其他系统的处理
  - 削峰:  通过消息长度来控制请求量
- **Mq的问题**?
  - 顺序消费？
    - 在业务层面上保证业务顺序
  - 重复消费？
    - 幂等Key解决
- **RabbitMq 基本概念？ 主要载体**
  - Broker:消息队列服务器实体
  - Exchange:交换器
  - Queue:队列
  - Bindkey:  交换器和队列通过绑定key进行绑定
  - Routingkey: 通过routingkey,交换器可以知道路由到哪里队列中
- 路由类型？
  - fanout：如果交换器收到消息，将会广播到所有绑定的队列上
  - direct：如果路由键完全匹配，消息就被投递到相应的队列
  - topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符    * 代表一个  #代表多个
- 设计MQ思路
  - 持久性-刷磁盘
  - 可用性-集群架构
  - 性能- 如何通讯

#### Dubbo

- Dubbo是什么？
  - Duubo是一个分布式服务框架。
- Dubbo服务注册流程？
  - ServiceBean 里有一个Spring事件回调,在Spring容器启动的时候进行回调,首先通过ServiceConfig 解析出Dubbo标签中的属性,并拼装成一个URL
  - 然后通过Dubbo的代理工厂生成一个Invoker,Invoker中包含了url和接口地址。
  - 然后将Invoker转换成Exporter, 然后进行服务的注册,启动Server,创建Zk节点,注册到Zk上。
- Dubbo服务引用流程？
  - 根据config信息从注册中心订阅服务,首次全量缓存到本地,后续会动态的监听更新到本地
  - 根据prodiver的地址和接口信息连接到服务端server,创建client,并创建invoker
  - 通过invoker生成代理对象，用于进行远程调用
- Dubbo负载均衡算法？		
  - 加权随机算法
    - 随机
  - 最小活跃数算法
    - 服务提供者内部维护了一个活跃数,每一个请求过去活跃数进行加1,请求结束后活跃数减1
  - 一致性hash算法
- Dubbo的分层？
  - 大体上就是3层
    - Biz ： 提供者和消费者
    - RPC: RPC调用的核心层,对整个RPC的调用过程,负载均衡，集群容错,代理
    - Remoting:对网络传输协议和数据转换的封装

#### Zookeeper

- 分布式服务

#### Es

- 倒排索引：正常的我们的索引都是通过ID对应列,倒排索引呢就是通过列对应ID,比如这个列里面有你好这个两个字,可能ID 1,10,20,50这些记录上的这个列中都有你好,那么就用你好  对应这些ID

#### Apollo

- **Apollo 动态配置的原理？**
  - 基于http长轮询和spring扩展机制实现的,apollo通过自己定义的一些BeanPostprocessor 将 包含 @Value注解的bean注册到apollo自己定义的注册表中，配置如果一旦发生了变化,apollo会根据配置的key找到对应的bean然后修改bean的属性。
  - 客户端和服务端保持了一个长连接,从而能够第一时间获得配置更新的推送
  - 客户端也会定时从apollo上拉取应用最新的配置
  - 客户端会把从服务端拉取的配置保存在本地一份

#### Spring  

- **SpringBoot启动过程？**https://zhuanlan.zhihu.com/p/115029344
  - 首先会调用SpringApplication.run方法,构建出一个SpringApplication实例,在构造器确定当前web应用类型。设置一些监听器监听SpringApplication启动过程。执行run方法。
  - 然后创建一个StopWatch计时器,统计run方法的启动耗时
  - 创建一个applicationContext,可以理解为applicationContext是一个高级容器,BeanFactory是其中的一个属性,我们一般获取Bean是通过applicationContext来获取。
  - 然后会调用prepareContext方法,将运行时参数封装成Bean,注册到BeanFactory中去。
  - 然后执行refreshContext方法 ,在这里会启动容器,为BeanFactory做很多配置,注册BeanPostProcessors,设置类加载器等。
  - 然后再执行afterRefresh方法,会把ApplicationRunner和CommandLineRunner自定义的子类的Bean全部拿取出来,执行他们的run方法。
- Bean的生命周期?
  - Bean的实例化阶段
  - 属性赋值阶段
  - Bean的初始化阶段
  - Bean的销毁阶段
- Spring IOC如何解决循环依赖的问题？
  - IOC只能解决属性注入之间的循环依赖,不能解决构造器
  - 首先呢Spring 提供了3个map存储Bean,我们也称之为三级缓存
  - 一级缓存:存放已经实例化好的Bean
  - 二级缓存:存放的是没有完全创建好的Bean,bean刚刚构造完成,没有进行属性天成
  - 三级缓存:存放的是正在创建中的Bean,便于有机会创建代理对象,此时的bean是没有完成属性填充的
  - 假设A依赖B,B依赖A,初始化A的 时候,发现没有三个缓存中都没有A这个实例,那么去初始化A这个实例并存入到三级缓存,走到A需要B那步,那么去加载B,B同事添加到三级缓存,B需要A就从三级缓存中取出A,这样B就完成了属性填充,并存入到二级缓存中,然后对B进行初始化,初始化完成后放入1级缓存中,然后A从一级缓存中获取到B,从而完成A进入二级依赖,A完全初始化完成后,A加入到一级缓存。
- SpringAOP？
  - Aop的实现关键在于代理模式,AOP代理主要分为静态代理和动态代理，
  - Spring使用的时动态代理：动态代理主要实现有两种,一种是JDK自带的动态代理,一种是Spring 的CGLIB代理。
  - JDK的有接口的实现,并实现InvocationHandler来进行代理的实现
  - CGLIB通过继承的方式进行代理的实现
- Spring 设计模式？
  - 工厂模式:  工厂模式
  - 单例模式:  Spring Bean
  - 代理模式:  Spring AOP
  - 模板方法:  JDBCTemplate,RedisTemplate
  - 观察者模式:定义对象间一种一对多的依赖关系,当一个对象的状态发生改变的时候,所有依赖它的对象都会的到通知被制动更新,如Spring中listener的实现-ApplicationListener
- Spring框架中有哪些不同类型的事件？
  - 上下文更新事件  ContextRefreshEvent
  - 上下文开始事件  ContextRefreshEvent
  - 上下文停止事件 
  - 上下文关闭事件
- Spring事务传播行为有哪些？https://segmentfault.com/a/1190000020386113
  - 为什么会有传播机制？

    - Spring不同服务之间会互相调用,比如方法A有事务,方法B有事务,方法A中存在方法B,那么这种情况下事务如何处理。

  - 传播机制生效条件

    - Spring是使用AOP来代理事务控制的,是针对接口和类的,所以在同一个Service类中两个方法的调用,事务的传播机制是不生效的。

  - 传播行为：

    - propagation_required (默认): 支持当前事务,如果当前无事务,则新建一个事务。如果当前存在事务,则加入当前事务,合并成一个事务
    - requires_new： 新建事务,如果当前存在事务,则把当前事务挂起,这个方法独立提交事务,不受调用者的影响,父级异常,也会正常提交。
    - Nested:当前存在事务,将会成为父级事务的一个子事务,方法结束后并没有提交,只有等父级事务结束后才提交,父级异常它会回滚
    - Supports:存在事务则加入事务,不存在事务,以非事务方式运行
    - Not_supported:非事务方式运行
    - Never:非事务方式运行,如果存在事务就异常。


#### Mongo:

- Mongo的特点?与mysql的区别？
  - MongoDB是文档型数据,文档实际上就是一个个json字符串。数据结构比较灵活,文档内的数据格式可以灵活改变,不固定。 不支持跨文档的事务。
- 分布式ID的实现？
  - 根据天的单位在mongo上创建文档,并有一个序列字段,如果是同一天该序列字段进行+1操作.findOnUpdate 方法,mongo保证线程安全的。返回至少四个序列。 最终前面再加上时间戳, 实现分布式ID。
  - 雪花算法:  将64位分割成多个部分, 由时间戳 和 机器ID以及序列数生成。

#### **实践**:

- 死锁：客户端存在并发提交的情况: 表中存在唯一索引（评价单号+问题编码）, 当唯一索引冲突的时候,第二个事务会将冲突的索引记录升级为next-key锁,next-key锁表示当前索引记录的锁定以及和前一个记录之间的间隙锁。 因为评价答案的顺序不是递增的,导致了唯一key冲突的时候,第一个事务插入到最后一个数据的时候,他的值位于事务二所持有的间隙锁之间,导致了死锁。 解决办法,提交评价前 将其排序后在进行提交。然后在排查为什么并发请求。
- OOM:评价记录导出。 ~~minor调大：有什么影响,减少minorGC时间,从而效率更高。~~
- Redis分布式锁以及可重入？
  - 可以使用Redis的hash结构，对应的key的hash结构记录当前线程的一个唯一标识 可以是UUID, 然后value可以存储锁次数。
- Redis限流:
  - key : export   value: exportPeopleNum  -- 通过lua脚本实现。
  - 评价后台导出时候由于业务同时导出大量的数据,导致后台服务器出现OOM,从而导致服务不可用。使用Redis加了导出操作的一个限制。一次允许多少人进行导出,一次能够导出的最大量是多少。
- JVM调优:
  - 个人中心： 4C8G   堆内存  5G
  - 查看GC日志的命令?
  - 之前优化过自如个人中心的项目,该项目集成了各个系统的api调用,每月我们都要梳理梳理系统中的慢请求来进行优化,发现请求量高峰的时候系统的整体响应就存在偏慢的情况,当时查看了系统各项指标的的大盘,看到了请求高峰期发生GC, 当时查看系统的GC日志, 我们项目使用的是CMS垃圾回收器,发现在重标记 Remark 阶段耗时1秒多,remark阶段我们都知道是暂停用户线程的,处理垃圾回收的线程其余线程全部挂起。所以我们的目的是要降低一下重标记这个阶段的时间。
  - 首先呢CMS分为四个阶段:
    - 初始标记  STW
    - 并发标记  
    - 重新标记: 重新标记要解决的问题呢就是并发标记时,用户线程可能对之前未标记到的对象进行了重新引用,防止在下一阶段被清理掉,所以这个过程暂停用户线程的,而且这个过程是以新生代中的对象来判断对象是否存活的, 也就是说重新标记需要扫描 （整个堆 新生代+老年代）,所以其实就是堆中的数量影响了Remark的时间。 
      - 为什么必须扫描整个堆？
        - 新生代的GC和老年代的GC是独立进行的,只有minor GC时,才会使用根搜索算法,标记新生代对象是否可达,有一些对象即使不可达,那么没有minorGC的话,还是不会标记为不可达,CMS没办法区分哪些对象是存活的。
    - CMS提供了一个参数是 CMSScavengeBeforeRemark,在重新标记之前强制执行一次minorGC。

#### 开放:

- **项目的迁移重构需要注意的东西**？
  - 首先是服务透传。 （老服务的API进行改造透传到新服务,并同时老流程的逻辑也不变,保证两个服务的数据源虽然表结构不同,但是都有该数据）
  - 两个服务之间同步异常的情况下: 看以哪个数据源为主,主数据源失败的情况下,另一个服务也不去执行相关逻辑。
  - 定时任务校验两个数据源的数据是否相同。
  - 灰度开关, 可以在新老逻辑之间切换 ,指定某个地区的少量流量进行执行新逻辑,并进行验证。
  - 回滚方案: 线上异常的情况下,如何做到快速回滚。 比如就是我前面说的开关
  - 上线时间: 夜间流量低的情况。
  - 上线前要经过充分测试。
  - 等这部分流量在线上跑的没有问题,就可以准备将查询流程和写入流程都切换为新服务的数据源。仍然保证双数据源写
  - 最后如果依赖老服务DB的业务线全都切换成新服务，那么就直接下调老服务的数据查写逻辑。
- 



​                                             

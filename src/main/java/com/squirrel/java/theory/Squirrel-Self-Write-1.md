## Squirrel  - Self - Write

#### Introduce Self

- 我是18年的毕业的,目前工作三年了,19年加入的自如到现在,主要负责了两个系统,评价系统和会议系统,当然也会做一些别的系统。
  - **评价系统**呢就是一个给公司所有业务线的评价场景提供评价能力的有一个平台,核心的评价流程就是:  
    - **业务线创建评价单**
    - **评价中台返回评价链接给业务线**
    - **业务线将评价链接或者评价列表展示给用户**（我们这面的评价入口由业务线去调用评价系统获取评价状态来进行展示,因为不同业务线的入口逻辑不同）
    - **用户进行评价-评价数据落入评价中台**
    - **评价中台发送评价完成的消息通知业务线该用户的某个评价已经完成。**
  - 然后呢这个项目是我接触的最深的项目,因为在这个项目上进行了重构啊,分表,以及中台化建设以及,并完成了将公司所有业务线的评价进行了接入。完成了评价数据的统一口径与来源。
  - **会议系统**呢主要就是给公司所有业务人员提供的一个晨会的线上平台,提供了一些业务的基础数据指标以及业务人员每日必做的事项（每日一题以及每日工单处理,收出房数据等等这些）,来聚焦管家每日该做的事情。为公司的核心目标进行提效。
- 平常用的技术栈就是项目里所用的这些:**SpringBoot + Mysql + Redis + Dubbo + Zk + RabbitMq + Es + Mongo**

#### Evaluate

- **评价系统介绍**
  - 评价系统的业务背景呢就是,自如之前的评价数据不统一,自如有好多业务线么,长租,资管(自如寓/自如驿等),服务线(自如的搬家/保洁/维修等),之前每个业务线都有评价的业务,但是呢评价的功能都是每个业务线自己维护的,就类似于每个系统呢有一套自己的评价系统。
  - 后来公司要统一管理评价数据,就做了现在的这个评价中台,这个评价中台是基于之前长租的评价系统改进重构,技术背景之前的是Oracle数据库,公司要进行去O,从而进行去O操作,并不断接入新的评价场景。
  -  当前的评价系统主要有几个模块:
    - 首先呢项目结构就是  评价API服务 + 评价DUBBO服务提供者 + 评价定时任务服务  + 评价后台服务 
    - 第一个就是数据模型,现在评价系统的数据模型是基于评价问题模板来进行设计的。首先呢是评价场景,场景下会有多个评价模板,我们可以根据该评价单的城市以及被评对象的分类或者评价人的用户画像以及被评人的用户画像等等去路由到不同的模板,说白了其实就是一个用户在去进行一个评价的时候可能会展示不同的问题。(而之前的评价系统一个评价场景对应一套问题,不利于评价问卷的快速迭代与扩展,也不利于数据的统计,)
    - 第二个就是评价系统抛弃之前APP原生页面,而是改用为H5页面,这样的话其实就是不依赖app发版时间,从而达到更快的迭代,更方便的让业务线进行对接,如果业务线要接入评价场景,可以直接使用评价系统提供的H5,而业务线只需要进行一个创建评价单的操作,就能够让用户进行一套完整的评价流程。
    - 第三个就是评价系统的数据存储: 使用Mysql,并用Sharding-JDBC进行分表,以及使用Es存储评价数据,来达到可以存储大量的评价数据以及快速的进行评价数据的检索功能。
    - 第四个就是评价后台管理系统,对评价场景以及评价模板的灵活化配置,无需研发的操作,即可以完全达到产品和业务的自主配置就能对接一个评价场景,以及评价数据的各种方式的检索以及低分评价的一个处理回访等,以及一些统计报表。
  - 标准化接口相关逻辑：
    - 创建评价单：
      - 评价单相关信息： 评价单归属地,评价单城市,评价单的开始和结束时间（可以由业务线自己制定）,幂等key,评价单来源,是否可进行回访等
      - 评价人相关信息：评价人uid 等。 异步补全评价人照片等信息。
      - 被评对象相关信息
        - 管家：管家Code,管家类型   --  评价存储快照信息   -- 异步补全当时管家的信息- 姓名啊  所属组织等等
        - 房子:   房源Code,房源类型  --  评价存储快照信息   -- 异步补全当时房源的信息  -- 房源地址 房源的产品类型等等
    - 查看评价问题  ：通过评价单号去查询评价问题。 创建评价单的时候根据 城市+场景+房源类型+管家类型+评价人类型 （有一个路由规则,确定一个评价模板） 
    - 评价模板是什么？
      - 评价模板就是类似异于一张问卷。  该模板上绑定了一些评价问题。 有星星  标签、mot 、多选、矩阵、文本  图片等问题。
      - 核心是,一个评价场景下有很多模板, 例如客户新签了要给客户推送个评价。 之前老系统是不管是哪个城市的新签,评价的问题都是一样的。然后有了模板的概念之后,就比如 不同城市或者几个城市对应一个模板。这样的话就能够针对性的给用户推送不同的问题。
      - 城市、产品、被评人类型、评价人类型  去做匹配。 （傻瓜式对接）
    - 提交评价：用户在页面选择答案进行提交
    - 查看详情：通过评价单号查询评价的详情.
    - 发送已评价消息：通过Mq  发送给业务线该评价的状态。  tipic 模式： routingkey 是 场景编号。 各自对接的业务线去消费这些数据。
  - 如何保证幂等key - 既然做了分表？
    - 我们的分表- 主要流程数据就是用评价单号进行分表。
    - 然后呢，还做了一个mapping表用来做  幂等key,uid 与评价单号的映射, 然后这个mapping的分区key 就是通过 幂等key和uid进行分区,然后通过有个字段代表这个key是属于 幂等key还是 uid，从而能够查询出评价单号，业务线创建评价单的时候,我们会首先根据幂等key 去该映射表查询是否生成过评价，如果生成过了  就把生成过的评价单号返给业务线。
- **评价系统相关指标**
  - 接入业务线：  长租、自如寓、自如驿、保洁、搬家、维修、职能。   9个业务线
  - 接入场景:  调研问卷、
  - 分表数量:  16
  - 单表数量:  1000万
  - 评价数据总量:  16 * 1000万 =  1.6亿
  - 目前每天评价单数据量: 10万, 月单量300万,年单量 3600万,可以支撑5年左右
  - 系统QPS:  总体来说不是很大,毕竟是房子评价之类的。  100 左右
- **系统的难点**:
  - 数据模型的设计以及场景的配置？
    - 如何能够尽最大程度的满足业务的目标以及更多地业务需求？
      - 做到不同评价问卷按照一定的规则进行不同的适配（根据城市、房屋类型、以及简单的智慧推评）
      - **智慧推评**：其实就是我们会收集用户低评的相关信息,
      - 以及某个评价问卷中问题按照一定的规则进行展示。 比如配置了多个MOT问题,随机展示两个或者1个。
      - 这样的话可以做到更精准的评价数据运营,针对更细粒度的被评对象,拿到用户的评价,然后再去对这些评价进行分析,这种更精细的问题可以更有效的找到业务上的痛点。
  - 数据迁移？ 分表
    - 平滑的进行数据迁移（不停机）
    - 第一阶段:主分表数据源同时写数据,以及将主表的历史数据写入分表数据源,并校验两个数据源的数据是否一致（但是事务模型以主表为准）
    - 第二阶段:主分表数据一致,仍然同时写入数据,并校验两个数据源的数据是否一致,(此时事务模型以分表为准)
    - 第三阶段:某些业务方依赖我们的主表数据源,等她们完全切换成我们的分表数据源,（数据平台跑我们的表出统计数据），我们最终下掉主表。
  - 系统QPS？
    - 100 QPS ~~ 
- **主要表结构**
  - 评价单表:    
  - 评价人表
  - 被评对象表
  - 被评人表
  - 被评房屋表

#### Jvm

- **Java内存结构有哪些？**
  - 堆: 对象主要存在的位置。
  - 虚拟机栈: 每个方法的执行会在虚拟机栈创建一个栈桢,并对应着入栈以及出栈的过程。
  - 本地方法栈: 与虚拟机栈类似,不过是jdk提供的本地方法,由C++实现
  - 方法区: 存储类的元信息,静态变量,运行时常量池等
  - 程序计数器: 记录每个线程的下一个指令的地址。CPU在进行时间片切换的时候,线程会交替执行,当一个线程暂停后要继续执行的时候需要知道下一步指令的地址。
- **类的加载机制？**
  - 按需加载,第一次使用该类的时候进行加载。
  - 装载,链接,解析,初始化。
  - 采用的是双亲委托加载机制。JDK 提供的几个类加载器,顶级加载器  BootStrapClassLoader,ExtensionClassLoader,AppClassLoader, 当加载一个类的时候,通过当前的类加载器逐层向上找到父类加载器,首先由父类加载器进行加载,如果加载不成功,那么由父类加载器在逐层向下找到加载器进行加载,这样就可以保证一个类只能被加载一次。
- **什么打破了双亲委派机制？**
  - SPI机制.JDBC的类的实现是由不同的厂商来开发的,JDK默认的父类加载器加载不到,所以直接使用应用程序加载器直接进行加载。
  - Tomcat的类加载机制: Tomcat是一个web容器,可以包含不同的web项目,不同web项目依赖的相同限定类名的版本不同,如果用JDK默认的类加载器,相同限定类名类只能加载一个,web项目中的依赖的版本不同所以是不可行的。
- **new一个对象发生了什么？** https://www.cnblogs.com/JackPn/p/9386182.html
  - 判断类是否已经被加载,如果没有没加载首先进行加载
  - 在堆中分配内存空间
  - 对所有实例变量赋默认值
  - 执行实例初始化代码,然后执行构造方法
- **如何确定一个对象是否可以被回收**？
  - 引用计数法:如果该对象有一个引用进行+1计数,循环引用可以解决 ,但是多线程环境下要进行同步操作,性能比较低。
  - 可达性分析法:GCROOT(栈中的引用变量,方法区的静态变量等),查找引用这些变量的对象。
- **垃圾收集算法有哪些**？
  - 标记-清除:  标记完成后进行清理,而不整理内存空间,可能会存在不连续的空间
  - 标记-整理: 
  - 复制算法: 分代收集中的年轻代。
- **CMS垃圾回收机制**？
  - https://tech.meituan.com/2020/11/12/java-9-cms-gc.html
  - https://www.jianshu.com/p/2a1b2f17d3e4
  - 初始标记:Stop The World。 标记出GCRoot出关联的对象（这些对象是不可进行回收的）
  - 并发标记:GC线程和用户线程同时执行。针对初始标记的对象在根据这些对象引用的对象的一个标记
  - 重新标记:Remark,Stop the world。重新标记,避免并发标记的时候修改了对象之间的引用关系。
  - 并发清理: 针对不可达的对象进行一个垃圾回收。
- **JVM参数**  http://www.51gjie.com/java/551.html
- 调优:  个人中心项目(GC日志)

#### Java

- **HashMap**: 	 **hashMap底层是数组+链表+红黑树**

1. 计算key的hashCode,并将其无符号右移16位,对高低位进行一个异或运算,避免低位相同造成hash冲突。
2. 判断数组是否为空,如果为空进行第一次扩容也就是初始化,如果指定了集合容量,那么就取于该容量嘴接近的2的n次幂的整数,作为集合的容量
3. 根据hashCode与数组长度  n-1  相当于  hashCode % n 进行位运算,的到数组的下标。
4. 再判断当前数组的下标该位置是否有节点,如果没有那么就插入一个节点。如果有节点,判断当前插入的key是否与该节点的key是否相同,如果相同则返回,判断当前节点属于链表节点还是树节点,如果是链表节点那么遍历这个链表,并插入到链表尾部,如果是树节点,按照红黑树的节点插入逻辑进行插入。如果链表节点个数大于到8,那么转换成红黑树。
5. 判断当前集合元素是否到达了集合的阈值,如果超过了那么就进行扩容操作。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       

- **ConcurrentHashMap**:

1. 校验key和value的值不能为空
2. 计算key的hashCode, 判断数组为空,如果为空进行第一次扩容,扩容的时候通过cas保证只有一个线程进行扩容。通过一个集合大小的控制变量进行判断。
3. 通过hashCode与数组长度-1进行与运算计算出该节点在数组中的下标,并判断该下标处是否有节点,如果无节点,那么通过cas设置该新节点。
4. 如果不为空判断是否处于扩容阶段,并进行协同迁移。（协同迁移如何迁移？）
5. 否则使用synchronize锁定头结点。如果是链表就插入到链表尾部。如果是红黑树节点就按照红黑树的插入逻辑插入到红黑树中。如果链表长度到8的时候那么进行链表转红黑树的操作。
6. 对集合元素的大小进行+1操作.

- **hashmap的长度总是设置为2的整数次幂的原因？**
  1. 因为hashmap计算hashCode的时候,总是将hashCode的高16位与低16位进行异或运算得到hash值,这样可以保留高位的特征,避免某些key的低位相同,造成hash冲突。
  2. 同时数组下标的计算方式是: hashCode 与 n-1进行位运算,其实就是相当于 hashCode与n进行取余计算,这个公式只有在n为2的整数次幂时才正确。而位运算在计算机中运算更快。
- **hashmap 扩容后是否需要进行 rehash？**
  1. 1.8之后不需要进行rehash。下标的计算方式是通过hash值与数组长度取模进行计算,hashmap扩容都是变为之前的2倍,这样的话,当hash值与数组长度-1进行位运算的时候,只需要多看一位,看hash值与1的位运算结果。如果为1,那么该元素在新数组中的下标位置为  之前的index+之前的数组长度。如果为0,那么该元素在数组中的下标位置不变。
-   **为什么链表长度为8的时候进行红黑树的转换？**
  1. hashmap中节点分布遵循泊松分布,链表长度超过8的概率极低。
  2. 在链表长度较短的时候时间复杂度和红黑树没什么区别。
  3. 红黑树的空间占是链表的两倍。
- **Hashmap 与ConcurrentHashMap的区别**？
  - hashmap 线程不安全、key value 可以为null、
  - concurrent 线程安全、key value 不能为null、
- **LinkedHashMap？**
  - 底层也是HashMap 不过每个节点有两个指针,指向前一个节点和后一个节点,形成一个双向链表。
  - accessOrder 实现了按照插入顺序以及访问顺序。 实现了LRU。
- **ArrayList和LinkedList**
  - ArrayList 底层是一个Object数组。默认数组长度为0,添加第一个元素的时候会初始化一个数组长度为10的数组,后面如果元素超过数组长度,那么进行扩容,新数组的容量为原来的1.5倍。
  - LinkedList底层使用的是双向链表,每个节点保存了指向前驱节点和后继节点的指针,初始化时,不执行任何操作,添加第一个元素时,再去构造链表中的节点。

#### Lock

- **CAS**
  
  - CAS涉及三个操作数:
    - 读写内存的地址
    - 该内存的地址的原值
    - 想替换的新值
  - 当传入的期望值与该内存的地址的值相同时,原子的将该地址的值替换成新值。
- **CAS** **的缺点**
  - ABA问题,一个线程对该内存地址的进行修改,此时有另一个线程对其进行了修改,并改回来了原先的值,此时这个线程还是能对该内存地址成功的进行修改,而不知道有其他线程已经对该内存地址进行了操作。
  - 自旋操作,长时间不成的话会消耗CPU。
  - 只能对一个共享变量进行操作。
- **Synchronzied**
  - Synchronized是Java提供的一个关键字,既是一个同步锁。1.6之前其是一个重量级锁，使用时会直接使用操作系统底层的互斥锁,比较耗费性能。jdk1.6之后对其进行一系列的优化,synchronized具有了偏向锁,轻量级锁,重量级锁这几种形态。每个对象的对象头中包含了一个MarkWord,包含了对象的GC年龄,hashCode,线程ID,偏向锁标识,锁标记等。
  - 偏向锁:某个线程去获取锁时候,将自己的线程ID通过Cas设置到锁对象中,如果设置成功,代表获取到偏向锁,如果下次该线程再次获取这把锁的时候,比较锁对象中的线程ID是否和该线程的线程ID相同,如果相同那么直接拿到这把锁,否则进行锁的升级。
  - 轻量级锁: 某个线程获取锁的时候会将锁对象的markword 复制到自身的lockRecord上,然后在通过cas将锁对象的markword替换成自身的锁记录,如果替换成功.那么证明获取到轻量级锁,否则会进行一个适应性自旋来获取锁,如果一段时间后仍然获取不到,那么就升级为重量级锁。
  - 重量级锁:(调用操作系统底层的互斥锁进行同步操作)每个对象都有一个monitor监视器对象,并且存在几个队列。 
    - 竞争队列: 如果存在多个竞争锁线程,其是先进后出的一个队列。
    - 候选队列:  获取到锁的线程会从竞争队列尾部选取一个线程进入候选队列,并指定某一个线程去竞争锁,与未入队进行自旋获取锁的线程互相竞争。
    - 等待队列: 调用对象的wait方法会进入等待队里。
    - 竞争锁线程: OnDeck
- **ReentrantLock**
  
  - 是JDK提供的一个锁工具类,基于AQS实现的。
  - 加锁流程？
    - Aqs中有一个state变量,标识锁的状态,ReentrantLock在加锁时候,通过cas将state变量从0变为1,如果cas操作成功,并设置当前线程ID,证明获取锁成功。
    - 如果cas失败,在进行一次获取锁,并判断是否是锁重入,如果是当前锁冲入那么将state加1,获取锁成功
    - 如果再次获取锁失败,那么加入到等待队列,进行阻塞等待。Lock.Support.
- **Synchronzied 和 ReentrantLock区别？**
  
  - Synchronized 是非公平锁,ReentrantLock支持公平锁以及非公平锁。
  - Synchronized是jdk提供的一个关键字,RenntrantLock是java并发包下提供的类。
  - Synchronized在线程竞争激烈的情况下没有ReentrantLock高。
  
  - Synchronized 一直堵塞到获取到锁,ReentrantLock可以设置一个超时时间进行尝试获取锁。
  - ReentrantLock可以进行响应中断,synchronized不行。
- **谈谈你对AQS的理解？**
  
  - AQS其实就是JDK提供的一个抽象队列同步器,可用于实现基于先进先出的等待队列的锁和同步器的框架,比如ReentrantLock、FutureTask、CountDownLatch等都是基于其实现的,该抽象类实现了线程的入队,出队等操作,所以我们只需要实现获取锁的逻辑,以及释放锁的逻辑即可。
- **读写锁以及底层实现**？

  - https://pdai.tech/md/java/thread/java-thread-x-lock-ReentrantReadWriteLock.html
  - 读写状态的设计：读写锁是在一个整型变量上通过高低位来区分读写锁的，读锁是高16位  写锁是低16位
  - 写锁的获取与释放：写锁首先获取state,若为0 表示此时没有读锁线程,在判断写线程是否应该被阻塞,然后在通过cas 进行加锁,然后返回, 如果不为0证明有读锁或者写锁,然后判断写锁如果为0 或者当前线程没有写锁那么直接返回,然后再 判断是否超出锁最大数,然后再设置锁状态 然后返回。
  - 读锁的获取与释放:  读锁是支持重入的共享锁,它能够被多个线程同时获取，首先判断写锁是否为0 并且当前线程没有占有写锁 直接返回,否则判断读线程是否需要被阻塞以及读锁数量是否小于最大值，然后设置状态成功,如果成功 ，判断读线程的数量是否为0 如果为0, 那么设置当前线程为第一个读线程, 线程数+1,判断当前 线程是否是第一个读线程,如果是++, 如果不是第一个线程 那么获取当前线程的一个计数器进行+1操作。 （ThreadLocal实现）
- **线程池设置**？
  - 参数： 核心线程、最大线程数、队列大小、线程存活时间、线程池拒绝策略。
  - 如何配置线程池的参数：
    - 主要是考虑两方面,看你的服务是CPU密集型还是  IO密集型
    - CPU ：  尽可能少的线程，Ncpu+1
    - IO： 尽可能多的线程, Ncpu*2.
    - 混合型: CPU密集型的任务与IO密集型任务的执行时间差别较小，拆分为两个线程池；否则没有必要拆分。
- **并发工具**？

#### Redis

- Redis**有哪些结构**？
  - string: 动态字符串, 预分配空间,维护了一个字节数组,分配了一定的空间,减少内存的频繁分配.字符串长度小于1M时,扩容是翻倍的现有空间,大于1M,扩容是扩展1MB的空间。
  - hash: 类似于java中的hashmap,基于数组+链表的结构。
  - list: 列表类似于java中 LinkedList,注意其是链表而不是数组。意味着ist的插入和删除操作非常快。
  - set: set集合,类似于java中的hashset,内部实现也是一个字典,每一个value是一个null
  - zset: 有序列表,  跳表。 类似于SortSet和HashMap的结合体。一方面它是一个set,保证了内部value的唯一性,另一方面value设置一个分值,用来进行排序。  单链表的某些节点的上层增加一些索引节点。
  
- **Redis过期key是如何清理的？**
  - 惰性清理:在访问key的时候,发现其已经过期,那么将其删除
  - 定时清理: 每次遍历所有的DB,从DB的过期字典里随机筛选出20个key,如果超过25%的key已经过期,那么继续对这个db进行清理,否则对下一个DB进行清理。
  - 内存不够时候进行清理:
    - 直接报错
    - 从所有结果集中进行淘汰:
      - 随机淘汰算法
      - LFU算法,使用频率最低的key。
      - LRU算法,最近最久未使用的key进行清理。
    - 从淘汰列表中进行淘汰:
      - ~~
  
- **Zset是怎么执行查询操作的？**
  - Zset是基于跳跃表+字典实现的.
    - 如果只是单key查询,那么就直接从字典中进行查询.
    - 跳跃表查询,首先根据要查找节点的分数与顶层的节点的分数进行比较,不断索引查找索引节点的区间,一层一层的向下查找,直到找到与这个节点相同的节点
  
- **Redis为什么是单线程的以及为什么这么快？**https://www.jianshu.com/p/bc6904abc330
  - Redis是纯基于内存的,处理请求速度非常快,不需要使用多线程提高其的CPU利用率。CPU不会成为瓶颈。
  - 这里单线程指的是处理客户端发送的请求命令的处理器模块是单线程,而有些模块不一定是单线程的。
  - 只有IO才是影响Redis服务器性能的主要因素,而Redis采用了IO多路复用模型,尽量减少网络 I/O 的时间消耗。减少了线程的切换。
  - Redis的数据结构也是进行了一些优化的,例如动态字符串,是预分配的一些空间,避免修改时候进行扩容带来的开销,以及list使用压缩链表等减少内存占用。
  
- **Linux IO模型有哪些？**

  - BIO:阻塞IO,当用户态进程发出一个IO请求时,用户进程进行阻塞,内核态准备数据,进行阻塞等待,等内核态准备好数据后,将数据从内核拷贝到用户态,然后告知用户进程数据好了,然后返回。
  - NIO:非阻塞 IO,进程不断的询问内核,数据准备好了没有,知道内核准备好数据。
  - IO多路复用: 一个进程处理多个socket连接
  - 信息驱动IO: 内核准备好数据后,会给用户态发送一个信号,通知其准备好了,用户态在去请求,拿到数据
  - 异步IO模型: 数据在内核态拷贝到用户态之后,在通知用户态来处理数据,在复制数据到用户空间这个时间段内,用户态进程也是不阻塞的。

- **聊聊IO多路复用模型？**
  
  - 单个线程处理多个socket连接请求,减少系统开销,不必创建过多的线程。 
  
  - select：当 没有IO事件的时候,进程处于阻塞状态,当有IO事件时候,有一个代理（select和poll）去轮询的遍历所有Socket连接,来处理IO事件
  
    ​	select只能处理1024个链接,而poll无限,poll是基于链表来实现的。
  
  - poll：
  
  - epoll：epoll是基于事件驱动,通知进程那个socket连接有IO事件,不需要进行全部连接进行遍历,提高了查找效率。
  
- **Redis缓存穿透？**
  
  - 缓存穿透指的是攻击者故意大量的请求一些缓存中不存在的key,从而导致大量请求打入到DB,从而导致了DB崩溃。
    - 解决方案:
      - 参数校验（总会绕过这些参数进来） 
      - 对DB不存在的key也进行一个缓存,失效时间可以设置小一点,比如几秒钟,可以避免大量的请求打入DB。
  
- **Redis缓存击穿？**     
  
  - 某个热点key失效造成了大量的请求打入DB。
    - 解决方案：
      - 每次请求的时候去判断缓存剩余时间,如果缓存剩余时间小于设置的缓存时间的一半去更新缓存。
      - 热点key,可以使用两个key例如A和B进行存储,两个key的缓存时间不同,如果A查不到去查B,同时在去更新两个key的缓存值。
  
- **Redis缓存雪崩?**
  - 缓存雪崩指的是大量的key失效,导致流量一次又一次的打进Redis服务器,导致Redis一直垮掉。
    - 解决方案:
      - 原有的失效时间上增加一个随机值,避免了采用相同的过期时间导致的缓存雪崩。
      - 熔断机制,当请求达到一个阈值的时候,直接返回。保证有一部分用户可用。
  
- **Redis缓存与数据库一致性问题如何解决？**
  
  - 原因：首先需要明白导致缓存与数据库不一致的情况:多个写请求的执行顺序不同导致脏数据,更新时正好有读请求,读请求取到旧数据然后更新上，或者数据库是读写分离的,在主库更新完之后,需要一定的时间,从库才能更新。
    - 延时双删: 先更新数据库,然后删除缓存,然后再启用一个异步线程进行延时删除缓存,保证缓存的值是最新的。
    - 定于binlog:通过阿里的canal来订阅Mysql中的更新操作,获取到指定的key然后进行缓存删除的操作，延时双删。 异常重试  Mq
  
- **Redis持久化如何实现的？**
  - **AOF**:
    - 将Redis的操作命令追加写入到AOF文件中。
  - **RDB**:
    - RDB是在一定条件下.对这个数据库某个时间点所有的键值对信息生成一个压缩文件,然后将旧的删除,新的替换掉。
  
- **AOF和RDB的区别？**
  
  - AOF是保存了所有的执行修改命令,粒度更细,进行数据恢复的时候,恢复的数据更加完整,但是由于需要对所有的命令重新执行一遍,所以效率没有RDB的方式高。因为是所有的修改命令,所以同样的数据集,aof文件也会比RDB文件大一些。
  - RDB就是保存了某一个时刻DB所有的键值对的信息,恢复效率比较高。
  
- **AOF如何防止文件越来越大？**
  
  - 进行AOF重写,生成此刻的DB数据所需的写命令并写入AOF文件。生成期间,父进程可以正常进行处理请求,将命令写入aof_buf缓冲区,然后在将其写入到新的aof文件中,并原子的替换掉原先的AOF文件。
  
- AOF持久化方式？
  - 混合持久化,AOF文件前半段是RDB,后半段是AOF文件。

- Redis集群方案？https://github.com/NotFound9/interviewGuide/blob/master/docs/RedisUserful.md
  - 主从：全量同步,部分同步
  - 哨兵：运行在哨兵模式下的Redis服务器,核心功能是检测主节点和从节点的运行情况,如果主节点宕机,让某个从节点变更为主节点。
  - 集群：no know

- **跳跃表与平衡树,哈希表的比较？**
  - 时间复杂度：单key查找时,跳跃表和平衡树的查找时间复杂度 ologn,哈希表 o1.
  - 空间复杂度：平衡树的节点包含两个指针,跳跃表的节点指针与其节点有几层的概率相关。redis默认的跳表指针就是1.33。  1 / 3/4
  
- **为什么Mysql不是用跳跃表作为索引？**
  - 磁盘IO的开销,B+树的一般是2到4层,而跳表查找一个Score对应的位置需要进行log(n)次的操作,如果所有的索引节点都存在磁盘中,那么也就需要logn次的磁盘IO。
  
- **为什么平衡二叉树也不适合作为索引？**https://www.cnblogs.com/aspirant/p/9214485.html
  - 平衡二叉树指的是逻辑上的结构,而物理结构其实就是数组,逻辑结构上相近,但是物理结构上却不一定相近,当查找数据的时候,平衡二叉树可能会查出很多没有用的数据,会导致更多的磁盘IO,导致性能下降。
  
- **红黑树**？

  - 

#### Mysql

- ​	一条Sql语句执行发生了什么?
  - 连接器->分析器->优化器->执行器
  - 首先写undolog-记录下执行语句的回滚日志,用来MVCC,回滚。
  - 如果查找的目标数据存在于内存中。
    - Yes:
      - 判断是唯一索引还是普通索引
        - 唯一索引,判断唯一索引是否冲突并更新内存
        - 普通索引,直接更新内存
    - No: 磁盘
      - 唯一索引,从磁盘读到内存,判断冲突与否并更新
      - 普通索引,变更到changeBuffer
  - 写Redo log
  - 写bin log
  - 提交事务
  - 刷redo log盘
  - 刷bin log盘
  
- **为什么要用二阶段提交机制**？

  - https://cloud.tencent.com/developer/article/1790507
  - 如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 
  - myql 执行一条语句时的时候 先写redo log  - （此时 redolog 标记为 prepare阶段）  在写 bin log   然后事务变为提交状态。
  - 如果写完redolog 后 失败了,那么对比binlog 没有 那么进行回滚 ,如果redolog 有  binlog 也有但是事务提交时候崩溃了，那么崩溃恢复的时候 对比两个文件中数据一致  那么将该事务进行提交。

- 聊聊索引？
  - 索引是一种对数据库表中一列或者多列数据进行排序的存储结构,能够通过索引快速的定位到数据中的某条数据。
  - Mysql中的索引分为聚簇索引和非聚簇索引。聚簇索引也就是主键索引,主键索引的叶子节点包含的时数据库某一行的数据,而非聚簇索引也就是二级索引,叶子节点存储的时主键的值。
  - Mysql有唯一索引、联合索引、普通索引。
    - 唯一索引:DB数据该字段的值时唯一的
    - 联合索引:多个字段组成一个索引,遵循最左前缀原则,遇到范围查询就停止
  - 覆盖索引: 查询的字段都在索引上,叫做覆盖索引,无需回表
  - 哪些字段需要建立索引？
    -  经常用作查询条件的
    - 与其他表相关联的字段
    - 需要排序,统计,分组的字段
  - 哪些字段不需要建立索引？
    - 区分度不高的字段
    - 数据量较少的表
  
- 聊聊Sql优化？
  - 首先我们在优化sql的时候要查询他的执行计划,通过explain语句,有一个extra字段
  - 如果是 use index证明使用索引,如果是use where 证明没有使用索引
  - use fileSort 代表排序的字段没有添加索引,结果集生成后在进行排序,可以在排序字段增加索引
  - 减少扫描行数,通过执行计划中扫描行数来添加合适的索引来减少扫描行数
  - join字段也要加索引,采用索引嵌套连接方式。 
  
- Mysql慢sql如何进行优化？
  - 通过explain关键字 看一下sql语句的执行计划,有个type属性,标记了语句使用了那种类型,是否走了索引。没有走索引的语句,看一下where语句中的字段看哪个字段比较适合加索引（区分度高,使用频率高）就加上。
  - 减少请求的数量:   可以只返回必要的列. * 改为需要的列
  - 减少表扫描的行数: 建立索引,对一些常用的条件作为查询字段,建立联合索引,使用联合索引,可以减少一些查询次数,也可以减少磁盘占用空间,而且当查询的字段在索引中包含时,就会用到覆盖索引。无需回表
  - 避免在查询时,对索引字段进行计算和使用函数, 使用函数的时候就不会通过索引查询
  - 切分大查询。
  
- Mysql事务的实现以及原理？https://cloud.tencent.com/developer/article/1431307
  - 事务的原子性是通过undolog来实现的
    - 回滚日志,如果有异常那么就执行回滚日志,返回之前的数据。
  - 事务的持久性是通过redolog来实现的
    - redo log是同步存储,而缓存同步是 随机操作也就是数据写入到文件中
    - 缓冲池,避免性能消耗
  - 事务的隔离性是通过读写锁+MVCC实现的
  
- Mvcc实现的原理是什么？https://github.com/NotFound9/interviewGuide/blob/master/docs/MySQLNote.md
  - Mysql每行数据有隐藏的两列,一列时事务ID,一列是回滚指针,指向undolog
  - 查询的时候,如果查询事务ID小于当前事务ID的时候,那么查询的时候就要通过unlog找到查询事务当时的数据,然后返回

- Mvcc实现的原理是什么？https://github.com/NotFound9/interviewGuide/blob/master/docs/MySQLNote.md
  - Mysql每行数据有隐藏的两列,一列时事务ID,一列是回滚指针,指向undolog
  - 查询的时候,如果查询事务ID小于当前事务ID的时候,那么查询的时候就要通过unlog找到查询事务当时的数据,然后返回
  
- Mysql锁有哪些？
  - 行锁:
    - 共享锁S锁,读锁,允许事务读一行数据,不能被修改。所以读锁之间不排斥  share in mode
    - 互斥锁X锁,写锁,只允许当前事务修改这条数据,其他事务不可以。  for update
    - next-key锁,锁当前记录以及该记录之前的间隙锁。
  - 间隙锁: gaplock
    - 对记录之间的间隙加锁,防止数据插入,为了防止读的过程中有新的数据插入,会对我们读的数据的左右区间进行加锁,防止其他事务插入数据,间隙锁之间是不排斥的。
  
- 当前读和快照读？
  - 快照读：也就是普通读,单纯的select语句,不包括 
    - select  for update 
    -  select lock in share mode
    - 利用MVCC机制来进行读取,并不会对锁记录进行加锁。是通过 undolog + MVCC来实现的
  - 当前读：就是读取的最新版本,并且对读取的记录进行加锁,（next-key 锁的方式 也就是行锁或者间隙锁）阻塞其他事务同事改动相同记录,避免出现相同问题。
  
- Mysql可重复读是怎么实现的？
  - MVCC 多版本并发控制：mysql的行数据有着隐藏的两列,一列是事务ID,一列是undolog,在可重复读的级别下,读取数据的时候,如果当前事务ID比查询事务的ID大,那么查询事务就要通过undolog找到查询事务ID的那一条记录快照,并查询到正确的值返回。
  
- Mysql底层采用什么树什么存储的？
  - B+树,B+树有什么特点？与B树有什么区别？
    - B+树一个多路平衡查找树,所有记录节点按照由小到大的顺序进行存储在最后一层的叶子节点上,并且由各叶子节点的指针相连接。可以认为每一个叶子节点就是一个内存页。B+树索引节点只存储索引值，不存储行的数据,这样的话可以让每个索引内存页存储更多的值,使得B+树的层数更少。
    - B+树所有数据都在叶子节点上,所以查询也会更稳定,也更适合区间查找。
  
- Mysql死锁实践？
  - b是唯一索引
  - 事务A
    - insert into  A (a,b) values (1,5);
    - insert into  A (a,b) values (2,6);
    - insert into  A (a,b) values (3,4);
  - 事务B
    - insert into  A (a,b) values (1,5);
    - insert into  A (a,b) values (2,6);
    - insert into  A (a,b) values (3,4);
  - 首先呢唯一索引冲突的时候唯一索引会升级为 Next-key锁,next-key锁是行锁+间隙锁
  - https://tech.meituan.com/2014/08/20/innodb-lock.html
  
- Mysql覆盖索引通过执行计划能看到哪几个？

- 设计数据库表的思路？
  - 首先根据我们的prd,原型图,找出某个业务对应的实体,来建立一张表,然后在考虑不同实体之间有什么联系,如果有联系的通过某一个字段进行关联。 例如用其中一个表的主键或者业务ID啊等
  - 然后考虑字段的类型呀,以及长度,根据业务场景确定字段的长度
  - 然后再就是考虑在经常查询的字段上建立合适的索引。
  - 然后再就是可以冗余的字段就冗余上,可以增加查询效率。（例如之前做过一个账单表中费用项,如果只存储费用项Code,还需要连表查询其名称,如果直接冗余,一次性就查出来了）
  
- 红黑树是什么？

  - 红黑树是一个平衡的二叉查找树。有以下几个性质：
  
    1.根节点和叶子节点都是黑色的（这里的叶子节点指的是普通的节点增加的一个黑色的空节点）。
  
    2.红色节点的子节点必须是黑色的，也就是不能有两个红色节点连续。
  
    3.黑色的节点可以连续，但是从根节点到叶子节点的所有路径包含的黑色节点的个数是一致的。(所以**根节点到叶子节点的最长路径<=最短路径的两倍**)
  
    红黑树是二叉查找树（也就是每个节点的左子树<当前节点的值，右子树所有节点>=当前节点值），但不是严格意义上的平衡二叉树，因为平衡二叉树要求任何节点的左右子树高度差是<=1，红黑树根节点到叶子节点的最长路径会<=最短路径的两倍,所有他是大致意义上的平衡树。
  
    相比于AV树（也就是自平衡的二叉查找树，左右子树高度差不超过1），红黑树插入，删除效率更高。因为不需要保证绝对的平衡，任何不平衡需要的旋转次数不超过3次，即便在最坏的情况下，红黑树能够以O(log(N))的时间复杂度进行搜索、插入、删除操作。
  
    ##### 与红黑树的比较
  
    红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，主要有以下两个原因：
  
    （一）更少的查找次数
  
    平衡树查找操作的时间复杂度和树高 h 相关，O(h)=O(logdN)，其中 d 为每个节点的出度。
  
    红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多，查找的次数也就更多。
  
    （二）利用磁盘预读特性
  
    为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。而B+数中存储的叶子节点在内存中是相邻的，这样可以读取会快一些。
  
    （三）存储更多的索引节点
  
    B+树跟B树的区别就是B+是叶子节点存储数据，非叶子节点(也就是索引节点)只存储索引项，B树是所有节点都存储数据，而每个节点都是磁盘的一个内存页，内存页大小是固定，B+树的每个索引节点可以容纳的索引值更多，与B树相比，B+树的层数更少。
  
  

#### Mq

https://blog.csdn.net/ThinkWon/article/details/104588612

- **Mq有哪些优点**？
  - 异步:  异步通讯
  - 解耦:  系统之间解耦,无序关心其他系统的处理
  - 削峰:  通过消息长度来控制请求量
- **Mq的问题**?
  - 顺序消费？
    - 在业务层面上保证业务顺序
  - 重复消费？
    - 幂等Key解决
- ​	Mq是什么？
  1. 是消息中间件。
- RabbitMQ 大体结构
  1. 由 Broker --  代表消息队列服务器
  2. Exchange -  消息换机器：  指定消息按照什么规则，路由到哪个队列
  3. Queue：  消息队列   消息会被投入到一个或者多个队列。
  4. Binding:  绑定：  作用就是 将 交换器和队列按照路由规则绑定起来
  5. Routing key  ： 路由key   exchange  通过路由key进行消息投递。
  6. Vhost： 虚拟的broker，可以进行隔离。
  7. 由 交换器  队列  路由key  能决定一个从 Exchange 到 Queue的唯一路线。
- RabbitMQ的工作模式？
  1. 发布订阅模式： 绑定到此交换机的每个队列，都能够收到消息。
  2. 路由模式：  topic ->  交换机根据key 的规则模糊匹配到对应的队列，由队列的监听消费者接收消息消费。
- 如何保证MQ消息的顺序性？
  1. 可以在业务代码中去保证。有序的操作  用一个消息体去包装。  拆分多个队列，每个队列一个 consumer
- 消息如何分发？
  1. 通过轮询的方式发送给消费者。  
- 消息咋么路由？
  1. 生产者-》路由-》消息拥有一个路由key， 然后呢这个路由key 将交换器和队列绑定了起来， 消息到交换器后，交换器通过这个key去与他绑定的队列的路由key去进行匹配，匹配到了 就投送的对应的队列中。
  2. fanout： 交换器收到消息：会广播到所有绑定的队列上。
  3. direct：路由key 完全匹配，才回去投送
  4. topic: 使得来自不同源头的消息能够到达一个队列，使用topic交换器，可以使用通配符。
- 消息基于什么传输？
  1. 通过信道：  Channel   是建立与TCP连接内的虚拟连接，且每条TCP连接上的信道数量没有限制。
- 如何保证消息不被重复消费？
  1. 做幂等校验即可。  消息中可以传一个幂等key  DB做一个校验 -- 判断这个是否已经消费完成
- 如何保证消息正确的发送至MQ，如果确保消息接收方消费了消息？
  1. 信道可以设置成 confirm 模式， 发送方确认模式。  所有在信道上发布的消息会被指派一个唯一ID
  2. 消息被投递到目的队列后，或者写入磁盘后， 信道会发送一个确认给生产者，包含了唯一ID。
  3. 发送方确认模式是异步的。生产者应用程序有个回调方法用来确认消息
- 如何确保接口放收到了消息？
  1. 消费者接受每条消息后都必须进行确认。 只有消费者确认了消息，MQ才能安全的把消息从队列中删除
  2. RabbitMQ 是通过Consumer的连接是否中断来确认是否需要重新发送消息，只要连接不中断 - mq给consumer 足够长的时间处理消息。
- 如何保证MQ可靠传输？
  1. 首先消息不可靠就几种情况： 
     1. 生产者丢失消息
     2. 消息列表丢失消息
     3. 消费者丢失消息
  2. 生产者丢失消息： 可以通过 生产者的 confirm 模式--  如果消息投递成功的话 会发送一个ACK给生产者，失败的话会发送一个Nack 消息
  3. 消息对垒丢失数据：可以进行消息持久化
  4. 消息丢失消息：一般是自动确认模式，然后消费失败了 才会导致消息丢之，开启手动确认模式， 然后处理成功后  手动确认消息。 或者,异常了存入DB。
- 消息队列的延时以及过期失效的问题？消息队列满了如何处理？ 有几百万的消息持续积压几小时，如何解决？
  - 消息队列积压：  先修复Consumer的问题，确保恢复速度，可以建多个队列与交换器进行绑定，以及消费者端配置并发消费。
- 设计MQ的思路？
  - 持久化消息
  - 服务器的高可用
  - 如何通讯

#### Dubbo

- Dubbo分了哪些层？
  - config dubbo配置层
  - proxy  dubbo 代理层
  - registry  注册中心层
  - cluster  路由层 负载均衡
  - monitor 监控层
  - transport  网络传输层
  - serialize   数据序列化层
  
- 服务的注册流程？
  - dubbo服务导出基于Spring容器发布刷新事件,Dubbo在接收到事件之后,会执行服务导出的逻辑。
  - 主要是三部分：
    - 第一部分就是检查检查参数,组装URL: 将配置在dubbo标签上的属性,按照url的格式拼装成一个url
    - 第二部分就是导出服务,包含导出服务到本地以及导出服务到远程,首先呢先创建一个Invoker,代表一个执行体,可以进行服务的调用,由dubbo提供的代理工厂创建一个invoker对象，里面包含了服务方法对象信息和具体的URL地址。然后再将invoker转换成Exporter,
    - 然后启动服务器server 监听端口
    - 最后 注册协议保存 Url和invoker的映射关系,注册到服务中心。
  
- 服务的发现流程？
  - 服务引用有两种方式,第一种是在ReferecnceBean的aferPropertiesSet方法时引用服务,第二个是在ReferenceBean对应的服务被注入到其他类中时引用。首先呢根绝config文件信息从注册中心订阅服务,首次会全量缓存到本地,后续的更新会监听动态更新到本地。
  - 接着 dubbo协议根据 provider的地址和接口信息连接到服务端server,开启客户端client,然后创建invoker
  - 然后为 invoker生成代理对象,用于远程调用provider,至此完成了服务引用
  
- Zookeeper 挂了dubbo还能用吗？有什么影响？
  - 能用,可以通过服务直连的方式绕过注册中心,但是不利于服务治理。宕机后不能够注册新服务。
  
- dubbo负载均衡有哪些？实现原理呢？
  - 加权随机:设置权重,并且相加,在这个和内 随机生一个随机数,判断在哪个区间。
  
  - 最小活跃数: 每个服务提供者都对应一个活跃数acitve,收到一个请求,活跃数+1,完成请求后活跃数-1.
  
  - 一致性哈希算法:
  
    - **1、映射Provider至Hash值区间中（实际中映射的是Invoker）；**
  
      **2、映射请求，然后找到大于请求Hash值的第一个Invoker。**
  
- dubbo是线程阻塞的吗？
  - 默认同步 支持异步
  
- dubbo一次调用的流程？
  - 消费者代理持有Invoker对象,使用Invoker进行调用
  - 通过调用服务目录获取远程服务的Invoker列表
  - 根绝负载均衡选择一个可以调用的Invoker
  - 经过消费者端的过滤器链
  - 在将请求发送到服务端
  - 服务端收到这个request请求,分配到线程池进行处理。
  - server处理这些req
  - 找到对应的服务接口并进行调用,将结果返回
  - // 白话文
    - 服务容器启动,加载,运行服务提供者
    - 服务提供者在启动的时候,向注册中心注册自己所提供的服务。
    - 服务消费者在启动时,向注册中心订阅自己所需的服务。
    - 注册中心将服务列表提供给消费者,如果有变更,那么将基于长连接推送变更数据给消费者。
    - 服务消费者,从服务提供者列表中,通过负载均衡算法，选一台进行调用,如果调用失败,那么再选另外一台。
  
- ##### 聊聊 Dubbo SPI 机制？

  SPI（Service Provider Interface）是一种服务发现机制。其实就是将结构的实现类写入配置当中，在服务加载的时候读取配置文件，加载实现类。这样就可以在运行的时候，动态帮助接口替换实现类。

  Dubbo 的 SPI 其实是对 Java 的 SPI 进行了一种增强,可以按需加载实现类之外，增加了 IOC 和 AOP 的特性，还有自适应扩展机制。

  SPI 在 dubbo 应用很多，包括协议扩展、集群扩展、路由扩展、序列化扩展等。

  Dubbo 对于文件目录的配置分为了三类：

  1. META-INF/services/ 目录：该目录下的 SPI 配置文件是为了用来兼容 Java SPI；
  2. META-INF/dubbo/ 目录：该目录存放用户自定义的 SPI 配置文件：key=com.xxx.xxx；
  3. META-INF/dubbo/internal/ 目录：该目录存放 Dubbo 内部使用的 SPI 配置文件。

- **Java SPI**

  Java SPI 在查找扩展实现类的时候遍历 SPI 的配置文件，并且将实现类全部实例化。

  **Dubbo SPI**

  1. 对 Dubbo 进行扩展不需要改动 Dubbo 源码；
  2. 延迟加载，可以一次只加载自己想要加载的扩展实现；
  3. 增加了对扩展点 IOC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点；
  4. Dubbo 的扩展机制能很好的支持第三方 IoC 容器，默认支持 Spring Bean。

**15 服务提供者能实现失效踢出是什么原理？**

服务失效踢出基于 Zookeeper 临时节点原理。

Zookeeper 中的节点是有生命周期的，具体的生命周期取决于节点的类型。节点主要分为持久（Persistent）节点和临时（Ephemeral）节点 。

#### Zookeeper

  https://zhuanlan.zhihu.com/p/345761223

   https://zhuanlan.zhihu.com/p/45728390

- Zookeeper是一个分布式应用程序协调服务，为分布式应用提供一致性服务的软件,提供的功能包括，配置维护，域名服务，分布式同步，组服务。

- Zookeeper 的特性？
  - 顺序一致性：从一个客户端发起的请求,最终将会严格的按照其发起的顺序被应用到zk中
  - 原子性：所有的事务请求的处理结果在集群中所有机器的应用情况是一致的。
  - 单一视图：无论连接哪个节点,看到的数据都是一致的。
  
- Zookeeper可以做什么？
  - 分布式服务的注册与订阅
    - 在分布式服务中,为了保证服务高可用,通常一个应用或者服务的提供方会部署多分,达到对等服务,而消费者就必须要在这些对等的服务器中选一个执行相关的业务逻辑。
  - 分布式配置中心
    - 发布订阅模型,将配置发布到Zk节点上,供订阅者获取数据,实现配置信息的集中式管理与动态更新
  - 命名服务, 例如服务名   通过服务名找到服务地址
  - 分布式锁：Zk强一致性,独占锁。   crate znode 方式来实现，最终成功创建的那个客户端也就拥有了这把锁。
  
- Zookeeper的工作流程？
  - 首先客户端连接Zk集群中的任何一个节点，可以使leader节点,也可是follower节点,一旦连接，节点会给客户端分配会话ID,并像客户端发送确认,如果客户端收到确认,那么连接成功,客户端会规律醒的发送心跳给zk
    - 客户端向zk发送读请求,节点会从数据库中找到这个节点的数据并返回
    - 客户端向zk发送写请求,节点会将znode路径发送到leader节点,leader会给该请求分配一个事物ID,然后通知从节点,从节点接收到消息后将该事务写入磁盘,然后主节点等待 ack相应,如果有过半以上的从节点相应后,认为该事务提交成功,然后给所有从节点发送commit消息,从节点接收到消息后,将该事务进行提交。（leader接受客户端的写请求后，会将请求通过队列发送个每个节点，每个节点收到消息后将记录写到磁盘， 并且返回ACK给leader，当半数以上的从节点返回ACK后，leader才commit这条更新。）
  
- Zookeeper Watch机制？

  - 客户端与服务端首先建立一个连接,然后去订阅某个节点或某些节点,如果节点数据发布变化的时候,服务端会通知客户端该节点发生了变化等等。

  - 服务端通知的就是一些Zk节点的变动时间类型,比如就是增加 删除 修改等,而不是推送结果。需要客户端主动的去拉取最新的节点信息。

  - ```java
      	    ZkClientWatcher zkClientWatcher = new ZkClientWatcher();
            zkClientWatcher.createConnection(CONNECT_ADDRES, SESSIONTIME);
            zkClientWatcher.createPath("/watcher","watcherData");
            zkClientWatcher.updateNode("/watcher","new Data");
            zkClientWatcher.zk.getChildren("/watcher",true);
            zkClientWatcher.createPath("/watcher/child","child");
            zkClientWatcher.deleteNode("/watcher/child");
            zkClientWatcher.deleteNode("/watcher");
    ```

#### Es

- 倒排索引：正常的我们的索引都是通过ID对应列,倒排索引呢就是通过列对应ID,比如这个列里面有你好这个两个字,可能ID 1,10,20,50这些记录上的这个列中都有你好,那么就用你好  对应这些ID

#### Apollo

- **Apollo 动态配置的原理？**
  - 基于http长轮询和spring扩展机制实现的,apollo通过自己定义的一些BeanPostprocessor 将 包含 @Value注解的bean注册到apollo自己定义的注册表中，配置如果一旦发生了变化,apollo会根据配置的key找到对应的bean然后修改bean的属性。
  - 客户端和服务端保持了一个长连接,从而能够第一时间获得配置更新的推送
  - 客户端也会定时从apollo上拉取应用最新的配置
  - 客户端会把从服务端拉取的配置保存在本地一份

#### Spring  

- **SpringBoot启动过程？**https://zhuanlan.zhihu.com/p/115029344
  
  - 首先会调用SpringApplication.run方法,构建出一个SpringApplication实例,在构造器确定当前web应用类型。设置一些监听器监听SpringApplication启动过程。执行run方法。
  
  
  
  - 然后创建一个StopWatch计时器,统计run方法的启动耗时
  - 创建一个applicationContext,可以理解为applicationContext是一个高级容器,BeanFactory是其中的一个属性,我们一般获取Bean是通过applicationContext来获取。
  - 然后会调用prepareContext方法,将运行时参数封装成Bean,注册到BeanFactory中去。
  - 然后执行refreshContext方法 ,在这里会启动容器,为BeanFactory做很多配置,注册BeanPostProcessors,设置类加载器等。
  - 然后再执行afterRefresh方法,会把ApplicationRunner和CommandLineRunner自定义的子类的Bean全部拿取出来,执行他们的run方法。
- Bean的生命周期?
  - Bean的实例化阶段
  - 属性赋值阶段
  - Bean的初始化阶段
  - Bean的销毁阶段
- Spring IOC如何解决循环依赖的问题？
  - IOC只能解决属性注入之间的循环依赖,不能解决构造器
  - 
  - 
  - 首先呢Spring 提供了3个map存储Bean,我们也称之为三级缓存
  - 一级缓存:存放已经实例化好的Bean
  - 二级缓存:存放的是没有完全创建好的Bean,bean刚刚构造完成,没有进行属性天成
  
  
  
  - 三级缓存:存放的是正在创建中的Bean,便于有机会创建代理对象,此时的bean是没有完成属性填充的
  - 假设A依赖B,B依赖A,初始化A的 时候,发现没有三个缓存中都没有A这个实例,那么去初始化A这个实例并存入到三级缓存,走到A需要B那步,那么去加载B,B同事添加到三级缓存,B需要A就从三级缓存中取出A,这样B就完成了属性填充,并存入到二级缓存中,然后对B进行初始化,初始化完成后放入1级缓存中,然后A从一级缓存中获取到B,从而完成A进入二级依赖,A完全初始化完成后,A加入到一级缓存。
- SpringAOP？https://cloud.tencent.com/developer/article/1692917
  - Aop的实现关键在于代理模式,AOP代理主要分为静态代理和动态代理，
  - Spring使用的时动态代理：动态代理主要实现有两种,一种是JDK自带的动态代理,一种是Spring 的CGLIB代理。
  - JDK的有接口的实现,并实现InvocationHandler来进行代理的实现
  - CGLIB通过继承的方式进行代理的实现
- Spring 设计模式？
  - 工厂模式:  工厂模式
  - 单例模式:  Spring Bean
  - 代理模式:  Spring AOP
  - 模板方法:  JDBCTemplate,RedisTemplate
  - 观察者模式:定义对象间一种一对多的依赖关系,当一个对象的状态发生改变的时候,所有依赖它的对象都会的到通知被制动更新,如Spring中listener的实现-ApplicationListener
- Spring框架中有哪些不同类型的事件？
  - 上下文更新事件  ContextRefreshEvent
  - 上下文开始事件  ContextRefreshEvent
  - 上下文停止事件 
  - 上下文关闭事件
- Spring事务传播行为有哪些？https://segmentfault.com/a/1190000020386113
  - 为什么会有传播机制？

    - Spring不同服务之间会互相调用,比如方法A有事务,方法B有事务,方法A中存在方法B,那么这种情况下事务如何处理。

  - 传播机制生效条件

    - Spring是使用AOP来代理事务控制的,是针对接口和类的,所以在同一个Service类中两个方法的调用,事务的传播机制是不生效的。

  - 传播行为：

    - propagation_required (默认): 支持当前事务,如果当前无事务,则新建一个事务。如果当前存在事务,则加入当前事务,合并成一个事务
    - requires_new： 新建事务,如果当前存在事务,则把当前事务挂起,这个方法独立提交事务,不受调用者的影响,父级异常,也会正常提交。
    - Nested:当前存在事务,将会成为父级事务的一个子事务,方法结束后并没有提交,只有等父级事务结束后才提交,父级异常它会回滚
    - Supports:存在事务则加入事务,不存在事务,以非事务方式运行
    - Not_supported:非事务方式运行
    - Never:非事务方式运行,如果存在事务就异常。
- Spring如何在运行时候通知对象？
  - 通过代理类包裹切面,Spring在运行的时候把切面啊织入到Spring管理的bean中,代理封装了目标类,并拦截被通知方法的调用,在把调用转发给真正的目标bean。当代理拦截到方法调用时,在调用目标bean方法之前,会执行切面逻辑。
- SpringMVC的执行流程？
  - 用户发送 请求到前端控制器 DispatcherServlet
  - DispatcherServlet收到请求后,调用HandlerMapping处理器映射器,请求获取handler
  - 处理器映射器根据请求url找到 具体的处理器handler 返回给DispatcherServlet
  - DispatcherServlet调用处理器适配器,请求执行handler
  - 经过适配调用,具体处理器进行处理业务逻辑,然后返回ModleAndView
  - 然后将ModelAndView返回给DispatchServlet
  - 然后DispatcherServlet 将其传给 ViewResolver 视图解析器进行解析
  - 解析后返回具体的View
  - 然后对View进行渲染,然后返回给用户。


#### Mongo:

- Mongo的特点?与mysql的区别？
  - MongoDB是文档型数据,文档实际上就是一个个json字符串。数据结构比较灵活,文档内的数据格式可以灵活改变,不固定。 不支持跨文档的事务。
- 分布式ID的实现？
  - 根据天的单位在mongo上创建文档,并有一个序列字段,如果是同一天该序列字段进行+1操作.findOnUpdate 方法,mongo保证线程安全的。返回至少四个序列。 最终前面再加上时间戳, 实现分布式ID。
  - 雪花算法:  将64位分割成多个部分, 由时间戳 和 机器ID以及序列数生成。

#### **实践**:

- 死锁：客户端存在并发提交的情况: 表中存在唯一索引（评价单号+问题编码）, 当唯一索引冲突的时候,第二个事务会将冲突的索引记录升级为next-key锁,next-key锁表示当前索引记录的锁定以及和前一个记录之间的间隙锁。 因为评价答案的顺序不是递增的,导致了唯一key冲突的时候,第一个事务插入到最后一个数据的时候,他的值位于事务二所持有的间隙锁之间,导致了死锁。 解决办法,提交评价前 将其排序后在进行提交。然后在排查为什么并发请求。
- OOM:评价记录导出。 ~~minor调大：有什么影响,减少minorGC时间,从而效率更高。~~
- Redis分布式锁以及可重入？
  - 可以使用Redis的hash结构，对应的key的hash结构记录当前线程的一个唯一标识 可以是UUID, 然后value可以存储锁次数。
- Redis限流:
  - key : export   value: exportPeopleNum  -- 通过lua脚本实现。
  - 评价后台导出时候由于业务同时导出大量的数据,导致后台服务器出现OOM,从而导致服务不可用。使用Redis加了导出操作的一个限制。一次允许多少人进行导出,一次能够导出的最大量是多少。
- JVM调优:
  - 个人中心： 4C8G   堆内存  5G
  - 查看GC日志的命令?
  - 之前优化过自如个人中心的项目,该项目集成了各个系统的api调用,每月我们都要梳理梳理系统中的慢请求来进行优化,发现请求量高峰的时候系统的整体响应就存在偏慢的情况,当时查看了系统各项指标的的大盘,看到了请求高峰期发生GC, 当时查看系统的GC日志, 我们项目使用的是CMS垃圾回收器,发现在重标记 Remark 阶段耗时1秒多,remark阶段我们都知道是暂停用户线程的,处理垃圾回收的线程其余线程全部挂起。所以我们的目的是要降低一下重标记这个阶段的时间。
  - 首先呢CMS分为四个阶段:
    - 初始标记  STW
    - 并发标记  
    - 重新标记: 重新标记要解决的问题呢就是并发标记时,用户线程可能对之前未标记到的对象进行了重新引用,防止在下一阶段被清理掉,所以这个过程暂停用户线程的,而且这个过程是以新生代中的对象来判断对象是否存活的, 也就是说重新标记需要扫描 （整个堆 新生代+老年代）,所以其实就是堆中的数量影响了Remark的时间。 
      - 为什么必须扫描整个堆？
        - 新生代的GC和老年代的GC是独立进行的,只有minor GC时,才会使用根搜索算法,标记新生代对象是否可达,有一些对象即使不可达,那么没有minorGC的话,还是不会标记为不可达,CMS没办法区分哪些对象是存活的。
    - CMS提供了一个参数是 CMSScavengeBeforeRemark,在重新标记之前强制执行一次minorGC。

#### 开放:

- **项目的迁移重构需要注意的东西**？
  - 首先是服务透传。 （老服务的API进行改造透传到新服务,并同时老流程的逻辑也不变,保证两个服务的数据源虽然表结构不同,但是都有该数据）
  - 两个服务之间同步异常的情况下: 看以哪个数据源为主,主数据源失败的情况下,另一个服务也不去执行相关逻辑。
  - 定时任务校验两个数据源的数据是否相同。
  - 灰度开关, 可以在新老逻辑之间切换 ,指定某个地区的少量流量进行执行新逻辑,并进行验证。
  - 回滚方案: 线上异常的情况下,如何做到快速回滚。 比如就是我前面说的开关
  - 上线时间: 夜间流量低的情况。
  - 上线前要经过充分测试。
  - 等这部分流量在线上跑的没有问题,就可以准备将查询流程和写入流程都切换为新服务的数据源。仍然保证双数据源写
  - 最后如果依赖老服务DB的业务线全都切换成新服务，那么就直接下调老服务的数据查写逻辑。
- 设计一个日志系统？（分布式）
  - 采集日志：使用哪种方式接入  sdk  （jar包） 规范日志格式等等？ 异步发送到消息中间件
  - 日志存储：可以使用Es进行存储,支持快速检索 （倒排索引）
  - 日志可视化管理： 
- 系统治理 （防止崩溃的）的手段有哪些？
  - 提交告警：通过异常日志进行告警，进行处理
  - 环境隔离： 生产部署两套环境
  - 重试策略： 调用外部接口进行重试 
  - 内部异常： 可进行降级处理。
- 操作系统中断？
  - 中断：处理器收到硬件或者软件通知的信号,提示发生了某个事件,应该被注意,这种情况就被称为中断。
  - 硬件中断：外中断：来自处理器以外的中断信号,包括时钟中断,键盘中断,外部设备中断等。  内中断：来自处理器内部的中断
  - 软件中断：CPU指令，用以自陷一个中断,由于软中断指令通常要运行一个切换CPU至内核态的子例程，
- 操作系统中的进程和线程的关系？ 
  - JDK1.2以后,JVM的线程采用了操作系统原生的线程模型,通过系统调用,将程序的线程交给了操作系统内核进行调度。Java线程的本质也就是操作系统中的线程。
  - JAVA线程的几种状态： 
    - 新生态：刚创建完未执行   Thread t  =    new Thread()
    - 就绪状态：  t.start()
    - 运行状态：  running
    - 阻塞状态：  wait  sleep  synchronized yield
    - 死亡状态:     dead
  - 进程的几种状态？
    - 因为在现在的操作系统中,线程依旧被视为轻量级进程,所以操作系统中线程的状态实际上和进程的状态是一致的。
    - ready：线程已经创建，等待系统调度分配CPU使用权
    - running：表示线程获得了CPU使用权,正在进行运算。
    - waiting：表示线程等待（挂起）,让出CPU资源给其他线程使用

#### 分布式：

- CAP：

  - C：一致性：所有节点访问同一份最新的数据副本

  - A：可用性：非故障节点在合理的时间内返回合理的响应

  - P：分区容错性：分布式系统出现网络分区的时候,仍能够对外提供服务

  - 如果发生分区以后 - 才去选择  CP还是AP

  - **为啥无同时保证 CA 呢？**

    举个例子：若系统出现“分区”，系统中的某个节点在进行写操作。为了保证 C， 必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。

- BASE：

  - **BASE** 是 **Basically Available（基本可用）** 、**Soft-state（软状态）** 和 **Eventually Consistent（最终一致性）** 三个短语的缩写。BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求。

    

​                                             

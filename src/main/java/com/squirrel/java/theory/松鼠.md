

## 	松鼠(Squirrel)

#### Introduce Self

- 面试官你好，我叫罗宝松,目前在自如工作。
-  我是18年的毕业的,工作三年了, 在自如主要负责了两个系统,一个是自如的评价系统和自如业务人员会议系统,当然也支持过一些别的系统 ,目标系统、交易系统、楼盘系统啊这些,但是对评价和会议比较熟悉。
  - 评价系统的定位是作为一个业务中台,主要核心就是提供评价能力以及评价数据处理能力。然后呢公司各个业务线去对接评价系统,用来实现他们业务场景下的一个评价功能。评价这个项目是我接触最深的一个项目,因为在这个项目上进行了系统的重构以及分表,还有中台化建设并完成了将公司所有业务线的评价场景进行了对接,完成了评价数据的统一口径与来源。
  - 会议系统呢主要就是给公司所有业务人员提供的一个晨会的线上平台,提供了一些业务的数据指标 （包含收出房的数据、以及客源数据、以及房屋库存数据等等 （目标管理、工单管理、会议纪要等））,方便经理开会的时候可以合理的为当前业务组确定一个目标以及为每个管家分配相应的工作,来聚焦管家每日该做的事情。
- 平常用的技术栈就是项目里所用的这些:**SpringBoot + Mysql + Redis + Dubbo + Zk + RabbitMq + Es + Mongo**

#### Evaluate

- **评价系统介绍**
  
  - 评价系统的业务背景呢就是,自如之前的评价数据不统一,自如有好多业务线,长租,资管(自如寓/自如驿等),服务线(自如的搬家/保洁/维修等),之前每个业务线都有评价的业务,但是呢评价的功能都是每个业务线自己维护的,就类似于每个系统呢有一套自己的评价系统。
  - 后来公司要统一管理评价数据,就做了现在的这个评价中台,这个评价中台是基于之前长租的评价系统改进重构,技术背景之前的是Oracle数据库,然后重构直接进行了去O。
  -  当前的评价系统主要有几个模块:
    - 项目结构就是  评价API服务 + 评价DUBBO服务提供者 + 评价定时任务服务  + 评价后台服务 
    - 第一个就是数据模型进行了改造::现在评价系统的数据模型是基于评价问题模板来进行设计的。首先呢是评价场景,场景下会有多个评价模板,我们可以根据该评价单的城市以及被评对象的分类或者评价人的用户画像以及被评人的用户画像等等去路由到不同的模板,说白了其实就是一个用户在去进行一个评价的时候会通过各种规则路由到一个评价模板上。(而之前的评价系统一个评价场景对应一套问题,不利于评价问卷的快速迭代与扩展,也不利于数据的统计,)
    - 第二个就是评价系统抛弃之前APP原生页面,而是改用为H5页面,这样的话其实就是不依赖app发版时间,从而达到更快的迭代,更方便的让业务线进行对接,如果业务线要接入评价场景,可以直接使用评价系统提供的H5,而业务线只需要进行一个创建评价单的操作,就能够让用户进行一套完整的评价流程。(如果想要新增一个类型的问题,如果是APP的话肯定要等下一个版本进行发版（因为我们APP有固定的发版时间,一般双周发一次),如果是H5的话就不需要等待APP的发版时间。直接生效
    - 第三个就是评价系统的数据存储: 使用Mysql,并用Sharding-JDBC进行分表,以及使用Es存储评价数据,来达到可以存储大量的评价数据以及快速的进行评价数据的检索功能。 
    - 第四个就是评价后台管理系统,对评价场景以及评价模板的灵活化配置,无需研发的操作,即可以完全达到产品和业务的自主配置就能对接一个评价场景,以及评价数据的各种方式的检索以及低分评价的一个处理回访等,以及一些统计报表。
  - 一套完整的评价流程？
    -  业务线调用评价的创建评价单接口-生成评价相关信息
    - 评价系统会返回给业务线一个去评价的链接。
    - 业务线拿到链接后返回给用户,提示用户去评价
    - 然后用户点击去评价的链接，就是从评价系统查看问题。（查看问题的部分有些逻辑-  根据城市、产品类型、被评人类型、以及当前被评人之前是否收过差评,如果收过差评继续推送之前的低分问题。）
  - 标准化接口相关逻辑：
    - 业务线创建评价单：
      - 评价单相关信息： 评价单归属地,评价单城市,评价单的开始和结束时间（可以由业务线自己制定）,幂等key,评价单来源,是否可进行回访等
      - 评价人相关信息：评价人uid 等。 异步补全评价人照片等信息。
      - 被评对象相关信息
        - 管家：管家Code,管家类型   --  评价存储快照信息   -- 异步补全当时管家的信息- 姓名啊  所属组织等等
        - 房子:   房源Code,房源类型  --  评价存储快照信息   -- 异步补全当时房源的信息  -- 房源地址 房源的产品类型等等
    - 查看评价问题  ：通过评价单号去查询评价问题。 创建评价单的时候根据 城市+场景+房源类型+管家类型+评价人类型 （有一个路由规则,确定一个评价模板） 
      - 评价模板是什么？
      - 评价模板就是类似异于一张问卷。  该模板上绑定了一些评价问题。 有星星  标签、mot 、多选、矩阵、文本  图片等问题。
      - 核心是,一个评价场景下有很多模板, 例如客户新签了要给客户推送个评价。 之前老系统是不管是哪个城市的新签,评价的问题都是一样的。然后有了模板的概念之后,就比如 不同城市或者几个城市对应一个模板。这样的话就能够针对性的给用户推送不同的问题。
      - 城市、产品、被评人类型、评价人类型  去做匹配。 （傻瓜式对接）
    - 提交评价：用户在页面选择答案进行提交
    - 查看详情：通过评价单号查询评价的详情.
    - 发送已评价消息：通过Mq  发送给业务线该评价的状态。  tipic 模式： routingkey 是 场景编号。 各自对接的业务线去消费这些数据。
  - 如何保证幂等key - 既然做了分表？
    - 我们的分表- 主要流程数据就是用评价单号进行分表。
    - 然后呢，还做了一个mapping表用来做  幂等key,uid 与评价单号的映射, 然后这个mapping的分区key 就是通过 幂等key和uid进行分区,然后通过有个字段代表这个key是属于 幂等key还是 uid，从而能够查询出评价单号，业务线创建评价单的时候,我们会首先根据幂等key 去该映射表查询是否生成过评价，如果生成过了  就把生成过的评价单号返给业务线。
    - 做了一个幂等key与评价单号的映射表, 然后呢,创建评价单的时候首先去查询是否已经创建过了,如果创建过了那么直接返回评价单号。
- **评价系统相关指标**
  
  - 接入业务线：  长租、自如寓、自如驿、保洁、搬家、维修、职能。   9个业务线
  - 接入场景:  调研问卷、
  - 分表数量: 32张表
  - 单表数量:  1000万
  - 评价数据总量:  32 * 1000万 =  3.2亿            
  - 目前每天评价单数据量: 15万, 月单量500万,年单量 7500万,可以支撑5年左右
  - 系统QPS:  总体来说不是很大,毕竟是房子、以及服务之类的评价。  80左右, 比较均匀
- **系统的难点**:
  
  - 数据模型的设计以及场景的配置？
    - 如何能够尽最大程度的满足业务的目标以及更多地业务需求？
      - 做到不同评价问卷按照一定的规则进行不同的适配（根据城市、房屋类型、以及简单的智慧推评）
      - 智慧推评：其实就是我们会收集用户低评的相关信息,记录某个低评相关的人以及问题，下次继续将该问题推送给他，
      - 以及某个评价问卷中问题按照一定的规则进行展示。 比如配置了多个MOT问题,随机展示两个或者1个。
      - 这样的话可以做到更精准的评价数据运营,针对更细粒度的被评对象,拿到用户的评价,然后再去对这些评价进行分析,这种更精细的问题可以更有效的找到业务上的痛点。
  - 数据迁移？ 分表
    - 平滑的进行数据迁移（不停机）
    - 第一阶段:主分表数据源同时写数据,以及将主表的历史数据写入分表数据源,并校验两个数据源的数据是否一致（但是事务模型以主表为准）
    - 第二阶段:主分表数据一致,仍然同时写入数据,并校验两个数据源的数据是否一致,(此时事务模型以分表为准)
    - 第三阶段: 第三阶段就是下掉主表，主表不在写入数据了。 完成分表
  - 系统QPS？
    - 一天平均访问次数400W PV
    
    - 平均响应时间 100ms
    
    - 最快速解决方案，就是增加机器。我们根据以上情况来实际计算一下。
    
      - 访问量：一天 400w pv
      - QPS： 60 多   两台机器作为流量的入口。
    
      根据日常经验，80% 的访问量集中在 20%的时间，算一下这 200w pv实际需要机器达到多少qps才能满足。
    
      ```apache
      qps = (200w * 0.8) / (24 * 3600 * 0.2)
      
      qps = 61.7
      ```
- **主要表结构**
  
  - 评价单表:    
  - 评价人表
  - 被评对象表
  - 被评人表
  - 被评房屋表

#### Jvm

- **Java内存结构有哪些？**
  - 堆: 对象主要存在的位置。
  - 虚拟机栈: 每个方法的执行会在虚拟机栈创建一个栈桢,并对应着入栈以及出栈的过程。
  - 本地方法栈: 与虚拟机栈类似,不过是jdk提供的本地方法,由C++实现
  - 方法区: 存储类的元信息,静态变量,运行时常量池等  https://blog.csdn.net/xiaojin21cen/article/details/105300521
  - 程序计数器: 记录每个线程的下一个指令的地址。CPU在进行时间片切换的时候,线程会交替执行,当一个线程暂停后要继续执行的时候需要知道下一步指令的地址。

- **类的加载机制？https://juejin.cn/post/6970887415598678047**

  - 类的加载机制主要有以下几个过程？
    - 加载：JVM 将.class文件加载到内存中
    - 验证: JVM验证该class文件是否符合JVM的规范
    - 准备: JVM为类变量也就是静态变量分配内存,并初始化默认值  一般都是0或null
    - 解析：将class文件中的符号引用转换为直接引用,直接引用就是标记了某个类对象的地址或者方法的内存地址
    - 初始化：就是对成员变量进行一个初始化的操作。
  - 类的加载器有哪些？
    - BootStrapClassLoader   启动类加载
    - ExtensionClassLoader   额外包加载器
    - ApplicationClassLoader  应用程序加载起
    - CustomCloader 

- **什么打破了双亲委派机制？**

  - SPI机制.JDBC的类的实现是由不同的厂商来开发的,JDK默认的父类加载器加载不到,所以直接使用应用程序加载器直接进行加载。设置了ThreadLoal--线程加载器。
  - Tomcat的类加载机制: Tomcat是一个web容器,可以包含不同的web项目,不同web项目依赖的相同限定类名的版本不同,如果用JDK默认的类加载器,相同限定类名类只能加载一个,web项目中的依赖的版本不同所以是不可行的。

- **常量池与运行时常量池总结**？

  - class常量池是在编译的时候每个class都有的,在编译阶段,存放的符号引用。
  - 字符串常量池:每个jvm只有一份,存储的是字符串的引用值。
  - 运行时常量池：在类加载完成之后，将每个class常量池中的符号引用值转存到运行时常量池。 每个class都有一个运行时常量池,在解析阶段将符号引用替换成直接引用,与字符串常量池中的引用值保持一致。

- **new一个对象发生了什么？** https://www.cnblogs.com/JackPn/p/9386182.html

  - 判断类是否已经被加载,如果没有没加载首先进行加载
  - 在堆中分配内存空间
  - 对所有实例变量赋默认值
  - 执行实例初始化代码,然后执行构造方法

- **如何确定一个对象是否可以被回收**？

  - 引用计数法:如果该对象有一个引用进行+1计数,循环引用可以解决 ,但是多线程环境下要进行同步操作,性能比较低。
  - 可达性分析法:GCROOT(栈中的本地变量,方法区的静态变量等),
  - 因为栈中的本地变量和静态变量引用着对象，从而这些对象是不能够进行回收的。 标记到这些不能回收的，那么剩下的就支持回收了。

- **垃圾收集算法有哪些**？
  - 标记-清除:  标记完成后进行清理,而不整理内存空间,可能会存在不连续的空间
  - 标记-整理:  G1。
  - 复制算法: 分代收集中的年轻代。

- **CMS垃圾回收机制**？

  - https://tech.meituan.com/2020/11/12/java-9-cms-gc.html
  - https://www.jianshu.com/p/2a1b2f17d3e4
  - https://www.jianshu.com/p/12544c0ad5c1  三色标记法
  - 初始标记:Stop The World。 标记出GCRoot出关联的对象（这些对象是不可进行回收的）
  - 并发标记:GC线程和用户线程同时执行。针对初始标记的对象在根据这些对象引用的对象的一个标记
  - 重新标记:Remark,Stop the world。重新标记,避免并发标记的时候修改了对象之间的引用关系。
  - 并发清理: 针对不可达的对象进行一个垃圾回收。

- G1l垃圾回收器？单次GC时间太长该如何处理。

  - G1垃圾回收器的目标是能够在  **用户设定的延迟时间内**获得尽可能高的吞吐量。
  - G1不在按照新生代和老年代那种连续的内存进行划分,而是将内存区分划分成一个一个的Region区域。然后每一个region都可能作为新生代和老年代的空间。他的回收思路其实是G1 会跟踪各个Region的回收价值（回收可释放的空间和回收所需要的时间）,然后维护一个优先列表,在用户设定的最大收集停顿时间内,优先回收价值比较大的区域。

- **JVM参数**  http://www.51gjie.com/java/551.html

- 调优:  个人中心项目(GC日志)

  **MajorGC和minor GC频繁**

  - minorGC频繁的原因,可能是由于新生代空间比较小,Eden区很快就会被填满,就会导致频繁的minorGC,可以通过增大新生代空间来降低minor GC的频率,例如 新生代中的Eden区增加一倍数,那么Minor GC的次数就会减少一半。
  - 扩大新生代 Eden 的空间,不会增大MinorGC的时间么？
    - MinorGC的时间实际上是由两部分组成的,一部分扫描对象,一部分是复制对象。明显复制对象的时间比较长, 所以说minor GC的时长更多取决于GC后存活对象的数量,而非Eden区的大小。

  - **结论： ** **如果应用存在大量的短期对象,应该选择较大的年轻代,如果存在相对较多的持久对象,老年代应该适当增大。**


- **GC时间过长如何分析？** 

  - 之前我们线上出现过一次这样的案例。 当时有用户反馈查看评价问题的时候很慢,然后当时查了sql的索引这些,都没问题的sql执行还是很快的,当时就想是不是垃圾回收的问题。然后我们这是有一个监控平台的,可以看每台机器的性能以及内存占用,GC等情况的。然后就看一了一下当时的GC情况,发现了当时系统major GC的时间有点长,然后就去看GC日志,发现  Remark冲标记阶段时间比较长, 因为重标记阶段,用户线程是暂停的,所以会导致用户反映系统慢。 然后就开始着手降低remark时间。

  - remark阶段主要是通过扫描堆来判断对象是否存活,但是remark 需要扫描的是整个堆,因为可能存在跨代引用的情况,比如新生代持有老年代对象的应用。
  - jvm默认在remark阶段之前增加了一个**可中断的并发预清理**,这个余庆里就是针对新生代的,  这个机制是判断新生代使用是否超过2M,如果超过那么就执行 minorGC,否则等待有一个限制时间5s,如果5s没有发生 mindorGC 仍然执行remark。
  - 解决办法就是增加了一个参数  在CMS并发标记之前强行执行一次 minor GC。

- 遇到过内存泄漏吗？如何解决的？

  - 没遇到内存泄漏,不过遇到过内存溢出，内存泄漏的话就是，jvm内存开辟完一些空间之后,在使用完毕后并没有进行释放,因为我们知道 jvm有自己的一套垃圾处理器，无用的对象最后会被释放掉。如果对象没用了但是对象还是没有释放掉。则可能造成内存泄漏。

  - 可能造成内存泄漏的操作有哪些？

    - 使用静态变量存储对象,因为静态变量的生命周期是和程序一致的。例如我们的静态变量是个集合,我们在某个方法中对这个集合进行了添加了很多对象的操作，然后使用完这个对象后，就没有管这个对象,由于是静态变量，所以垃圾回收器不会去主动回收。从而占用大量的内存空间。

    - ThreadLocal 也可能存在内存泄漏，ThreadLocal 内部有个ThreadLocalMap，然后ThreadLocalMap持有

    - ThreadLocal的弱引用,如果没有外部强引用的话,那么ThreadLocal会被回收,那么TheadLocalMap 中就会出现 key为null 的Entry, 如果线程不死亡的话会一直存在一条引用链，ThreadLocalRef - ThreadLocal-ThreadLocalMap-Entry-value，会导致内存一致不能被回收，从而导致内存泄漏。

    - 使用完ThreadLocal的时候 记得即使清除 ThreadLocal中的对象。  使用ThreadLocal.remove();
    
    - ```java
      private static final ThreadLocal<UserBO> innerUserInfoThreadLocal = new ThreadLocal<>();
      ```

- JMM:
  - 内存可见性：线程对共享变量修改的可见性,当一个线程修改了共享变量的值,其他线程能够立刻得到这个修改。
    - volatile : synchronized: final
  - 原子性：
    - 当某个变量存在于不同的CPU缓存中,结果未来的及同步到主存,会导致数据计算异常。
  - 指令重排：编译器在不改变单线程程序语义的前提下,可以重新安排语句的执行顺序。
  - haapens before:
    - 程序顺序规则: 单个线程操作, 发生于该线程中任意的后续操作
    - 监视器锁规则：对一个锁的解锁, 发生于随后对这个锁的加锁。
    - volatile 变量规则: 对一个volatile的写  发生于任意后续对 volatile的读之前。
    - 传递性原则  如果A发生于B之前,切B发生于C之前,那么A发生于C之前。

#### Java

- 函数式接口是什么？ 函数表达式有什么好处？

  - 有且只有一个抽象方法的接口被称为函数式接口。有且只有一个抽象方法的接口,并且被FunctionalInterface标记。

  - 比较轻巧,使用方便,可以直接把函数表达式写入参数中。 

    ```java
    im.Fuc1(() -> {System.out.println("asf");return "hello";});
    ```

- Java内部类有什么好处？
  - 内部类就是class中还存在一个class,内部类可以有多个实例,每个实例都有自己的状态信息,并且与外围类对象那个的信息相互独立。
  - 在单个外围类中,可以让多个内部类以不同的方式实现同一个接口,或者继承同一个类。  可以模拟多继承。
  - 方便将存在一定逻辑关系的类组织在一起,又可以对外界隐藏。

- **Java的基本类型有几个？String是不是java的基本类型？为什么String 是final的？**
  
  - int,long,float,double,boolean,short,char,byte
  - 不是
  - 首先我们知道final 就是代表不可变的含义么， 字符串其实就是我们开发中用到最多的一种数据类型。为了避免创建过多的字符串对象，java提供了一个字符串常量池,字符对象创建出来后都存储到方法区的常量池中，供各个线程使用,这样的话我们就知道了字符串是共享的,既然是共享的，所以我们就要考虑线程安全的问题，如果一个线程正在用这个对象，被另一个线程修改了 就出问题了，所以才用final 保证字符串不能被修改，保证安全性
  - String 为final 也防止子类继承,如果子类继承,可能会对String的方法进行重写，从而导致语义上的改变 导致应用程序不安全。
  
- **反射机制的底层实现是什么？动态呢？动态的实现原理？**
  
  - 方法的反射调用就是 Method.invoke() ,然后呢 实际上其实是委派给  MethodAccessor接口来处理。
  - 然后MethodAccessor接口 有两个实现 一个是本地方法的实现另一个是委托方法的实现。
  - 默认的话是通过本地方法的实现 来执行方法，然后还提供了一个动态生成字节码的实现，虚拟机设置了一个阈值,如果某个反射的调用次数在15次之下，那么就用本地实现  java-c++-java,  如果在15次之上就用动态实现。  为何直接使用动态？因为如果调用次数少的话,本地实现更快。
  
- **反射调用的开销？**

  - class.getMethod  -- 为遍历所有类中所有的方法。 比较耗时
  - 另外 Method.invoke 使用的是变长参数- Object类型，到最终会编译称Object[] 数组，Object数组中不能使用基本类型，从而也会引起自动装箱等操作。引起性能开销。

- **JAVA线程**？  JVM的线程模型

  -  实现线程主要有几种方式？
    - 使用内核线程
      - 轻量级进程与内核线程是一一对应的。所以每个轻量级进程都是一个独立的调度单元，即使阻塞了，也不会影响整个进程的工作。
      - 基于内核线程的实现，所以各种进程的操作都需要系统调用，系统调用需要频繁的在用户态和内核态之间切换。
    - 使用用户线程
      - 用户线程是基于用户态基础上的，内核感觉不到用户线程的存在，用户线程的创建 同步 调度 销毁等需要在用户态进行完成，需要用户程序自己处理。但是维护起来比较复杂。
    - 使用用户线程与内核线程混合
      - 用户线程+轻量级进程混合使用，用户线程依然建立在用户空间,轻量级进程为用户线程和内核线程的桥梁。降低了进程被阻塞的风险。
    - JAVA是1.2之前是自己用用户线程实现的，1.2之后使用的是内核线程。

- **JAVA线程调度以及状态切换？**

  - 进程和线程的区别？

    - 进程是系统进行资源调度和分配的基本单位,实现了操作系统的并发。
    - 线程是进程的子任务,是CPU调度和分派的基本单位。  一个进程中可以有多个线程。

  - 线程调度：

    - 协同式线程调度：一个线程执行完事后再去执行下一个线程
    - 抢占式线程调度：优先级抢占--时间片

  - 进程状态：?

    - 创建：进程创建好
    - 就绪：等待CPU时间片
    - 运行：运行状态
    - 阻塞：等待某一事件执行完成或者等待IO操作完成
    - 结束：进程结束

  - 线程状态：

    - 新建：创建后尚未启动的线程

    - 运行：处于运行的状态：也可能在等待CPU分配执行时间

    - 无限期等待：wait  处于这种状态的线程  需要手动去唤醒 或者终端

    - 超时等待：指定时间后继续去抢占时间片。

    - 阻塞：线程阻塞于锁。

    - 结束：线程结束。

      ![preview](https://segmentfault.com/img/remote/1460000023194699/view)

- **HashMap:hashMap底层是数组+链表+红黑树**

1. 计算key的hashCode,并将其无符号右移16位,对高低位进行一个异或运算,避免低位相同造成hash冲突。
2. 判断数组是否为空,如果为空进行第一次扩容也就是初始化,如果指定了集合容量,那么就取于该容量最接近的2的n次幂的整数,作为集合的容量
3. 通过hashCode与数组长度  n-1进行与运算  相当于  hashCode % n 进行位运算,的到数组的下标。
4. 再判断当前数组的下标该位置是否有节点,如果没有那么就插入一个节点。如果有节点,判断当前插入的key是否与该节点的key是否相同,如果相同则返回,判断当前节点属于链表节点还是树节点,如果是链表节点那么遍历这个链表,并插入到链表尾部,如果是树节点,按照红黑树的节点插入逻辑进行插入。如果链表节点个数大于到8,那么转换成红黑树。
5. 判断当前集合元素是否到达了集合的阈值,如果超过了那么就进行扩容操作。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       

- **ConcurrentHashMap**:

1. 校验key和value的值不能为空
2. 计算key的hashCode, 判断数组为空,如果为空进行第一次扩容,扩容的时候通过cas保证只有一个线程进行扩容。通过一个集合大小的控制变量进行判断。
3. 通过hashCode与数组长度-1进行与运算计算出该节点在数组中的下标,并判断该下标处是否有节点,如果无节点,那么通过cas设置该新节点。
4. 如果不为空判断是否处于扩容阶段,并进行协同迁移。（协同迁移如何迁移？）
5. 否则使用synchronize锁定头结点。如果是链表就插入到链表尾部。如果是红黑树节点就按照红黑树的插入逻辑插入到红黑树中。如果链表长度到8的时候那么进行链表转红黑树的操作。
6. 对集合元素的大小进行+1操作.

- **hashmap的长度总是设置为2的整数次幂的原因？**
  
  1. 因为下标计算方式为： hashCode & length-1,如果长度为偶数的话,length-1为奇数,这样 hashCode&length-1进行计算的话,末尾可能为0也可能为1,如果为奇数的话,那么length-1为偶数,从而末尾都是0；
  2. 同时数组下标的计算方式是: hashCode 与 n-1进行位运算,其实就是相当于 hashCode与n进行取余计算,这个公式只有在n为2的整数次幂时才正确。而位运算在计算机中运算更快。
  
- **hashCode扰动函数**？
  - 因为hashmap计算hashCode的时候,总是将hashCode的高16位与低16位进行异或运算得到hash值,这样可以保留高位的特征,避免某些key的低位相同,造成hash冲突。
  
- **hashmap 扩容后是否需要进行 rehash？**
  1. 1.8之后不需要进行rehash。下标的计算方式是通过hash值与数组长度取模进行计算,hashmap扩容都是变为之前的2倍,这样的话,当hash值与数组长度-1进行位运算的时候,只需要多看一位,看hash值与1的位运算结果。如果为1,那么该元素在新数组中的下标位置为  之前的index+之前的数组长度。如果为0,那么该元素在数组中的下标位置不变。
  
-   **为什么链表长度为8的时候进行红黑树的转换？**
  
  1. hashmap中节点分布遵循泊松分布,链表长度超过8的概率极低。
  2. 在链表长度较短的时候时间复杂度和红黑树没什么区别。
  3. 红黑树的空间占是链表的两倍。
  
- **Hashmap 与ConcurrentHashMap的区别**？
  
  - hashmap 线程不安全、key value 可以为null、
  - concurrent 线程安全、key value 不能为null、
  
- **ConcurrentHashMap协同迁移如何迁移？**

- 协助扩容：

  - 根据操作系统的CPU核数和集合length计算每个核一轮处理桶的个数
  - 修改迁移节点的下标，一个线程领取完任务后, 第二个线程要在第 数组长度-第一个线程处理的节点个数的位置进行处理，以此类推
  - 领取完要处理的节点后进行处理,进行同步处理
  - 直到最后一个线程处理完。 旧的数组被新数组替换掉

    // **简要总结**：

      - 分配任务： 把一个大数组切分，切分成多个小份，然后每个线程处理其中每一小份，当然可能只有一个或几个线程在扩容，那就一轮轮的处理，直到 处理结束。
      - 复制部分主要有两点，第一点加锁，第二点处理完之后置为ForwardingNode标记这个位置被迁移过。

- **LinkedHashMap？**
  
  - 底层也是HashMap 不过每个节点有两个指针,指向前一个节点和后一个节点,形成一个双向链表。
  - accessOrder 实现了按照插入顺序以及访问顺序。 实现了LRU。
  
- **ArrayList和LinkedList**
  
  - ArrayList 底层是一个Object数组。默认数组长度为0,添加第一个元素的时候会初始化一个数组长度为10的数组,后面如果元素超过数组长度,那么进行扩容,新数组的容量为原来的1.5倍。
  - LinkedList底层使用的是双向链表,每个节点保存了指向前驱节点和后继节点的指针,初始化时,不执行任何操作,添加第一个元素时,再去构造链表中的节点。
  
- String、StringBuffer StringBuilder？
  - StringBuffer和StringBuilder都是可变的 ， StringBuffer是线程安全的，为什么是可变的？因为底层使用的一个 char[] 数组，而String不可变是因为用了 final  char []

#### Lock

- **什么是线程安全？**
  - 线程安全其实就是指的是内存安全,因为对象等存在堆中,因为堆是线程共享的区域,而且现在的系统都是多线程进行执行的，如果不加什么限制的话,可能当前线程访问的对象,被其他线程修改,从而造成线程不安全的问题。
- **Volatile了解吗**？是线程安全的吗？
  - volatile是java中的一个关键字，
    - 实现了多个线程读一个共享变量的时候能够读到最新的值。
    - 禁止指令重排序
  - 因为我们知道CPU会有缓存的，可能某个共享变量被另一个线程修改了，但是当前线程读的还是CPU缓存中的值，可能缓存的值与实际值不同，导致业务错误。volatile 可以做到读取的时候直接拿主内存的值。
  - 不是线程安全的。 不能保证原子性。 当一个被volatile修饰的变量 ，一开始两个线程都从将变量的值为0 读取到内存，然后进行++操作，其中一个线程++完后并没有写，此时为1，另一个线程因为读到的也是0然后进行++刷新到内存，此时内存为1。这时候前一个线程拿到时间片继续执行，又将1重新写入到内存中。造成的结果就是某个值被少加了。
- **CAS**
  - CAS涉及三个操作数:
    - 读写内存的地址
    - 该内存的地址的原值
    - 想替换的新值
  - 当传入的期望值与该内存的地址的值相同时,原子的将该地址的值替换成新值。
- **CAS** **的缺点**
  - ABA问题,一个线程对该内存地址的进行修改,此时有另一个线程对其进行了修改,并改回来了原先的值,此时这个线程还是能对该内存地址成功的进行修改,而不知道有其他线程已经对该内存地址进行了操作。  可以通过AtomicStamp -- 来解决，增加了版本号的机制。类似于乐观锁
  - 自旋操作,长时间不成功的话会消耗CPU。
  - 只能对一个共享变量进行操作。
- **Synchronzied**
  - Synchronized是Java提供的一个关键字,是一个同步锁。1.6之前其是一个重量级锁，使用时会直接使用操作系统底层的互斥锁,比较耗费性能。jdk1.6之后对其进行一系列的优化,synchronized具有了偏向锁,轻量级锁,重量级锁这几种形态。每个对象的对象头中包含了一个MarkWord,包含了对象的GC年龄,hashCode,线程ID,偏向锁标识,锁标记等。
  - 偏向锁:某个线程去获取锁时候,将自己的线程ID通过Cas设置到锁对象中,如果设置成功,代表获取到偏向锁,如果下次该线程再次获取这把锁的时候,比较锁对象中的线程ID是否和该线程的线程ID相同,如果相同那么直接拿到这把锁,否则进行锁的升级。
  - 轻量级锁: 某个线程获取锁的时候会将锁对象的markword 复制到自身的lockRecord上,然后在通过cas将锁对象的markword替换成自身的锁记录的指针,如果替换成功.那么证明获取到轻量级锁,否则会进行一个适应性自旋来获取锁,如果一段时间后仍然获取不到,那么就升级为重量级锁。
  - 重量级锁:(调用操作系统底层的互斥锁进行同步操作)每个对象都有一个monitor监视器对象,并且存在几个队列。    
    - 竞争队列: 如果存在多个竞争锁线程,其是先进后出的一个队列。
    - 等待队列: 调用对象的wait方法会进入等待队里。
    - 竞争锁线程: OnDeck
  - ![preview](https://segmentfault.com/img/remote/1460000038392247/view)
- **ReentrantLock**
  
  - 是JDK提供的一个锁工具类,基于AQS实现的。
  - 加锁流程？
    - Aqs中有一个state变量,标识锁的状态,ReentrantLock在加锁时候,通过cas将state变量从0变为1,如果cas操作成功,并设置当前线程ID,证明获取锁成功。
    - 如果cas失败,在进行一次获取锁,并判断是否是锁重入,如果是当前锁重入那么将state加1,获取锁成功
    - 如果再次获取锁失败,那么加入到等待队列,进行阻塞等待。Lock.Support.
- Condition
  - Condition是对ReentrantLock锁粒度细化的产物,在实际应用中,我们发现能够对数据操作的线程进行分类,在唤醒阻塞线程的时候,每次唤醒某个或者某些类型的线程。而不是每次都唤醒全部线程。
- **Synchronzied 和 ReentrantLock区别？**
  - Synchronized 是非公平锁,ReentrantLock支持公平锁以及非公平锁。
  - Synchronized是jdk提供的一个关键字,RenntrantLock是java并发包下提供的类。
  - Synchronized在线程竞争激烈的情况下性能没有ReentrantLock高：
    - 为何？ 因为sync本质上是悲观锁 使用操作系统底层的互斥锁,reentrantlock本质属于是乐观锁 通过cas比较变量的状态,,每次sync都要去进行加锁和释放锁的操作,而reent是cas获取不到直接进行入队的操作。只有一个线程进行自旋的操作。消耗并不会很大 。
  - Synchronized 一直堵塞到获取到锁,ReentrantLock可以设置一个超时时间进行尝试获取锁。
  - ReentrantLock可以进行响应中断,synchronized不行。
- **谈谈你对AQS的理解？**
  - AQS其实就是JDK提供的一个抽象队列同步器,可用于实现基于先进先出的等待队列的锁和同步器的框架,比如ReentrantLock、FutureTask、CountDownLatch等都是基于其实现的,该抽象类实现了线程的入队,出队等操作,所以我们只需要实现获取锁的逻辑,以及释放锁的逻辑即可。
- **读写锁以及底层实现**？
  - https://pdai.tech/md/java/thread/java-thread-x-lock-ReentrantReadWriteLock.html
  - 读写锁特点：读读共享：读写互斥  写写互斥
  - 读写状态的设计：读写锁是在一个整型变量上通过高低位来区分读写锁的，读锁是高16位  写锁是低16位
  - 写锁的获取与释放:
    - 首先会获取state，判断是否为0，若为0，表示此时没有读锁线程，再判断写线程是否应该被阻塞，而在非公平策略下总是不会被阻塞，在公平策略下会进行判断(判断同步队列中是否有等待时间更长的线程，若存在，则需要被阻塞，否则，无需阻塞)，之后在设置锁状态state，然后返回true。若state不为0，则表示此时存在读锁或写锁线程，若写锁线程数量为0或者当前线程不为独占锁线程，则返回false，表示不成功，否则，判断写锁线程的重入次数是否大于了最大值，若是，则抛出异常，否则，设置状态state，
  - 读锁的获取与释放:  
    - 读锁是支持重入的共享锁,它能够被多个线程同时获取,首先判断写锁是否为0并且当前线程不占有独占锁，直接返回；否则，判断读线程是否需要被阻塞并且读锁数量是否小于最大值并且比较设置锁状态成功，若当前没有读锁，则设置第一个读线程firstReader和firstReaderHoldCount；若当前线程线程为第一个读线程，则增加firstReaderHoldCount；否则，将设置当前线程对应的HoldCounter对象的值。
- 高并发读 高并发写用什么锁？
  - 可以采用Redis锁以及数据库乐观锁来进行实现，  可以使用Redis实现读写锁或者   Redission
- **线程池设置**？
  - 参数： 核心线程、最大线程数、队列大小、线程存活时间、线程池拒绝策略。
  - 如何配置线程池的参数：
    - 主要是考虑两方面,看你的服务是CPU密集型还是  IO密集型
    - CPU ：  尽可能少的线程，Ncpu+1
    - IO： 尽可能多的线程, Ncpu*2.
    - 混合型: CPU密集型的任务与IO密集型任务的执行时间差别较小，拆分为两个线程池；否则没有必要拆分。
- 并发工具？
  - CountdownLatch：
    - CountDownLatch是利用AQS中的state来做计数器功能，当初始化CountDownLatch的时候，会对state的值进行初始化，调用countDownLatch的await的方法的时候,判断state是否为0.如果不为0就挂起当前线程，并加入阻塞队列,如果有线程调用了countDownLatch的countDown方法，那么state会减1,并唤醒阻塞队列中的线程，然后判断state是否为0，如果不为0 接着挂起。
  - CyclicBarrier：
    - 多个线程互相等待，到达某一个临界点，然后一起可以再去执行下一组任务。
    - CyclicBarrier内部有一个计数器，每个线程在达到屏障点的时候都会调用await方法将自己进行阻塞，然后将计数器count进行减1，当计数器减为0 的时候，所有因await方法而阻塞的线程将会被唤醒。
  - FutureTask:
    - furureTask 中维护了几个状态,一个新建状态和执行中状态,其他的就是正常完成状态、中断 异常状态等, 如果当前futureTask状态是新建和执行中的状态,就把当前线程挂起,等待所有的线程执行完毕。 LockSupport.park.

#### Redis

- Redis如何实现分布式锁？
  - 通过redis的setNx方法来实现分布式锁， setNx  key  value  timeout 
  - redis的lua脚本来释放锁。  保证原子操作   key  value   进行比对，

- Redis**有哪些结构**？
  - string: 动态字符串, 预分配空间,维护了一个字节数组,分配了一定的空间,减少内存的频繁分配.字符串长度小于1M时,扩容是翻倍的现有空间,大于1M,扩容是扩展1MB的空间。
  - hash: 类似于java中的hashmap,基于数组+链表的结构。
  - list: 列表类似于java中 LinkedList,注意其是链表而不是数组。意味着ist的插入和删除操作非常快。 压缩列表
  - set: set集合,类似于java中的hashset,内部实现也是一个字典,每一个value是一个null
  - zset: 有序列表,  跳表。 类似于SortSet和HashMap的结合体。一方面它是一个set,保证了内部value的唯一性,另一方面value设置一个分值,用来进行排序。  单链表的某些节点的上层增加一些索引节点。
  
- **Redis过期key是如何清理的？**
  
  - 惰性清理:在访问key的时候,发现其已经过期,那么将其删除
  - 定时清理: 每次遍历所有的DB,从DB的过期字典里随机筛选出20个key,如果超过25%的key已经过期,那么继续对这个db进行清理,否则对下一个DB进行清理。
  - 内存不够时候进行清理:
    - 直接报错
    - 从所有结果集中进行淘汰:
      - 随机淘汰算法
      - LFU算法,使用频率最低的key。
      - LRU算法,最近最久未使用的key进行清理。
    - 从淘汰列表中进行淘汰:
      - ~~
  
- **Zset是怎么执行查询操作的？**
  
  - Zset是基于跳跃表+字典实现的.
    - 如果只是单key查询,那么就直接从字典中进行查询.
    - 跳跃表查询,首先根据要查找节点的分数与顶层的节点的分数进行比较,不断索引查找索引节点的区间,一层一层的向下查找,直到找到与这个节点相同的节点
  
- **Redis为什么是单线程的以及为什么这么快？**https://www.jianshu.com/p/bc6904abc330
  - Redis是纯基于内存的,处理请求速度非常快,不需要使用多线程提高其的CPU利用率。CPU不会成为瓶颈。如果用多线程的话还需要关心线程安全的问题。
  - 这里单线程指的是处理客户端发送的请求命令的处理器模块是单线程,而有些模块不一定是单线程的。
  - 只有IO才是影响Redis服务器性能的主要因素,而Redis采用了IO多路复用模型,尽量减少网络 I/O 的时间消耗。减少了线程的切换。  多核的话你就要考虑线程安全等问题,得不偿失
  - Redis的数据结构也是进行了一些优化的,例如动态字符串,是预分配的一些空间,避免修改时候进行扩容带来的开销,以及list使用压缩链表等减少内存占用。
  
- **Linux IO模型有哪些？**

  - BIO:阻塞IO,当用户态进程发出一个IO请求时,用户进程进行阻塞,内核态准备数据,进行阻塞等待,等内核态准备好数据后,将数据从内核拷贝到用户态,然后告知用户进程数据好了,然后返回。
  - NIO:非阻塞 IO,进程不断的询问内核,数据准备好了没有,知道内核准备好数据。
  - IO多路复用: 一个进程处理多个socket连接
  - 信息驱动IO: 内核准备好数据后,会给用户态发送一个信号,通知其准备好了,用户态在去请求,拿到数据
  - 异步IO模型: 数据在内核态拷贝到用户态之后,在通知用户态来处理数据,在复制数据到用户空间这个时间段内,用户态进程也是不阻塞的。

- Reactor模式：

  - Reactor模式称为[反应器模式](https://www.zhihu.com/search?q=反应器模式&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A347779760})或应答者模式，是基于事件驱动的设计模式，拥有一个或多个并发输入源，有一个服务处理器和多个请求处理器，[服务处理器](https://www.zhihu.com/search?q=服务处理器&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A347779760})会同步的将输入的请求事件以多路复用的方式分发给相应的请求处理器。
  - Reactor设计模式是一种为处理并发服务请求，并将请求提交到一个或多个服务处理程序的事件设计模式。当客户端请求抵达后，服务处理程序使用多路分配策略，由一个非阻塞的线程来接收所有请求，然后将请求派发到相关的[工作线程](https://www.zhihu.com/search?q=工作线程&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A347779760})并进行处理的过程。
  - 在事件驱动的应用中，将一个或多个客户端的请求分离和调度给应用程序，同步有序地接收并处理多个服务请求。对于高并发系统经常会使用到Reactor模式，用来替代常用的多线程处理方式以节省系统资源并提高系统的吞吐量。

- Redis事件机制？https://segmentfault.com/a/1190000023891056

  - Redis的事件驱动库只关注网络IO,以及定时器。该事件库处理下面两类事件。
    - 文件事件： Redis服务器在多个客户端进行IO多路复用,实现了高效的命令请求处理,多个客户端通过socket连接到Redis服务器,但只有在socket无阻塞读或写的情况下,server才会和这些客户端进行交互。
      - 读事件：**读事件标志着客户端命令请求的发送状态。**
        - 读事件在整个网络连接的生命期内， 都会在**等待**和**就绪**两种状态之间切换：
        - 当**事件处理器**被执行时，就绪的**文件事件**会被识别到，相应的命令请求就会被发送到**命令执行器**，并对命令进行求值。
      - 写事件：**写事件标志着client对命令结果的接收状态。**
        - 和client自始至终都关联着读事件不同， server只会在有命令结果要传回给client时， 才会为client关联写事件， 并且在命令结果传送完毕之后， client和写事件的关联就会被移除。
      - 同时关联读写事件：
        - 事件处理器 优先处理读事件。
    - 时间事件：
      - 时间事件记录这哪些要在指定时间点运行的事件,多个时间事件以无序链表结构保存在服务器状态中。
      - 时间事件示例:    `redis.c/serverCron` 
        - aof和rdb持久化操作
        - 清除数据库中过期的键值对
        - 更新服务器的各类统计信息,比如时间、内存占用、数据库占用
        - 服务器是主节点的话,对从节点进行定期同步

- Redis事务机制？https://segmentfault.com/a/1190000018706074

  - Redis事务可以看做是批量Redis命令的一个执行,批量执行也并非原子性。也就是说,如果中间有些指令失败了,前面和后面的操作不会收到影响（比如给一个字符串 添加元素）。除非是语法错误  set 后面不加元素。

  - 开始事务。  命令入队。 执行事务。

  - ```go
    1.multi；  
    2.set key value   
    3.exec
    ```

    

- **聊聊IO多路复用模型？**
  
  - 单个线程处理多个socket连接请求,减少系统开销,不必创建过多的线程。 
  
  - select：当 没有IO事件的时候,进程处于阻塞状态,当有IO事件时候,有一个代理（select和poll）去轮询的遍历所有Socket连接,来处理IO事件
  
    ​	select只能处理1024个链接,而poll无限,poll是基于链表来实现的。
  
  - poll：
  
  - epoll：epoll是基于事件驱动,一个socket事件来的时候会绑定一个回调函数,如果事件已经就绪,会通知对应socket连接的事件已经完成,不需要进行全部连接进行遍历,提高了查找效率。
  
  - | 系统调用                               | select                                                       | poll                                                         | epoll                                                        |
    | -------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
    | 事件集合                               | 用哦过户通过3个参数分别传入感兴趣的可读，可写及异常等事件内核通过对这些参数的在线修改来反馈其中的就绪事件这使得用户每次调用select都要重置这3个参数 | 统一处理所有事件类型，因此只需要一个事件集参数。用户通过pollfd.events传入感兴趣的事件，内核通过修改pollfd.revents反馈其中就绪的事件 | 内核通过一个事件表直接管理用户感兴趣的所有事件。因此每次调用epoll_wait时，无需反复传入用户感兴趣的事件。epoll_wait系统调用的参数events仅用来反馈就绪的事件 |
    | 应用程序索引就绪文件描述符的时间复杂度 | O(n)                                                         | O(n)                                                         | O(1)                                                         |
    | 最大支持文件描述符数                   | 一般有最大值限制                                             | 65535                                                        | 65535                                                        |
    | 工作模式                               | LT                                                           | LT                                                           | 支持ET高效模式                                               |
    | 内核实现和工作效率                     | 采用轮询方式检测就绪事件，时间复杂度：O(n)                   | 采用轮询方式检测就绪事件，时间复杂度：O(n)                   | 采用回调方式检测就绪事件，时间复杂度：O(1)                   |
  
- **Redis缓存穿透？**
  
  - 缓存穿透指的是攻击者故意大量的请求一些缓存中不存在的key,从而导致大量请求打入到DB,从而导致了DB崩溃。
    - 解决方案:
      - 参数校验（总会绕过这些参数进来） 
      - 对DB不存在的key也进行一个缓存,失效时间可以设置小一点,比如几秒钟,可以避免大量的请求打入DB。
  
- **Redis缓存击穿？**     
  
  - 某个热点key失效造成了大量的请求打入DB。
    - 解决方案：
      - 每次请求的时候去判断缓存剩余时间,如果缓存剩余时间小于设置的缓存时间的一半去更新缓存。
      - 热点key,可以使用两个key例如A和B进行存储,两个key的缓存时间不同,如果A查不到去查B,同时在去更新两个key的缓存值。
  
- **Redis缓存雪崩?**
  - 缓存雪崩指的是大量的key失效,导致流量一次又一次的打进Redis服务器,导致Redis一直垮掉。
    - 解决方案:
      - 原有的失效时间上增加一个随机值,避免了采用相同的过期时间导致的缓存雪崩。
      - 熔断机制,当请求达到一个阈值的时候,直接返回。保证有一部分用户可用。
  
- **Redis缓存与数据库一致性问题如何解决？**
  
  - 原因：首先需要明白导致缓存与数据库不一致的情况:多个写请求的执行顺序不同导致脏数据,更新时正好有读请求,读请求取到旧数据然后更新上，或者数据库是读写分离的,在主库更新完之后,需要一定的时间,从库才能更新。
    - 延时双删: 先更新数据库,然后删除缓存,然后再启用一个异步线程进行延时删除缓存,保证缓存的值是最新的。
    - 定于binlog:通过阿里的canal来订阅Mysql中的更新操作,获取到指定的key然后进行缓存删除的操作，延时双删。 异常重试  Mq
  
- **Redis持久化如何实现的？**
  
  - **AOF**:
    - 将Redis的操作命令追加写入到AOF文件中。
  - **RDB**:
    - RDB是在一定条件下.对这个数据库某个时间点所有的键值对信息生成一个压缩文件,然后将旧的删除,新的替换掉。
  
- **AOF和RDB的区别？**
  
  - AOF是保存了所有的执行修改命令,粒度更细,进行数据恢复的时候,恢复的数据更加完整,但是由于需要对所有的命令重新执行一遍,所以效率没有RDB的方式高。因为是所有的修改命令,所以同样的数据集,aof文件也会比RDB文件大一些。
  - RDB就是保存了某一个时刻DB所有的键值对的信息,恢复效率比较高。
  
- **AOF如何防止文件越来越大？**
  
  - 进行AOF重写,生成此刻的DB数据所需的写命令并写入AOF文件。生成期间,父进程可以正常进行处理请求,将命令写入aof_buf缓冲区,然后在将其写入到新的aof文件中,并原子的替换掉原先的AOF文件。
  
- AOF持久化方式？
  - 混合持久化,AOF文件前半段是RDB,后半段是AOF文件。

- Redis集群方案？https://github.com/NotFound9/interviewGuide/blob/master/docs/RedisUserful.md
  - 主从：全量同步,部分同步
  - 哨兵：运行在哨兵模式下的Redis服务器,核心功能是检测主节点和从节点的运行情况,如果主节点宕机,让某个从节点变更为主节点。
  - 集群：no know

- **跳跃表与平衡树,哈希表的比较？**
  - 时间复杂度：单key查找时,跳跃表和平衡树的查找时间复杂度 ologn,哈希表 o1.
  - 空间复杂度：平衡树的节点包含两个指针,跳跃表的节点指针与其节点有几层的概率相关。redis默认的跳表指针就是1.33。  1 / 3/4
  
- **为什么Mysql不是用跳跃表作为索引？**
  
  - 磁盘IO的开销,B+树的一般是2到4层,而跳表查找一个Score对应的位置需要进行log(n)次的操作,如果所有的索引节点都存在磁盘中,那么也就需要logn次的磁盘IO。
  
- **为什么平衡二叉树也不适合作为索引？**https://www.cnblogs.com/aspirant/p/9214485.html
  
  - 平衡二叉树指的是逻辑上的结构,而物理结构其实就是数组,逻辑结构上相近,但是物理结构上却不一定相近,当查找数据的时候,平衡二叉树可能会查出很多没有用的数据,会导致更多的磁盘IO,导致性能下降。
  
- Redis限流如何实现？ 你们用Redis的场景有哪些？   https://www.cxybb.com/article/Wisimer/110259465

  - 用作缓存
    - 评价详情-
    - 评价问题
  - 简单的限流器：
    - setNx  count 设置过期时间。  （更新count）  但是不是滑动窗口      
    
    - ```java
        private static boolean setNxExpire() {
              SetParams setParams = new SetParams();
              setParams.nx();
              setParams.px(TIME);
              String result = jedis.set(KEY, COUNT + "", setParams);
              if (SUCCESS.equals(result)) {
                  return true;
              }
              return false;
          }
          @Override
          public boolean canDo() {
             if (setNxExpire()) {
                  //设置成功，说明原先不存在，成功设置为COUNT
                  return true;
              } else {
                  //设置失败，说明已经存在，直接减1，并且返回
                  return jedis.decrBy(KEY, 1) > 0;
              }
          }
      ```
    
    - 滑动窗口可以使用 redis 的 zset来进行实现。
    
      - 具体可以使用    zcard 统计集合中元素的数量   jedis.zcard(KEY2) > 0)
      - zadd  key  时间戳 （代表分值）  uuid    jedis.zadd(KEY2, Double.valueOf(currentTime), UUID.randomUUID().toString());
      - zrangeScore        Integer count = jedis.zrangeByScore(KEY2, currentTime - TIME, currentTime).size();
    
    - 令牌桶算法： 按一定速率生产令牌，请求进来直接拿令牌，有令牌就支持请求，否则线路
    
    - 漏斗算法： 请求进来放在一个容器中，以固定的速率处理请求。
    
    - 算法特性：
    
      ```
      计数器固定窗口算法实现简单，容易理解。和漏斗算法相比，新来的请求也能够被马上处理到。但是流量曲线可能不够平滑，有“突刺现象”，在窗口切换时可能会产生两倍于阈值流量的请求。而计数器滑动窗口算法作为计数器固定窗口算法的一种改进，有效解决了窗口切换时可能会产生两倍于阈值流量请求的问题。
      漏斗算法能够对流量起到整流的作用，让随机不稳定的流量以固定的速率流出，但是不能解决流量突发的问题。令牌桶算法作为漏斗算法的一种改进，除了能够起到平滑流量的作用，还允许一定程度的流量突发。
      以上四种限流算法都有自身的特点，具体使用时还是要结合自身的场景进行选取，没有最好的算法，只有最合适的算法。比如令牌桶算法一般用于保护自身的系统，对调用者进行限流，保护自身的系统不被突发的流量打垮。如果自身的系统实际的处理能力强于配置的流量限制时，可以允许一定程度的流量突发，使得实际的处理速率高于配置的速率，充分利用系统资源。而漏斗算法一般用于保护第三方的系统，比如自身的系统需要调用第三方的接口，为了保护第三方的系统不被自身的调用打垮，便可以通过漏斗算法进行限流，保证自身的流量平稳的打到第三方的接口上。
      ```
    
      

#### Mysql

- Mysql主从复制原理？

  - MySQL 主从复制涉及到三个线程：

    一个在主节点的线程：`log dump thread`

    从库会生成两个线程：一个 I/O 线程，一个 SQL 线程

  - 主库会生成一个log dump线程,用来给从库IO线程传binlog数据,从库的IO线程回去请求主库的binlog,并将得到的binlog 写到本地的 relay log 中继日志中,然后从库的sql线程会 读取relay log文件中的日志,并解析成 sql语句逐一执行。

  - 主库会生成一个log dump线程, 用于发送和读取Binlog的内容, 在读binlog的操作中，log dump线程会对主节点的binlog加锁,当读完成发送给从节点之前,锁会被给释放。主节点会为每一个从节点创建一个 log dump线程。

- Mysql 二阶段锁？

  - mysql的二阶段锁其实就是 加锁和解锁的过程。 
    - 加锁阶段：就是例如更新操作或者select for update 或者 select lock in share mode
    - 解锁阶段：当一个事务commit 或者 rollback 的情况下进行解锁。

  - 在日常使用中,我们要尽量的将对热点记录的操作放在事务的最后面,这样可以提高程序的吞吐量。

- ​	一条Sql语句执行发生了什么?

  - 连接器->分析器->优化器->执行器
  - 首先写undolog-记录下执行语句的回滚日志,用来MVCC,回滚。
  - 如果查找的目标数据存在于内存中。
    - Yes:
      - 判断是唯一索引还是普通索引
        - 唯一索引,判断唯一索引是否冲突并更新内存
        - 普通索引,直接更新内存
    - No: 磁盘
      - 唯一索引,从磁盘读到内存,判断冲突与否并更新
      - 普通索引,变更到changeBuffer
  - 写Redo log
  - 写bin log
  - 提交事务
  - 刷redo log盘
  - 刷bin log盘

- **为什么要用二阶段提交机制**？

  - https://cloud.tencent.com/developer/article/1790507
  - 如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 
  - myql 执行一条语句时的时候 先写redo log  - （此时 redolog 标记为 prepare阶段）  在写 bin log   然后事务变为提交状态。
  - 如果写完redolog 后 失败了,那么对比binlog 没有 那么进行回滚 ,如果redolog 有  binlog 也有但是事务提交时候崩溃了，那么崩溃恢复的时候 对比两个文件中数据一致  那么将该事务进行提交。

- 数据库的索引有哪几种？https://segmentfault.com/a/1190000037683781

  - 数据结构分的话就是 ： 
    - B+Tree索引：
    - Hash索引：  Hash只适合等值查询,不适合范围查询 也不适合排序
    - Full-text索引：

- 聊聊索引？
  - 索引是一种对数据库表中一列或者多列数据进行排序的存储结构,能够通过索引快速的定位到数据中的某条数据。
  - Mysql中的索引分为聚簇索引和非聚簇索引。聚簇索引也就是主键索引,主键索引的叶子节点包含的时数据库某一行的数据,而非聚簇索引也就是二级索引,叶子节点存储的时主键的值。
  - Mysql有唯一索引、联合索引、普通索引。
    - 唯一索引:DB数据该字段的值时唯一的
    - 联合索引:多个字段组成一个索引,遵循最左前缀原则,遇到范围查询就停止
  - 联合索引和单列索引的区别？
    - 联合索引是多列字段组合成的索引。遵循最左前缀原则。遇到范围查询就停止。
    - **联合索引比对每个列分别建索引更有优势**，因为索引建立得越多就越占磁盘空间，在更新数据的时候速度会更慢。另外建立多列索引时，顺序也是需要注意的，**应该将严格的索引放在前面，这样筛选的力度会更大，效率更高**。
  - 覆盖索引: 查询的字段都在索引上,叫做覆盖索引,无需回表
  - 哪些字段需要建立索引？
    -  经常用作查询条件的
    - 与其他表相关联的字段
    - 需要排序,统计,分组的字段
  - 哪些字段不需要建立索引？
    - 区分度不高的字段
    - 数据量较少的表

- 索引失效的场景有哪些？

  - 列与列进行了对比 （并且两个列都建立了索引）

  - 查询条件为非的时候,  比如 !=  not in 等。 更倾向于全表扫描。

  - 模糊搜索 前匹配的情况下更倾向于全表扫描

  - 条件上包含函数，  不走索引 

    ```sql
     select * from test where upper(name)='SUNYANG';
    ```

  - 数据类型的转换, 隐式转换的时候  索引会失效。

- Mysql慢sql如何进行优化？
  - 通过explain关键字 看一下sql语句的执行计划,有个type属性,标记了语句使用了那种类型,是否走了索引。没有走索引的语句,看一下where语句中的字段看哪个字段比较适合加索引（区分度高,使用频率高）就加上。
  - 减少请求的数量:   可以只返回必要的列. * 改为需要的列
  - 减少表扫描的行数: 建立索引,对一些常用的条件作为查询字段,建立联合索引,使用联合索引,可以减少一些查询次数,也可以减少磁盘占用空间,而且当查询的字段在索引中包含时,就会用到覆盖索引。无需回表
  - 避免在查询时,对索引字段进行计算和使用函数, 使用函数的时候就不会通过索引查询
  - 切分大查询。

- Explain中type的值

  - system:表明数据表只有一行数据
  - const: 表最多只有一行匹配,用于主键或者唯一索引比较
  - eq_ref: 用于唯一索引的join等
  - ref:  每次只匹配少数行, 左覆盖索引或者非主键或者非唯一键
  - range ： 范围查询
  - index : 走了索引
  - all ： 全表扫描

- Mysql事务的实现以及原理？https://cloud.tencent.com/developer/article/1431307
  - 事务的原子性是通过undolog来实现的
    - 回滚日志,如果有异常那么就执行回滚日志,返回之前的数据。
  - 事务的持久性是通过redolog来实现的
    - redo log是同步存储,而缓存同步是 随机操作也就是数据写入到文件中
    - 缓冲池,避免性能消耗
  - 事务的隔离性是通过读写锁+MVCC实现的

- Mvcc实现的原理是什么？https://github.com/NotFound9/interviewGuide/blob/master/docs/MySQLNote.md
  - Mysql每行数据有隐藏的两列,一列时事务ID,一列是回滚指针,指向undolog
  - 查询的时候,如果查询事务ID小于当前事务ID的时候,那么查询的时候就要通过unlog找到查询事务当时的数据,然后返回
    - 如果一个事务ID小于当前事务ID的话,那么要通过回滚日志查找到此事务开始时快照数据。

- Mysql锁有哪些？
  - 行锁:  **lock in share mode适用于两张表存在业务关系时的一致性要求，for  update适用于操作同一张表时的一致性要求。**
    - 共享锁S锁,读锁,允许事务读一行数据,不能被修改。所以读锁之间不排斥 

      - ```sql
        select * from evaluate_order_11 where evaluate_code  = 'PJ2020070818040028' lock in share mode
        ```

    - 互斥锁X锁,写锁,只允许当前事务修改这条数据,其他事务不可以。  for update

      - ```sql
        select * from evaluate_order_11 where evaluate_code  = 'PJ2020070818040028' for update 
        ```

    - next-key锁,锁当前记录以及该记录之前的间隙锁。

  - 间隙锁: gaplock
    - 锁定一个范围,而不锁定记录本身。
    - 对记录之间的间隙加锁,防止数据插入,为了防止读的过程中有新的数据插入,会对我们读的数据的左右区间进行加锁,防止其他事务插入数据,间隙锁之间是不排斥的。

  - nex-key锁：

    - 锁定前一个索引以及到后一个索引之间的范围,并且锁定索引本身。
    - Next-key锁是在下一个索引记录本身和索引之前的gap加上S锁或是X锁(如果是读就加上S锁（共享锁），如果是写就加X锁（排他锁）)。

  - 表锁:
    - 表锁的话是由 意向共享锁 IS和意向互斥锁IX。
    - 因为mysql innodb中的锁是锁索引的,  只有通过索引条件检索数据,innodb才是用行锁,否则使用表锁。

  - 乐观锁：**乐观锁假定数据一般情况下不会造成冲突,所以在数据进行提交更新的时候,才会真正的对数据的冲突与否进行检测, 每个事务会先检查在该事物读取数据后,是否有别的事务将当前数据进行了修改,如果修改了,那么将正在提交的事务进行一个回滚。 一般我们都通过版本号或者状态位去实现乐观锁。**

  - 悲观锁：**悲观锁是假定一定会发生并发冲突, 悲观锁的实现,往往依赖于底层提供的锁机制。悲观锁的实现,往往依靠底层提供的锁机制,悲观锁会将其他所有需要锁的线程进行挂起,等待持有锁的线程释放锁。**  （并发特别大的情况下会导致系统负载变大）

- 当前读和快照读？
  - 快照读：也就是普通读,单纯的select语句,不包括 
    - select  for update 
    -  select lock in share mode
    - 利用MVCC机制来进行读取,并不会对锁记录进行加锁。是通过 undolog + MVCC来实现的
  - 当前读：就是读取的最新版本,并且对读取的记录进行加锁,（next-key 锁的方式 也就是行锁或者间隙锁）阻塞其他事务同事改动相同记录,避免出现相同问题。

- Mysql可重复读是怎么实现的？
  - MVCC 多版本并发控制：mysql的行数据有着隐藏的两列,一列是事务ID,一列是undolog,在可重复读的级别下,读取数据的时候,如果当前事务ID比查询事务的ID大,那么查询事务就要通过undolog找到查询事务ID的那一条记录快照,并查询到正确的值返回。

- Mysql可重复读,为什么要用可重复读？

  - mysql 记录binlog的模式有几种  statement,row和mix。 statement只是记录修改的sql语句。
  - 如果在读提交的情况下,事务A首先进行了一个删除,但是没提交,事务B进行了一个插入操作,然后提交。然后事务A再去进行事务的提交,此时从库由于是statement的格式,记录的binlog是先插入后删除的。导致如果客户端分别读取主从两个库,主库能够查到对应的值,从库却查不到对应的值。

- MVCC解决了什么？

  - 简而言之就是解决了在REPEATABLE READ和READ COMMITTED两个隔离级别下读同一行和写同一行的两个事务的并发。对数据库的任何修改的提交都不会直接覆盖之前的数据，而是产生一个新的版本与老版本共存，使得读取时可以完全不加锁**

- Mysql底层采用什么树什么存储的？
  - B+树,B+树有什么特点？与B树有什么区别？
    - B+树一个多路平衡查找树,所有记录节点按照由小到大的顺序进行存储在最后一层的叶子节点上,并且由各叶子节点的指针相连接。可以认为每一个叶子节点就是一个内存页。B+树索引节点只存储索引值，不存储行的数据,这样的话可以让每个索引内存页存储更多的值,使得B+树的层数更少。
    - B+树所有数据都在叶子节点上,所以查询也会更稳定,也更适合区间查找。

- Mysql死锁实践？
  - b是唯一索引
  - 事务A
    - insert into  A (a,b) values (1,5);
    - insert into  A (a,b) values (2,6);
    - insert into  A (a,b) values (3,4);
  - 事务B
    - insert into  A (a,b) values (1,5);
    - insert into  A (a,b) values (2,6);
    - insert into  A (a,b) values (3,4);
  - 首先呢唯一索引冲突的时候唯一索引会升级为 Next-key锁,next-key锁是行锁+间隙锁
  - https://tech.meituan.com/2014/08/20/innodb-lock.html

- 如何解决Mysql访问量大的问题。

  - 主从分离, 分库分表

  - 读数据时效性要求特别高的时候指定主库为数据源。

  - 可以用缓存 redis等中间件左一层预防,避免一直打DB。

  - mysql主从复制原理：主库将变更写binlog日志,然后从库连接到主库之后,从库有一个IO线程,将主库的binlog日志拷贝到自己本地,然后从库启动 一个sql线程执行该binlog 然后保证和主库的数据一致。

  - ```
    架构方面：
    1.业务的持久化层的实现采用分库架构，mysql服务可平行扩展，分散压力。
    2.单个库读写分离，一主多从，主写从读，分散压力。这样从库压力比主库高，保护主库。
    3.服务的基础架构在业务和mysql之间加入memcache或者redis的cache层。降低mysql的读压力。
    4.不同业务的mysql物理上放在不同机器，分散压力。
    5.使用比主库更好的硬件设备作为slave
    ```

    

- 设计数据库表的思路？
  - 首先根据我们的prd,原型图,找出某个业务对应的实体,来建立一张表,然后在考虑不同实体之间有什么联系,如果有联系的通过某一个字段进行关联。 例如用其中一个表的主键或者业务ID啊等
  - 然后考虑字段的类型呀,以及长度,根据业务场景确定字段的长度
  - 然后再就是考虑在经常查询的字段上建立合适的索引。
  - 然后再就是可以冗余的字段就冗余上,可以增加查询效率。（例如之前做过一个账单表中费用项,如果只存储费用项Code,还需要连表查询其名称,如果直接冗余,一次性就查出来了）

- 红黑树是什么？

  - 红黑树是一个平衡的二叉查找树。有以下几个性质：

    1.根节点和叶子节点都是黑色的（这里的叶子节点指的是普通的节点增加的一个黑色的空节点）。

    2.红色节点的子节点必须是黑色的，也就是不能有两个红色节点连续。

    3.黑色的节点可以连续，但是从根节点到叶子节点的所有路径包含的黑色节点的个数是一致的。(所以**根节点到叶子节点的最长路径<=最短路径的两倍**)

    红黑树是二叉查找树（也就是每个节点的左子树<当前节点的值，右子树所有节点>=当前节点值），但不是严格意义上的平衡二叉树，因为平衡二叉树要求任何节点的左右子树高度差是<=1，红黑树根节点到叶子节点的最长路径会<=最短路径的两倍,所有他是大致意义上的平衡树。

    相比于AV树（也就是自平衡的二叉查找树，左右子树高度差不超过1），红黑树插入，删除效率更高。因为不需要保证绝对的平衡，任何不平衡需要的旋转次数不超过3次，即便在最坏的情况下，红黑树能够以O(log(N))的时间复杂度进行搜索、插入、删除操作。

    ##### 与红黑树的比较

    红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，主要有以下两个原因：

    （一）更少的查找次数

    平衡树查找操作的时间复杂度和树高 h 相关，O(h)=O(logdN)，其中 d 为每个节点的出度。

    红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多，查找的次数也就更多。

    （二）利用磁盘预读特性

    为了减少磁盘 I/O 操作，磁盘往往不是严格按需读取，而是每次都会预读。而B+数中存储的叶子节点在内存中是相邻的，这样可以读取会快一些。

    （三）存储更多的索引节点

    B+树跟B树的区别就是B+是叶子节点存储数据，非叶子节点(也就是索引节点)只存储索引项，B树是所有节点都存储数据，而每个节点都是磁盘的一个内存页，内存页大小是固定，B+树的每个索引节点可以容纳的索引值更多，与B树相比，B+树的层数更少。

- **分库分表分区**
  - 分区：将同一表中的不同行记录分配到不同的idb 文件中。 分区可以将一个表或者索引分解成多个更小,更可管理的部分,每个分区都是独立的，业务代码无需改动
  - 分表：将某一个表中的数据,按照一定的规则分布在多个表中。
    - 优化单一表数据量过大从而导致的性能问题
    - 避免IO争抢  减少锁表几率
  - 分库: 分库是应对超大数据带来的巨大IO请求,如果不拆库，单裤的吞吐能力和磁盘空间会成为瓶颈。 突破单点服务器的IO能力限制。


#### Mq

https://blog.csdn.net/ThinkWon/article/details/104588612

- **Mq有哪些优点**？
  - 异步:  异步通讯
  - 解耦:  系统之间解耦,无序关心其他系统的处理
  - 削峰:  通过消息长度来控制请求量
- **Mq的问题**?
  - 顺序消费？
    - 在业务层面上保证业务顺序
  - 重复消费？
    - 幂等Key解决
- ​	Mq是什么？
  1. 是消息中间件。
- RabbitMQ 大体结构
  1. 由 Broker --  代表消息队列服务器
  2. Exchange -  消息换机器：  指定消息按照什么规则，路由到哪个队列
  3. Queue：  消息队列   消息会被投入到一个或者多个队列。
  4. Binding:  绑定：  作用就是 将 交换器和队列按照路由规则绑定起来
  5. Routing key  ： 路由key   exchange  通过路由key进行消息投递。
  6. Vhost： 虚拟的broker，可以进行隔离。
  7. 由 交换器  队列  路由key  能决定一个从 Exchange 到 Queue的唯一路线。
- RabbitMQ的工作模式？
  1. 发布订阅模式： 绑定到此交换机的每个队列，都能够收到消息。
  2. 路由模式：  topic ->  交换机根据key 的规则模糊匹配到对应的队列，由队列的监听消费者接收消息消费。
- 如何保证MQ消息的顺序性？https://www.cnblogs.com/-wenli/p/13047059.html
  1. 可以在业务代码中去保证。有序的操作  用一个消息体去包装。
  1. 创建多个queue,然后根据业务ID路由到指定的queue，这样可保证某一组消息的顺序性。
- 消息如何分发？
  1. 通过轮询的方式发送给消费者。  
- 消息咋么路由？
  1. 生产者-》路由-》消息拥有一个路由key， 然后呢这个路由key 将交换器和队列绑定了起来， 消息到交换器后，交换器通过这个key去与他绑定的队列的路由key去进行匹配，匹配到了 就投送的对应的队列中。
  2. fanout： 交换器收到消息：会广播到所有绑定的队列上。
  3. direct：路由key 完全匹配，才回去投送
  4. topic: 使得来自不同源头的消息能够到达一个队列，使用topic交换器，可以使用通配符。
- 消息基于什么传输？
  1. 通过信道：  Channel   是建立与TCP连接内的虚拟连接，且每条TCP连接上的信道数量没有限制。
- 如何保证消息不被重复消费？
  1. 做幂等校验即可。  消息中可以传一个幂等key  DB做一个校验 -- 判断这个是否已经消费完成
- 如何保证消息正确的发送至MQ，如果确保消息接收方消费了消息？
  1. 信道可以设置成 confirm 模式， 发送方确认模式。  所有在信道上发布的消息会被指派一个唯一ID
  2. 消息被投递到目的队列后，或者写入磁盘后， 信道会发送一个确认给生产者，包含了唯一ID。
  3. 发送方确认模式是异步的。生产者应用程序有个回调方法用来确认消息
- 如何确保接口放收到了消息？
  1. 消费者接受每条消息后都必须进行确认。 只有消费者确认了消息，MQ才能安全的把消息从队列中删除
  2. RabbitMQ 是通过Consumer的连接是否中断来确认是否需要重新发送消息，只要连接不中断 - mq给consumer 足够长的时间处理消息。
- 如何保证MQ可靠传输？
  1. 首先消息不可靠就几种情况： 
     1. 生产者丢失消息
     2. 消息列表丢失消息
     3. 消费者丢失消息
  2. 生产者丢失消息： 可以通过 生产者的 confirm 模式--  如果消息投递成功的话 会发送一个ACK给生产者，失败的话会发送一个Nack 消息
  3. 消息队列丢失数据：可以进行消息持久化
  4. 消息丢失消息：一般是自动确认模式，然后消费失败了 才会导致消息丢之，开启手动确认模式， 然后处理成功后  手动确认消息。 或者,异常了存入DB。
- 消息队列的延时以及过期失效的问题？消息队列满了如何处理？ 有几百万的消息持续积压几小时，如何解决？
  - 消息队列积压：  先修复Consumer的问题，确保恢复速度，可以建多个队列与交换器进行绑定，以及消费者端配置并发消费。
- 设计MQ的思路？
  - 持久化消息
  - 服务器的高可用
  - 如何通讯

#### Dubbo

- Dubbo分了哪些层？

  - **service**： 服务层   主要是服务接口的定义以及实现

    **config**：  配置层    负责解析 Dubbo 定义的配置，比如注解和 xml 配置，各种参数；

    **proxy**：  代理层     主要负责生成消费者和提供者的代理对象，加载框架功能，比如提供者过滤器链，扩展点；

    **registry**：注册中心层   负责注册服务的定义和实现类的装载；

    **cluster**： 集群层  只有消费者有这么一层，负责包装多个服务提供者成一个‘大提供者’，加载负载均衡、路有等扩展点；

    **monitor**： 监控层    定义监控服务，加载监控实现提供者；

    **protocol**： 协议层  封装 RPC 调用接口，管理调用实体的生命周期；

    **exchange**：信息交换层  封装请求响应模式，同步转异步；

    **transport**：抽象传输层模型，兼容 netty、mina、grizzly 等通讯框架；

    **serialize**：抽象序列化模型，兼容多种序列化框架，包括：fastjson、fst、hessian2、kryo、kryo2、protobuf 等，通过序列化支持跨语言的方式，支持跨语言的 rpc 调用；

- 服务的注册流程？

  - dubbo服务导出基于Spring容器发布刷新事件,Dubbo在接收到事件之后,会执行服务导出的逻辑。
  - 主要是三部分：
    - 第一部分就是检查检查参数,组装URL: 将配置在dubbo标签上的属性,按照url的格式拼装成一个url
    - 第二部分就是导出服务,包含导出服务到本地以及导出服务到远程,首先由dubbo提供的代理工厂创建一个invoker对象，里面包含了服务方法对象信息和具体的URL地址。然后再将invoker转换成Exporter,
    - 然后启动服务器server 监听端口 :  监听消费者的请求。
    - 最后 注册协议保存 Url和invoker的映射关系,注册到服务中心。

- 服务的发现流程？
  - 服务引用有两种方式,第一种是在ReferecnceBean的aferPropertiesSet方法时引用服务,第二个是在ReferenceBean对应的服务被注入到其他类中时引用。首先呢根绝config文件信息从注册中心订阅服务,首次会全量缓存到本地,后续的更新会监听动态更新到本地。
  - 接着 dubbo协议根据 provider的地址和接口信息连接到服务端server,开启客户端client,然后创建invoker
  - 然后为 invoker生成代理对象,用于远程调用provider,至此完成了服务引用

- Zookeeper 挂了dubbo还能用吗？有什么影响？
  - 能用,可以通过服务直连的方式绕过注册中心,但是不利于服务治理。宕机后不能够注册新服务。

- dubbo负载均衡有哪些？实现原理呢？
  - 加权随机:设置权重,并且相加,在这个和内 随机生一个随机数,判断在哪个区间。

  - 最小活跃数: 每个服务提供者都对应一个活跃数acitve,收到一个请求,活跃数+1,完成请求后活跃数-1.

  - 一致性哈希算法:

    - 1、映射Provider至Hash值区间中（实际中映射的是Invoker, 使用TreeMap进行存储

      2、映射请求，然后找到大于请求Hash值的第一个Invoker。**
    
    - 从配置中获取虚拟节点数以及参与 hash 计算的参数下标，默认情况下只使用第一个参数进行 hash。
    
    - 映射请求，然后找到大于请求Hash值的第一个Invoker。
  
- dubbo是线程阻塞的吗？
  - 默认是同步等待结果阻塞的,支持异步调用

- dubbo一次调用的流程？
  - 消费者代理持有Invoker对象,使用Invoker进行调用
  - 通过调用服务目录获取远程服务的Invoker列表
  - 根绝负载均衡选择一个可以调用的Invoker
  - 经过消费者端的过滤器链
  - 在将请求发送到服务端
  - 服务端收到这个request请求,分配到线程池进行处理。
  - server处理这些req
  - 找到对应的服务接口并进行调用,将结果返回
  - // 白话文
    - 服务容器启动,加载,运行服务提供者
    - 服务提供者在启动的时候,向注册中心注册自己所提供的服务。
    - 服务消费者在启动时,向注册中心订阅自己所需的服务。
    - 注册中心将服务列表提供给消费者,如果有变更,那么将基于长连接推送变更数据给消费者。
    - 服务消费者,从服务提供者列表中,通过负载均衡算法，选一台进行调用,如果调用失败,那么再选另外一台。

- ##### 聊聊 Dubbo SPI 机制？

  SPI（Service Provider Interface）是一种服务发现机制。其实就是将类的全限定名称写入配置当中，在服务加载的时候读取配置文件，加载实现类。这样就可以在运行的时候，动态帮助接口替换实现类。

  Dubbo 的 SPI 其实是对 Java 的 SPI 进行了一种增强,可以按需加载实现类之外，增加了 IOC 和 AOP 的特性，还有自适应扩展机制。

  SPI 在 dubbo 应用很多，包括协议扩展、集群扩展、路由扩展、序列化扩展等。

  Dubbo 对于文件目录的配置分为了三类：

  1. META-INF/services/ 目录：该目录下的 SPI 配置文件是为了用来兼容 Java SPI；
  2. META-INF/dubbo/ 目录：该目录存放用户自定义的 SPI 配置文件：key=com.xxx.xxx；
  3. META-INF/dubbo/internal/ 目录：该目录存放 Dubbo 内部使用的 SPI 配置文件。

- **Java SPI**

  Java SPI 在查找扩展实现类的时候遍历 SPI 的配置文件，并且将实现类全部实例化。

  **Dubbo SPI**

  1. 对 Dubbo 进行扩展不需要改动 Dubbo 源码；
  2. 延迟加载，可以一次只加载自己想要加载的扩展实现；
  3. 增加了对扩展点 IOC 和 AOP 的支持，一个扩展点可以直接 setter 注入其它扩展点；
  4. Dubbo 的扩展机制能很好的支持第三方 IoC 容器，默认支持 Spring Bean。

#### Zookeeper  

  https://bigdata.51cto.com/art/202009/625181.htm  ===

  https://zhuanlan.zhihu.com/p/345761223

   https://zhuanlan.zhihu.com/p/45728390

- **Zookeeper 是什么？ 有哪些功能？**
  - ZooKeeper是一个 分布式的,开放源码的分布式应用程序协调服务。提供的功能有：配置维护,域名服务,分布式同步,组服务等 ,目标就是封装好复杂易出错的关键服务,将简单易用的接口和性能高效、功能稳定的系统提供给用户。
  - 集群管理：监控节点的存活状态,运行请求等
  - 主节点选举：主节点挂掉了之后可以从备用的节点开始新一轮选主,主节点选举说的就是这个选举的过程,使用Zookeeper可以协助完成这个过程。
  - 分布式服务注册与订阅：
    - 在分布式环境下,同一个应用的服务会部署多份，并且所部署的服务具有相同的数据。 zk的一致性其实就保证了服务之间具有相同的数据。然后消费者可以去订阅这些服务,
    从而选取一个服务进行调用。
  - 分布式锁:Zookeeper提供两种锁,独占锁,共享锁,独占锁即一次只有一个线程使用资源,共享锁是读锁共享,读写互斥。
  - 命名服务:在分布式系统中,通过命名服务,客户端应用能够根据指定名字来获取资源或服务的地址,提供者等信息,因为zk的节点的结构是树形结构,然后保证了全局唯一的节点名称。
  
- **Zookeeper 的集群架构是怎么样的？ （主从架构）**
  - Zk是由多个服务组成的集群,一个leader节点,多个follower节点, leader提供读写服务,follower只能提供读服务。


- **Zookeeper 是如何保证顺序一致性的？**

  - 顺序一致性主要是针对写请求。客户端发来一个请求之后会到达leader节点或者从节点,如果是从节点要将请求转到leader节点,


  - leader节点会为每一个请求分配一个 zxid,然后转发给从节点,从节点会将请求写入到一个阻塞队列中。

  - 然后从节点会对leader节点响应 ack,如果ack过半,leader发送commit请求给所有follower,follower对比提交请求的zxid与阻塞队列中的zxid，如果不相同就重新和leader节点进行同步 。

- **Zookeeper 是强一致性的吗？**

  - 一致性指的是修改了一个副本节点后,其他副本节点也会进行同步修改,能够在其他副本节点读到修改后的值。

  - 强一致性指的是修改了某个副本节点后,其他节点能够立刻读取到其他节点的值。

  - Zookeeper其实不是强一致性的,Zk采用Zab协议,只要服务过半写入成功,数据就算写入成功了,如果请求落入到未同步完的节点上,那么读取到的数据还是旧的值。

  - 所以读的数据就不是强一致性的,因此zk无法保证数据的强一致性。只能保证最终一致性,而且可以保证统一客户端的顺序一致性。

- **谈下你对ZAB协议的了解？**
    - ZAB协议就是Zk的原子广播协议。 分为两种::一是崩溃恢复,二是消息广播。
    - 崩溃恢复的情况下有两种：
      - 一是集群刚启动的时候进行崩溃恢复。
      - 二是运行时服务异常进行崩溃恢复。
    - 崩溃恢复: 集群中的节点进入一个选取leader的状态。开始进行投票,投票的时候每个节点会发送自己的zxid和服务器ID进行比较,其实就是选出zxid比较大的那个服务器节点。然后判断是否有过半的机器投票选出leader,如果有那么此节点就当选leader，否则就接着进行投票。选取出leader后,其他节点就变为follower节点,然后follower节点向服务器发出自己服务器最大的zxid,leader服务器收到后会与自己本地的提议缓存队列进行比较,判断使用哪种策略进行同步。然后就正常进行到消息广播。
    - 消息广播: leader节点在收到写请求后,在广播事务的时候会分配一个全局递增的zxid。在进行广播, leader服务器会为每个follower节点分配一个单独的队列,然后将需要广播的事务依次放入这些队列中,然后根据先进先出的策略进行发送。每个follower节点在收到后会将其以事务日志的形式存入磁盘,并且在成功写入后返回给leader服务器一个ack响应。如果有过半的从节点进行了响应,那么leader会广播一个commit的消息给所有follower,follower接收到请求后完成对事务的广播操作。


- **Zookeeper怎么保证主从节点的状态同步？**
    - Zookeeper的核心是原子广播机制, ZAB协议。
      - 恢复模式：当服务启动或者领导这崩溃后,Zab就进入了恢复模式,当领导者被选举出来,其大多数完成了和leader的状态同步,那么恢复模式就结束了
      - 广播模式：leader与多数follower进行了状态同步之后,他就可以进行广播消息了。


- **Zookeeper部署模式？**

    - 单机部署

    - 集群部署

    - 伪集群部署


- **说一下Zk的通知机制？**
    - client端会对某个zNode建立一个watcher事件,当znode发生变化时，这些client会收到zk的通知,然后client可以根据znode变化做出业务上的改变。


- **集群中为什么要有主节点？**
    - 在分布式环境下,有些业务逻辑只需要及群众的某一台机器进行执行,其他的机器可以共享这个结果,这样可以大大减少重复计算,提高性能,于是 就需要 进行leader选举。


- **集群中有3台服务器,其中有一个宕机,这个时候zk还可以使用吗？**
    - 可以继续使用,单数服务器只要没超过一般的服务器宕机就可以继续使用 2n+1 n>0 最少3台 集群模式下


- **Zookeeper宕机如何处理？**

    - zk 集群的机制只要是超过半数的节点正常就可以提供服务。

    - Znode:
        - 持久节点： 持久节点,除非手动删除,否则zk节点一直存在于Zk上
        - 临时节点： 临时节点,临时节点的生命周期与客户端会话绑定,客户端失效,节点会被自动清理。  临时节点只能作为叶子节点。
        - 持久顺序节点：基本相同，增加了一个顺序属性。 由于父节点维护一个自增整型数字。
        - 临时顺序节点：临时顺序节点,在临时节点的基础添加了顺序特性。


- **Zookeeper和Dubbo的关系？**

    - Dubbo的将注册中心进行抽象,使得他可以外接不同的存储媒介给注册中心提供服务。
    - 引入了Zk作为存储媒介,也就是把Zk的特性引进来,可以进行资源同步,命名服务,以及节点之间的数据和资源进行同步,服务提供者在启动的时候,向 Zk上 的指定节点 /dubbo/serviceName/providers
      目录写入自己的URL地址,这个操作就完成了服务的发布,其他特性还有Mast选举,分布式锁。

- **服务提供者能实现失效踢出是什么原理？**

    - 服务失效踢出基于 Zookeeper 临时节点原理。

    - Zookeeper 中的节点是有生命周期的，具体的生命周期取决于节点的类型。节点主要分为持久（Persistent）节点和临时（Ephemeral）节点 。

- 版本号

    - 数据节点都有三种版本信息。

    - version ： 数据内容版本号

    - cversion: 当前数据子节点的版本号

    - aversion: 当前数据节点ACL变更版本号。

    - 通过版本号做一个乐观锁的机制,比如不同客户端对某一节点同时发出更新节点的请求，通过版本号的方式来解决并发修改的问题,只能保证一个更新请求执行成功。


- Zookeeper的工作流程？
  - 首先客户端连接Zk集群中的任何一个节点，可以使leader节点,也可是follower节点,一旦连接，节点会给客户端分配会话ID,并像客户端发送确认,如果客户端收到确认,那么连接成功,客户端会规律醒的发送心跳给zk
    - 客户端向zk发送读请求,节点会从数据库中找到这个节点的数据并返回
    - 客户端向zk发送写请求,节点会将znode路径发送到leader节点,leader会给该请求分配一个事务ID,然后通知从节点,从节点接收到消息后将该事务写入磁盘,然后主节点等待 ack相应,如果有过半以上的从节点响应后,认为该事务提交成功,然后给所有从节点发送commit消息,从节点接收到消息后,将该事务进行提交。（leader接受客户端的写请求后，会将请求通过队列发送个每个节点，每个节点收到消息后将记录写到磁盘， 并且返回ACK给leader，当半数以上的从节点返回ACK后，leader才commit这条更新。）

- Zookeeper Watch机制？

  - 客户端与服务端首先建立一个连接,然后去订阅某个节点或某些节点,如果节点数据发布变化的时候,服务端会通知客户端该节点发生了变化等等。

  - 服务端通知的就是一些Zk节点的变动时间类型,比如就是增加 删除 修改等,而不是推送结果。需要客户端主动的去拉取最新的节点信息。

  - ```java
      	    ZkClientWatcher zkClientWatcher = new ZkClientWatcher();
            zkClientWatcher.createConnection(CONNECT_ADDRES, SESSIONTIME);
            zkClientWatcher.createPath("/watcher","watcherData");
            zkClientWatcher.updateNode("/watcher","new Data");
            zkClientWatcher.zk.getChildren("/watcher",true);
            zkClientWatcher.createPath("/watcher/child","child");
            zkClientWatcher.deleteNode("/watcher/child");
            zkClientWatcher.deleteNode("/watcher");
    ```

#### Es   

- https://mp.weixin.qq.com/s/2LZ6zWe5ohQJl7GiZ52Vxg
- 倒排索引：正常的索引都是ID 对应某条记录的内容,而倒排索引呢就是某条记录的内容,对应这不同的ID。
- Es写数据的过程？
  1. 客户端选择一个节点发送请求过去，这个节点就是协调节点。
  2. 协调节点会对 文档进行路由，将请求转发给对应的节点 （主分片）。
  3. 然后对应节点的主分片处理请求，然后同步给从节点
  4. 协调节点发现  主节点和从节点都写完之后，再响应结果返回客户端
- Es读数据的过程？
  - 通过文档ID进行查询，根据文档ID进行hash，判断出来当时把文档ID分配到了哪个分片上去，从那个分片进行查询。
  - 客户端发送请求到任意一个node，成为协调节点
  - 协调节点对文档id进行hash路由，将请求转发到对应的node，此时使用轮询算法，在主节点和分节点选取一个，让读请求进行负载均衡。
  - 接收请求的节点返回文档给协调节点。
  - 协调节点把文档给客户端。
- Es搜索数据的过程？
  - 客户端发送一个请求到协调节点
  - 协调节点把搜索请求发送到所有分片对应的主节点或者从节点
  - 每个分片进行搜索，然后返回给协调节点
  - 然后协调节点进行合并，排序，分页等操作。
  - 最终返回给客户端
- Es写数据底层原理？
  - 先写入内存buffer，然后每隔1s，写入操作系统缓存，然后客户端可以查到，每隔5s写入translog文件中,translog 大到一定程度或者每30分钟 会将translog的数据进行一次提交，刷新到磁盘中。

#### Apollo

- **Apollo是什么？**
  - apollo是携程开源的一个配置管理中心,能够集中地管理应用不同环境不同集群之间的配置。 
  - 支持 应用、环境、命名空间 来管理k-v格式的配置

- **Apollo 动态配置的原理？**
  - 基于http长轮询和spring扩展机制实现的,apollo通过自己定义的一些BeanPostprocessor 将 包含 @Value注解的bean注册到apollo自己定义的注册表中，配置如果一旦发生了变化,apollo会根据配置的key找到对应的bean然后修改bean的属性。
  - 客户端和服务端保持了一个长连接,从而能够第一时间获得配置更新的推送
  - 客户端也会定时从apollo上拉取应用最新的配置
  - 客户端会把从服务端拉取的配置保存在本地一份

#### Spring  

- **SpringBean的作用域**？
  
  - singleton：单例
  - prototype：原型
  - request：每次http请求
  - session：http Session
  - globalSession：
  
- **SpringBoot启动过程？**https://zhuanlan.zhihu.com/p/115029344
  
  - ##### 构造SpringApplication实例
  
    1.首先会调用SpringApplication的静态方法run()，在这个方法里面会调用构造器方法创建出一个SpringApplication实例，在构造器中会确定当前web应用类型，是reactive web类型，还是servlet web类型，还是none类型。以及设置监听器等等，完成一些初始化操作。(监听器就是来监听SpringApplication启动过程的，在开始启动，创建上下文，启动失败等生命周期事件时都会调用监听器相关的方法)
  
    ##### 执行run()方法
  
    2.然后去执行实例的run()方法，首先会创建一个StopWatch计时器器，来统计run()方法的启动耗时，在日志里面会显示启动时间，那个时间就是在这里统计的。然后处理环境参数，就是`java -jar ***.jar`启动命令中带的那些jvm参数。
  
    ##### 创建applicationContext
  
    3.会创建出一个ApplicationContext，一般servlet的应用的context类型是AnnotationConfigServletWebServerApplicationContext。(可以认为beanFactory就是ioc容器，但是我们一般不直接使用beanFactory获取bean，而是通过applicationContext来获取，ioc容器beanFactory是应用上下文applicationContext的一个属性，applicationContext也实现了BeanFactory接口，可以认为applicationContext是一个高级容器，applicationContext支持国际化，默认是启动时加载所有bean，而不是用到时才进行懒加载，以及支持事件机制。)
  
    ##### 执行prepareContext()方法
  
    4.然后会调用prepareContext()方法来为应用上下文做一些准备工作，会将运行时的参数封装成bean，注册到beanFactory中去，以及使用load方法加载启动类。
  
    ##### 执行refreshContext()方法
  
    5.在这里会启动容器，也就是会为beanFactory做很多配置，注册BeanPostProcessors，设置类加载器等等。在这一步也会解析启动类中@SpringBootApplication这个组合注解。
  
    ##### afterRefresh()方法
  
    6.这个方法里面会把容器里面所有ApplicationRunner自定义子类和CommandLineRunner自定义子类的Bean全部取出来，执行它们的run()方法。(就是有时候如果需要在应用启动后执行一些我们自定义的初始化操作，可以通过自定义一个类，继承ApplicationRunner类来实现。)
  
    之后会调用listeners.started()方法，通知所有Listener，application已经启动完成了，以及调用listeners.running()方法通知所有Listener，application已经运行了。
    
  - 
  
  - **重点**
  
  - 首先执行SpringAppliation. run方法,构造出一个SpringApplication 实例,
  
  - 然后创建一个applicationContext,
  
  - 此时在对应的applicationContext的构造器中往BeanFactory中注册一个ConfigurationClassPostProcessor的后置处理器。
  
  - 然后执行到refreshContext 刷新上下文的时候,首先执行后置处理器,然后ConfigurationClassPost-- 会将其扫描的类都加入到BeanFactory中, 然后在接着实例化所有的bean
  
  - 最终查询出applicationRunner和CommindRunner的实现,依次执行。
  
- Bean的生命周期?
  - Bean的实例化阶段

  - 属性赋值阶段

  - Bean的初始化阶段

  - Bean的销毁阶段

  - ![img](https://img-blog.csdnimg.cn/20210510144229675.png)

    ------

    容器启动->实例化bean对象-》设置对象属性 -》调用BeanNameAware  设置bean名称。

  - 然后设置BeanFactroyAware -》设置ApplicationContextware-》 执行BeanPostProcessor （before）

  - 在调用 初始化Bean 的 afterproperties 方法， 调用 init方法  在调用BeanPostProcessor
  
  - 最终是Bean的销毁的方法。
  
- Spring IOC如何解决循环依赖的问题？ https://juejin.cn/post/6882266649509298189#heading-3
  - IOC只能解决属性注入之间的循环依赖,不能解决构造器
  - 首先呢Spring 提供了3个map存储Bean,我们也称之为三级缓存
  - 一级缓存:存放已经实例化好的Bean
  - 二级缓存:存放的是没有完全创建好的Bean,bean刚刚构造完成,没有进行属性天成
  - 三级缓存:存放的是正在创建中的Bean,便于有机会创建代理对象,此时的bean是没有完成属性填充的
  - 假设A依赖B,B依赖A,初始化A的 时候,发现没有三个缓存中都没有A这个实例,那么去初始化A这个实例并存入到三级缓存,走到A需要B那步,那么去加载B,B同事添加到三级缓存,B需要A就从三级缓存中取出A,这样B就完成了属性填充,并存入到二级缓存中,然后对B进行初始化,初始化完成后放入1级缓存中,然后A从一级缓存中获取到B,从而完成A进入二级依赖,A完全初始化完成后,A加入到一级缓存。
  - 如果 Spring 选择二级缓存来解决循环依赖的话，那么就意味着所有 Bean 都需要在实例化完成之后就立马为其创建代理，而 Spring 的设计原则是在 Bean 初始化完成之后才为其创建代理。所以，Spring 选择了三级缓存。但是因为循环依赖的出现，导致了 Spring 不得不提前去创建代理，因为如果不提前创建代理对象，那么注入的就是原始对象，这样就会产生错误。
  
- SpringAOP？https://cloud.tencent.com/developer/article/1692917
  - Aop的实现关键在于代理模式,AOP代理主要分为静态代理和动态代理，
  - Spring使用的时动态代理：动态代理主要实现有两种,一种是JDK自带的动态代理,一种是Spring 的CGLIB代理。
  - JDK的有接口的实现,并实现InvocationHandler来进行代理的实现
  - CGLIB通过继承的方式进行代理的实现
  
- Spring 设计模式？
  - 工厂模式:  工厂模式
  - 单例模式:  Spring Bean
  - 代理模式:  Spring AOP
  - 模板方法:  JDBCTemplate,RedisTemplate
  - 观察者模式:定义对象间一种一对多的依赖关系,当一个对象的状态发生改变的时候,所有依赖它的对象都会的到通知被制动更新,如Spring中listener的实现-ApplicationListener
  
- Spring框架中有哪些不同类型的事件？
  - 上下文更新事件  ContextRefreshEvent
  - 上下文开始事件  ContextRefreshEvent
  - 上下文停止事件 
  - 上下文关闭事件
  
- Spring事务传播行为有哪些？https://segmentfault.com/a/1190000020386113
  - 为什么会有传播机制？

    - Spring不同服务之间会互相调用,比如方法A有事务,方法B有事务,方法A中存在方法B,那么这种情况下事务如何处理。

  - 传播机制生效条件

    - Spring是使用AOP来代理事务控制的,是针对接口和类的,所以在同一个Service类中两个方法的调用,事务的传播机制是不生效的。

  - 传播行为：

    - propagation_required (默认): 支持当前事务,如果当前无事务,则新建一个事务。如果当前存在事务,则加入当前事务,合并成一个事务
    - requires_new： 新建事务,如果当前存在事务,则把当前事务挂起,这个方法独立提交事务,不受调用者的影响,父级异常,也会正常提交。
    - Nested:当前存在事务,将会成为父级事务的一个子事务,方法结束后并没有提交,只有等父级事务结束后才提交,父级异常它会回滚
    - Supports:存在事务则加入事务,不存在事务,以非事务方式运行
    - Not_supported:非事务方式运行
    - MANDATORY： 如果当前存在事务，则运行在当前事务中，如果当前无事务，则抛出异常，也即父级方法必须有事务
    - Never:非事务方式运行,如果存在事务就异常。
  
- Spring如何在运行时候通知对象？
  - 通过代理类包裹切面,Spring在运行的时候把切面啊织入到Spring管理的bean中,代理封装了目标类,并拦截被通知方法的调用,在把调用转发给真正的目标bean。当代理拦截到方法调用时,在调用目标bean方法之前,会执行切面逻辑。
  
- SpringMVC的执行流程？
  - 用户发送 请求到前端控制器 DispatcherServlet
  - DispatcherServlet收到请求后,调用HandlerMapping处理器映射器,请求获取handler
  - 处理器映射器根据请求url找到 具体的处理器handler 返回给DispatcherServlet
  - DispatcherServlet调用处理器适配器,请求执行handler
  - 经过适配调用,具体处理器进行处理业务逻辑,然后返回ModleAndView
  - 然后将ModelAndView返回给DispatchServlet
  - 然后DispatcherServlet 将其传给 ViewResolver 视图解析器进行解析
  - 解析后返回具体的View
  - 然后对View进行渲染,然后返回给用户。


#### Mongo:   

- https://juejin.cn/post/6844903513844121614
- Mongo的特点?与mysql的区别？
  - MongoDB将数据存储在类似JSON的文档中，并且文档中每个json串结构可能不同，相关信息存储在一起，通过MongoDB查询语言进行快速查询。可以不用预先定义结构就可以创建记录，例如字段或者其值的类型。 集合中的文档不需要相同的一组字段，非规范化
  - Mysql是将数据存储在表中，而数据表示预先定义好的。 并且mysql支持join查询， 支持事务。
- 分布式ID的实现？
  - 雪花算法:  将64位分割成多个部分, 由时间戳 和 机器ID以及序列数生成。
  - 根据天的单位在mongo上创建文档，并有一个字段是代表序列的。如果是同一天就在该字段进行+1的操作。然后我们程序在拼接上时间戳，最终实现该分布式ID。

#### **实践**:

- 死锁：客户端存在并发提交的情况: 表中存在唯一索引（评价单号+问题编码）, 当唯一索引冲突的时候,第二个事务会将冲突的索引记录升级为next-key锁,next-key锁表示当前索引记录的锁定以及和前一个记录之间的间隙锁。 因为评价答案的顺序不是递增的,导致了唯一key冲突的时候,第一个事务插入到最后一个数据的时候,他的值位于事务二所持有的间隙锁之间,导致了死锁。 解决办法,提交评价前 将其排序后在进行提交。然后在排查为什么并发请求。
- 死锁发生的必要条件？
  - 互斥
  - 占有且等待
  - 不可抢占
  - 循环等待
- 死锁该如何解决呢？
  - 避免死锁发生？  
    - 破坏“循环等待”条件
    - 将系统资源进行顺序编号，并有序分配，申请资源的时候按照顺序进行申请。
- OOM:评价记录导出, 导出限制 ，Redis限流操作。
- Redis分布式锁以及可重入？
  - 可以使用Redis的hash结构，对应的key的hash结构记录当前线程的一个唯一标识 可以是UUID, 然后value可以存储锁次数。
- JVM调优:
  - 个人中心： 4C8G   堆内存  5G
  - 查看GC日志的命令?
  - 之前优化过自如个人中心的项目,该项目集成了各个系统的api调用,每月我们都要梳理梳理系统中的慢请求来进行优化,发现请求量高峰的时候系统的整体响应就存在偏慢的情况,当时查看了系统各项指标的的大盘,看到了请求高峰期发生GC, 当时查看系统的GC日志, 我们项目使用的是CMS垃圾回收器,发现在重标记 Remark 阶段耗时1秒多,remark阶段我们都知道是暂停用户线程的,处理垃圾回收的线程其余线程全部挂起。所以我们的目的是要降低一下重标记这个阶段的时间。
  - 首先呢CMS分为四个阶段:
    - 初始标记  STW
    - 并发标记  
    - 重新标记: 重新标记要解决的问题呢就是并发标记时,用户线程可能对之前未标记到的对象进行了重新引用,防止在下一阶段被清理掉,所以这个过程暂停用户线程的,而且这个过程是以新生代中的对象来判断对象是否存活的, 也就是说重新标记需要扫描 （整个堆 新生代+老年代）,所以其实就是堆中的数量影响了Remark的时间。 
      - 为什么必须扫描整个堆？
        - 新生代的GC和老年代的GC是独立进行的,只有minor GC时,才会使用根搜索算法,标记新生代对象是否可达,有一些对象即使不可达,那么没有minorGC的话,还是不会标记为不可达,CMS没办法区分哪些对象是存活的。
    - CMS提供了一个参数是 CMSScavengeBeforeRemark,在重新标记之前强制执行一次minorGC。
  - 限流算法：
    - https://juejin.cn/post/6870396751178629127

#### 开放:

- **项目的迁移重构需要注意的东西**？

  ------

  - 就我们之前的项目来讲 重构的时候
  - 首先就是旧系统的熟悉和业务梳理。
  - 然后就是数据库重构, --- 进行表结构的设计。 并进行分库分表。
  - 然后就是后台服务的重构，按照之前旧系统的梳理，进行功能的迁移， 新系统中的接口有一部分是直接做老系统接口的逻辑，这样后面可以通过老系统直接透传过来。
  - 然后就是数据的迁移与校验。进行增量迁移。 然后写程序校验新旧系统的数据。
  - 然后就需要测试介入 -- 一顿测试。
  - 然后呢就是上线方案么？
  - 灰度 -- 选取个别城市，进行灰度测试。
    - 第一阶段是保证透传的接口稳定，能够保持服务正常运行。  并校验新旧系统的数据是否一致，并将老系统的数据洗到新系统。 此时事务用的是老系统,数据的查询仍然是老系统。
    - 第二阶段是采用新系统的接口走业务流程的数据，然后同步到老系统，这个时候事务用的是新系统了。同时也会校验两个系统的数据是否一致。
    - 第三阶段就是弃用老系统的数据库了，然后老项目的老接口不做业务逻辑了，只做透传。

- 设计一个日志系统？（分布式）
  - 采集日志：使用哪种方式接入  sdk  （jar包） 规范日志格式等等？然后可以异步发送到消息中间件
  - 日志存储：可以使用Es进行存储,支持快速检索 （倒排索引）
  - 日志可视化管理：  Kibana  Es 可视化管理

- 设计一个秒杀系统？

  - 秒杀系统面临的问题就是  高并发，而库存数量有限 主要就是抵挡高流量打入DB

  - 商品信息啥的可以都放缓存里，防止查询也直接打入DB

  - 可以在页面上限制用户几秒之内才能点一次啊

  - 防止超卖， 更新库存的时候可以用乐观锁。

    ```sql
    goods 表  quantity  库存   
    update Goods set quantity = quantity - #{buyQuantity} 
    where id = #{id} 
    and quantity - #{buyQuantity} >= 0 
    and status = 1
    ```

- 如何设计一个电梯调度系统？
  - 两个比较重要的点:
    - 一次性完成一个方向上的呼叫楼层。 
    - 然后掉转方向然后完成另一个方向上的呼叫楼层。
    - 如果没有具体的目标楼层，那么按照此方向的最高楼层或者最小楼层。
    - 如果在上升过程中,点击了当前楼层与目标楼层之间的楼层 并且是同方向,那么会在此楼层暂停
    - 如果在下降过程中,点击了当前楼层与目标楼层之间的楼层 并且是同方向 那么也会在此楼层暂停。
    - 如果上升或者下降的过程中点击了反方向,则会等待电梯运行同方向的时候才会停靠。

- 说一下快排的思路？
  - 快排就是选中一个pivot 中心点，然后把数组中的元素,又中心点分开 左面小，右面大。
  - 然后在递归的寻找中心点,在进行左右部分的切分
  - 最终切分完成 - 有序。

- 系统治理 （防止崩溃的）的手段有哪些？ https://xie.infoq.cn/article/2593d1a3b9e1e06cac6502c4f
  - 提交告警：通过异常日志进行告警，进行处理
  - 环境隔离： 生产部署两套环境
  - 重试策略： 调用外部接口进行重试 
  - 内部异常： 可进行降级处理。
  - **限流**：限流一般是从流量入口进行考虑,从进入的流量上进行限制,达到保护系统的作用,是指限制并发请求的场景。计数器、令牌桶、滑动窗口、漏斗
  - **熔断**：熔断强调的是服务之间的调用能够实现自我恢复的状态。其实就是如果某个服务A调用服务B,可能一直失败,如果失败到达一个阈值的时候,那么熔断器将会被打开,其实就是A服务不在发生请求或者刚发出就返回错误,不去请求B,等过一段时间,在使得熔断器进行一个半开的状态,如果请求成功就关闭熔断器。
  - **降级**：降级是从整体的资源使用的角度来考虑的,当整体资源不足的时候,牺牲部分低优先级的功能来保证高优先级的服务。 **限流和熔断都是降级的一致。**

- 操作系统中断？
  - 中断：处理器收到硬件或者软件通知的信号,提示发生了某个事件,应该被注意,这种情况就被称为中断。
  - 硬件中断：外中断：来自处理器以外的中断信号,包括时钟中断,键盘中断,外部设备中断等。  内中断：来自处理器内部的中断
  - 软件中断：CPU指令，用以自陷一个中断,由于软中断指令通常要运行一个切换CPU至内核态的子例程，

- Redis和zk实现分布式锁有什么差别？

  - Redis通过setNx命令来实现

  - Zk通过多个客户端创建临时节点来实现，临时节点路径保证唯一，只要谁能创建成功就能够获取到锁  通过session 判断谁拿到锁

  - 释放锁

    Zookeeper使用直接关闭临时节点session会话连接，因为临时节点生命周期与session会话绑定在一块，如果session会话连接关闭的话，该临时节点也会被删除。

    这时候客户端使用事件监听，如果该临时节点被删除的话，重新进入盗获取锁的步骤。

    Redis在释放锁的时候，为了确保是锁的一致性问题，在删除的redis 的key时候，需要判断同一个锁的id，才可以删除。

    共同特征：如何解决死锁现象问题

    Zookeeper使用会话有效期方式解决死锁现象。

    Redis 是对key设置有效期解决死锁现象

- **超大文件去重如何做**？
  - 将大文件切割称m个小文件
  - 然后对每个小文件进行排序
  - 然后取每个文件的第一行,然后进行比较,最小的行输出到新的文件中
  - 然后最小的那个文件在读一行，然后与其他文件的接着比较,继续将最小的输出到新的文件中，某一行与新文件中的行一样 则证明数据重复了,则不写入
  - 一直重复这个步骤输出  就可以了。

- 海量数据处理思路？
  - https://blog.csdn.net/v_july_v/article/details/7382693

- 亿级数据取出点赞排名前20的？

  - 可以利用Redis的一个数据结构, Sort Set 天然具有排序的功能。 因为是亿万级别数据所以,一个sortSet 的排序性能也会降低,我们可以根据点赞数量的切分成多个区间,某个区间的数据放入某个sortSet。 如果查询top 的 直接查询点赞数量最多的那个区间里 取出前面排名的即可。
  - 如果要是查看自己的排名 就计算自己所在区间的排名+比自己高的那些区间整体排名。


#### 分布式：

- CAP：

  - C：一致性指的就是 ：所有节点在同一时间的数据完全一致。

  - A：可用性：服务器能够正常的进行响应。

  - P：分区容错性：分布式系统出现网络分区的时候,仍能够对外提供服务。分区的概念其实就是可能某些节点的通讯连接异常,使得某些节点之间不连通了,数据就散布在了这些不连通的区域中,这就叫分区。

  - 如果发生分区以后 - 才去选择  CP还是AP

  - **为啥无同时保证 CA 呢？**

    举个例子：若系统出现“分区”，系统中的某个节点在进行写操作。为了保证 C， 必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。

  - 总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。

- BASE：

  - **BASE** 是 **Basically Available（基本可用）** 、**Soft-state（软状态）** 和 **Eventually Consistent（最终一致性）** 三个短语的缩写。BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求。 最终一致性。

- 分布式事务？

  - **TCC**
  - **本地消息表：**
    - 写本地消息和业务操作放入一个事务中,保证了业务和发消息的原子性,要么他们全部成功,要么全部失败。

  - **事务消息：**
    - 类似于本地消息表, 只不过功能挪到了消息队列时尚

  - **最大努力通知：**
    - 提供反查接口,让业务放能够知道对应的状态。
    - 最大努力通知, 尝试到一定次数,如果仍然失败就不再通知了。


####    网络:

- TCP三次握手?
  - 第一次握手,客户端向服务端发送一个SYN报文。
  
  - 第二次握手,服务端收到SYN报文后,会应答一个SYN+ACK报文。
  
  - 第三次握手,客户端收到SYN+ACK报文之后,会回应一个ACK报文
  
  - 服务器收到ACK报文之后,三次握手建立完成。
  
  - ```
    为什么两次不行：
    因为第二次完成的时候,服务端没法确定客户端的接收能力是否正常。
    第三次握手确认了 客户端和服务端的发送和接收能力都是正常的。
    ```
  
    
  
- TCP四次挥手?

  - 客户端发送一个FIN报文,报文中指定一个序列号,此时客户端处于FIN_WAITI 状态
  - 第二次挥手,服务器收到FIN之后,会发送ACK报文,并且把客户端的序列号值+1作为ack报文的序列号值,表明已经收到客户端的报文了，此时服务端处于CLOST_WAIT状态
  - 第三次挥手,如果服务端也想断开连接了,和客户端的第一次挥手一样,发给FIN报文,且指定一个序列号,此时服务端处于LAST_ACK的状态。
  - 第四次挥手,客户端收到 FIN之后 一样发送一个ACK作为应答,然后把服务端序列号的值+1作为自己ACK报文的序列号值,此时客户端处于TIME_WAIT状态,需要过一阵子以确保服务端受到自己的ACK保温之后才会进入CLOSED状态。


- 特别注意TIME_WAIT?
  - 客户端为什么发送ACK之后不能直接关闭？要确保服务器已经收到了我们的ACK报文,如果没收到的话,服务器会重发FIN给客户端,客户端再次接收到之后,会再次发送ACK报文
  - 至于TIME_WAIT的持续时间至少是一个报文的时间,如果超过这个时间  没有收到服务器的FIN报文,就证明 服务器已经断开连接了。

#### 智力题：

https://www.i4k.xyz/article/vic_torsun/117705247
